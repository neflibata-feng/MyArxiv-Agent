# üì• My Arxiv Inbox

>ËøôÈáåÊòØ**ÂæÖÈòÖËØªÂå∫**„ÄÇËá™Âä®ÂåñÁ®ãÂ∫è‰ºöËá™Âä®Â∞ÜÊõ¥Êñ∞ÁöÑËÆ∫ÊñáËøΩÂä†Âà∞‰∏ãÊñπ„ÄÇ

**Êìç‰ΩúÊåáÂçóÔºö**
- [ ] ËøôÊòØ‰∏Ä‰∏™Êú™ËØªÈ°π„ÄÇ
- [x] ËøôÊòØ‰∏Ä‰∏™Â∑≤Á°ÆËÆ§È°π (ÊâìÈí©ÂêéÊé®ÈÄÅÔºåGitHub Actions ‰ºöËá™Âä®Â∞ÜÂÖ∂ÂΩíÊ°£Âπ∂ÂàõÂª∫Á¨îËÆ∞)„ÄÇ
- Âà†Èô§Êï¥Ë°åÔºöËøôÊòØ‰∏Ä‰∏™‰∏çÊÑüÂÖ¥Ë∂£ÁöÑÈ°π (Â∞ÜË¢´ÂøΩÁï•)„ÄÇ

---

## 2026-02-25 Êõ¥Êñ∞ 31 ÁØáÊñ∞ËÆ∫Êñá
- [ ] **[cs.AI]** [Aletheia tackles FirstProof autonomously](https://arxiv.org/abs/2602.21201v1) *by Tony Feng et al. (2026-02-24)* - _We report the performance of Aletheia (Feng et al., 2026b), a mathematics research agent powered by Gemini 3 Deep Think, on the inaugural FirstProof challenge. Within the allowed timeframe of the challenge, Aletheia autonomously solved 6 problems (2, 5, 7, 8, 9, 10) out of 10 according to majority expert assessments; we note that experts were not unanimous on Problem 8 (only). For full transparency, we explain our interpretation of FirstProof and disclose details about our experiments as well as..._
- [ ] **[cs.LG]** [Learning from Trials and Errors: Reflective Test-Time Planning for Embodied LLMs](https://arxiv.org/abs/2602.21198v1) *by Yining Hong et al. (2026-02-24)* - _Embodied LLMs endow robots with high-level task reasoning, but they cannot reflect on what went wrong or why, turning deployment into a sequence of independent trials where mistakes repeat rather than accumulate into experience. Drawing upon human reflective practitioners, we introduce Reflective Test-Time Planning, which integrates two modes of reflection: \textit{reflection-in-action}, where the agent uses test-time scaling to generate and score multiple candidate actions using internal reflec..._
- [ ] **[cs.AI]** [A Benchmark for Deep Information Synthesis](https://arxiv.org/abs/2602.21143v1) *by Debjit Paul et al. (2026-02-24)* - _Large language model (LLM)-based agents are increasingly used to solve complex tasks involving tool use, such as web browsing, code execution, and data analysis. However, current evaluation benchmarks do not adequately assess their ability to solve real-world tasks that require synthesizing information from multiple sources and inferring insights beyond simple fact retrieval. To address this, we introduce DEEPSYNTH, a novel benchmark designed to evaluate agents on realistic, time-consuming probl..._
- [ ] **[cs.HC]** [SparkMe: Adaptive Semi-Structured Interviewing for Qualitative Insight Discovery](https://arxiv.org/abs/2602.21136v1) *by David Anugraha et al. (2026-02-24)* - _Qualitative insights from user experiences are critical for informing product and policy decisions, but collecting such data at scale is constrained by the time and availability of experts to conduct semi-structured interviews. Recent work has explored using large language models (LLMs) to automate interviewing, yet existing systems lack a principled mechanism for balancing systematic coverage of predefined topics with adaptive exploration, or the ability to pursue follow-ups, deep dives, and em..._
- [ ] **[cs.HC]** ["Are You Sure?": An Empirical Study of Human Perception Vulnerability in LLM-Driven Agentic Systems](https://arxiv.org/abs/2602.21127v1) *by Xinfeng Li et al. (2026-02-24)* - _Large language model (LLM) agents are rapidly becoming trusted copilots in high-stakes domains like software development and healthcare. However, this deepening trust introduces a novel attack surface: Agent-Mediated Deception (AMD), where compromised agents are weaponized against their human users. While extensive research focuses on agent-centric threats, human susceptibility to deception by a compromised agent remains unexplored. We present the first large-scale empirical study with 303 parti..._
- [ ] **[cs.RO]** [Cooperative-Competitive Team Play of Real-World Craft Robots](https://arxiv.org/abs/2602.21119v1) *by Rui Zhao et al. (2026-02-24)* - _Multi-agent deep Reinforcement Learning (RL) has made significant progress in developing intelligent game-playing agents in recent years. However, the efficient training of collective robots using multi-agent RL and the transfer of learned policies to real-world applications remain open research questions. In this work, we first develop a comprehensive robotic system, including simulation, distributed learning framework, and physical robot components. We then propose and evaluate reinforcement l..._
- [ ] **[cs.SE]** [Toward an Agentic Infused Software Ecosystem](https://arxiv.org/abs/2602.20979v1) *by Mark Marron (2026-02-24)* - _Fully leveraging the capabilities of AI agents in software development requires a rethinking of the software ecosystem itself. To this end, this paper outlines the creation of an Agentic Infused Software Ecosystem (AISE), that rests on three pillars. The first, of course, is the AI agents themselves, which in the past 5 years have moved from simple code completion and toward sophisticated independent development tasks, a trend which will only continue. The second pillar is the programming langua..._
- [ ] **[cs.CV]** [See and Fix the Flaws: Enabling VLMs and Diffusion Models to Comprehend Visual Artifacts via Agentic Data Synthesis](https://arxiv.org/abs/2602.20951v1) *by Jaehyun Park et al. (2026-02-24)* - _Despite recent advances in diffusion models, AI generated images still often contain visual artifacts that compromise realism. Although more thorough pre-training and bigger models might reduce artifacts, there is no assurance that they can be completely eliminated, which makes artifact mitigation a highly crucial area of study. Previous artifact-aware methodologies depend on human-labeled artifact datasets, which are costly and difficult to scale, underscoring the need for an automated approach..._
- [ ] **[econ.GN]** [Some Simple Economics of AGI](https://arxiv.org/abs/2602.20946v1) *by Christian Catalini et al. (2026-02-24)* - _For millennia, human cognition was the primary engine of progress on Earth. As AI decouples cognition from biology, the marginal cost of measurable execution falls to zero, absorbing any labor capturable by metrics--including creative, analytical, and innovative work. The binding constraint on growth is no longer intelligence but human verification bandwidth: the capacity to validate, audit, and underwrite responsibility when execution is abundant. We model the AGI transition as the collision of..._
- [ ] **[cs.AI]** [Architecting AgentOS: From Token-Level Context to Emergent System-Level Intelligence](https://arxiv.org/abs/2602.20934v1) *by ChengYou Li et al. (2026-02-24)* - _The paradigm of Large Language Models is undergoing a fundamental transition from static inference engines to dynamic autonomous cognitive systems.While current research primarily focuses on scaling context windows or optimizing prompt engineering the theoretical bridge between micro scale token processing and macro scale systemic intelligence remains fragmented.This paper proposes AgentOS,a holistic conceptual framework that redefines the LLM as a "Reasoning Kernel" governed by structured opera..._
- [ ] **[cs.NI]** [Airavat: An Agentic Framework for Internet Measurement](https://arxiv.org/abs/2602.20924v1) *by Alagappan Ramanathan et al. (2026-02-24)* - _Internet measurement faces twin challenges: complex analyses require expert-level orchestration of tools, yet even syntactically correct implementations can have methodological flaws and can be difficult to verify. Democratizing measurement capabilities thus demands automating both workflow generation and verification against methodological standards established through decades of research.  We present Airavat, the first agentic framework for Internet measurement workflow generation with systema..._
- [ ] **[cs.CR]** [SoK: Agentic Skills -- Beyond Tool Use in LLM Agents](https://arxiv.org/abs/2602.20867v1) *by Yanna Jiang et al. (2026-02-24)* - _Agentic systems increasingly rely on reusable procedural capabilities, \textit{a.k.a., agentic skills}, to execute long-horizon workflows reliably. These capabilities are callable modules that package procedural knowledge with explicit applicability conditions, execution policies, termination criteria, and reusable interfaces. Unlike one-off plans or atomic tool calls, skills operate (and often do well) across tasks.  This paper maps the skill layer across the full lifecycle (discovery, practice..._
- [ ] **[cs.LG]** [Regret-Guided Search Control for Efficient Learning in AlphaZero](https://arxiv.org/abs/2602.20809v1) *by Yun-Jui Tsai et al. (2026-02-24)* - _Reinforcement learning (RL) agents achieve remarkable performance but remain far less learning-efficient than humans. While RL agents require extensive self-play games to extract useful signals, humans often need only a few games, improving rapidly by repeatedly revisiting states where mistakes occurred. This idea, known as search control, aims to restart from valuable states rather than always from the initial state. In AlphaZero, prior work Go-Exploit applies this idea by sampling past states ..._
- [ ] **[cs.AI]** [Pipeline for Verifying LLM-Generated Mathematical Solutions](https://arxiv.org/abs/2602.20770v1) *by Varvara Sazonova et al. (2026-02-24)* - _With the growing popularity of Large Reasoning Models and their results in solving mathematical problems, it becomes crucial to measure their capabilities. We introduce a pipeline for both automatic and interactive verification as a more accurate alternative to only checking the answer which is currently the most popular approach for benchmarks. The pipeline can also be used as a generator of correct solutions both in formal and informal languages. 3 AI agents, which can be chosen for the benchm..._
- [ ] **[cs.AI]** [PyVision-RL: Forging Open Agentic Vision Models via RL](https://arxiv.org/abs/2602.20739v1) *by Shitian Zhao et al. (2026-02-24)* - _Reinforcement learning for agentic multimodal models often suffers from interaction collapse, where models learn to reduce tool usage and multi-turn reasoning, limiting the benefits of agentic behavior. We introduce PyVision-RL, a reinforcement learning framework for open-weight multimodal models that stabilizes training and sustains interaction. Our approach combines an oversampling-filtering-ranking rollout strategy with an accumulative tool reward to prevent collapse and encourage multi-turn ..._
- [ ] **[cs.CR]** [AdapTools: Adaptive Tool-based Indirect Prompt Injection Attacks on Agentic LLMs](https://arxiv.org/abs/2602.20720v1) *by Che Wang et al. (2026-02-24)* - _The integration of external data services (e.g., Model Context Protocol, MCP) has made large language model-based agents increasingly powerful for complex task execution. However, this advancement introduces critical security vulnerabilities, particularly indirect prompt injection (IPI) attacks. Existing attack methods are limited by their reliance on static patterns and evaluation on simple language models, failing to address the fast-evolving nature of modern AI agents. We introduce AdapTools,..._
- [ ] **[cs.AI]** [ICON: Indirect Prompt Injection Defense for Agents based on Inference-Time Correction](https://arxiv.org/abs/2602.20708v1) *by Che Wang et al. (2026-02-24)* - _Large Language Model (LLM) agents are susceptible to Indirect Prompt Injection (IPI) attacks, where malicious instructions in retrieved content hijack the agent's execution. Existing defenses typically rely on strict filtering or refusal mechanisms, which suffer from a critical limitation: over-refusal, prematurely terminating valid agentic workflows. We propose ICON, a probing-to-mitigation framework that neutralizes attacks while preserving task continuity. Our key insight is that IPI attacks ..._
- [ ] **[cs.AI]** [How Foundational Skills Influence VLM-based Embodied Agents:A Native Perspective](https://arxiv.org/abs/2602.20687v1) *by Bo Peng et al. (2026-02-24)* - _Recent advances in vision-language models (VLMs) have shown promise for human-level embodied intelligence. However, existing benchmarks for VLM-driven embodied agents often rely on high-level commands or discretized action spaces, which are non-native settings that differ markedly from real-world control. In addition, current benchmarks focus primarily on high-level tasks and lack joint evaluation and analysis at both low and high levels. To address these limitations, we present NativeEmbodied, ..._
- [ ] **[cs.SE]** [Agile V: A Compliance-Ready Framework for AI-Augmented Engineering -- From Concept to Audit-Ready Delivery](https://arxiv.org/abs/2602.20684v1) *by Christopher Koch et al. (2026-02-24)* - _Current AI-assisted engineering workflows lack a built-in mechanism to maintain task-level verification and regulatory traceability at machine-speed delivery. Agile V addresses this gap by embedding independent verification and audit artifact generation into each task cycle. The framework merges Agile iteration with V-Model verification into a continuous Infinity Loop, deploying specialized AI agents for requirements, design, build, test, and compliance, governed by mandatory human approval gate..._
- [ ] **[cs.AI]** [Grounding LLMs in Scientific Discovery via Embodied Actions](https://arxiv.org/abs/2602.20639v1) *by Bo Zhang et al. (2026-02-24)* - _Large Language Models (LLMs) have shown significant potential in scientific discovery but struggle to bridge the gap between theoretical reasoning and verifiable physical simulation. Existing solutions operate in a passive "execute-then-response" loop and thus lacks runtime perception, obscuring agents to transient anomalies (e.g., numerical instability or diverging oscillations). To address this limitation, we propose EmbodiedAct, a framework that transforms established scientific software into..._
- [ ] **[cs.AI]** [From Logs to Language: Learning Optimal Verbalization for LLM-Based Recommendation in Production](https://arxiv.org/abs/2602.20558v1) *by Yucheng Shi et al. (2026-02-24)* - _Large language models (LLMs) are promising backbones for generative recommender systems, yet a key challenge remains underexplored: verbalization, i.e., converting structured user interaction logs into effective natural language inputs. Existing methods rely on rigid templates that simply concatenate fields, yielding suboptimal representations for recommendation. We propose a data-centric framework that learns verbalization for LLM-based recommendation. Using reinforcement learning, a verbalizat..._
- [ ] **[cs.GT]** [Maximin Share Guarantees via Limited Cost-Sensitive Sharing](https://arxiv.org/abs/2602.20541v1) *by Hana Salavcova et al. (2026-02-24)* - _We study the problem of fairly allocating indivisible goods when limited sharing is allowed, that is, each good may be allocated to up to $k$ agents, while incurring a cost for sharing. While classic maximin share (MMS) allocations may not exist in many instances, we demonstrate that allowing controlled sharing can restore fairness guarantees that are otherwise unattainable in certain scenarios. (1) Our first contribution shows that exact maximin share (MMS) allocations are guaranteed to exist w..._
- [ ] **[cs.AI]** [Inner Speech as Behavior Guides: Steerable Imitation of Diverse Behaviors for Human-AI coordination](https://arxiv.org/abs/2602.20517v1) *by Rakshit Trivedi et al. (2026-02-24)* - _Effective human-AI coordination requires artificial agents capable of exhibiting and responding to human-like behaviors while adapting to changing contexts. Imitation learning has emerged as one of the prominent approaches to build such agents by training them to mimic human-demonstrated behaviors. However, current methods struggle to capture the inherent diversity and non-Markovian nature of human behavior and lack the ability to steer behavior at inference time. Drawing inspiration from the th..._
- [ ] **[cs.AI]** [ActionEngine: From Reactive to Programmatic GUI Agents via State Machine Memory](https://arxiv.org/abs/2602.20502v1) *by Hongbin Zhong et al. (2026-02-24)* - _Existing Graphical User Interface (GUI) agents operate through step-by-step calls to vision language models--taking a screenshot, reasoning about the next action, executing it, then repeating on the new page--resulting in high costs and latency that scale with the number of reasoning steps, and limited accuracy due to no persistent memory of previously visited pages.  We propose ActionEngine, a training-free framework that transitions from reactive execution to programmatic planning through a no..._
- [ ] **[cs.HC]** [Hybrid LLM-Embedded Dialogue Agents for Learner Reflection: Designing Responsive and Theory-Driven Interactions](https://arxiv.org/abs/2602.20486v1) *by Paras Sharma et al. (2026-02-24)* - _Dialogue systems have long supported learner reflections, with theoretically grounded, rule-based designs offering structured scaffolding but often struggling to respond to shifts in engagement. Large Language Models (LLMs), in contrast, can generate context-sensitive responses but are not informed by decades of research on how learning interactions should be structured, raising questions about their alignment with pedagogical theories. This paper presents a hybrid dialogue system that embeds LL..._
- [ ] **[cs.AI]** [Learning to Rewrite Tool Descriptions for Reliable LLM-Agent Tool Use](https://arxiv.org/abs/2602.20426v1) *by Ruocheng Guo et al. (2026-02-23)* - _The performance of LLM-based agents depends not only on the agent itself but also on the quality of the tool interfaces it consumes. While prior work has focused heavily on agent fine-tuning, tool interfaces-including natural language descriptions and parameter schemas-remain largely human-oriented and often become a bottleneck, especially when agents must select from large candidate tool sets. Existing approaches to improving tool interfaces rely on execution traces, which are frequently unavai..._
- [ ] **[cs.AI]** [Implicit Intelligence -- Evaluating Agents on What Users Don't Say](https://arxiv.org/abs/2602.20424v1) *by Ved Sirdeshmukh et al. (2026-02-23)* - _Real-world requests to AI agents are fundamentally underspecified. Natural human communication relies on shared context and unstated constraints that speakers expect listeners to infer. Current agentic benchmarks test explicit instruction-following but fail to evaluate whether agents can reason about implicit requirements spanning accessibility needs, privacy boundaries, catastrophic risks, and contextual constraints. We present Implicit Intelligence, an evaluation framework testing whether AI a..._
- [ ] **[cs.SE]** [Quantifying the Expectation-Realisation Gap for Agentic AI Systems](https://arxiv.org/abs/2602.20292v1) *by Sebastian Lobentanzer (2026-02-23)* - _Agentic AI systems are deployed with expectations of substantial productivity gains, yet rigorous empirical evidence reveals systematic discrepancies between pre-deployment expectations and post-deployment outcomes. We review controlled trials and independent validations across software engineering, clinical documentation, and clinical decision support to quantify this expectation-realisation gap. In software development, experienced developers expected a 24% speedup from AI tools but were slowe..._
- [ ] **[cs.CR]** [Right to History: A Sovereignty Kernel for Verifiable AI Agent Execution](https://arxiv.org/abs/2602.20214v1) *by Jing Zhang (2026-02-23)* - _AI agents increasingly act on behalf of humans, yet no existing system provides a tamper-evident, independently verifiable record of what they did. As regulations such as the EU AI Act begin mandating automatic logging for high-risk AI systems, this gap carries concrete consequences -- especially for agents running on personal hardware, where no centralized provider controls the log. Extending Floridi's informational rights framework from data about individuals to actions performed on their beha..._
- [ ] **[cs.SE]** [CodeHacker: Automated Test Case Generation for Detecting Vulnerabilities in Competitive Programming Solutions](https://arxiv.org/abs/2602.20213v1) *by Jingwei Shi et al. (2026-02-23)* - _The evaluation of Large Language Models (LLMs) for code generation relies heavily on the quality and robustness of test cases. However, existing benchmarks often lack coverage for subtle corner cases, allowing incorrect solutions to pass. To bridge this gap, we propose CodeHacker, an automated agent framework dedicated to generating targeted adversarial test cases that expose latent vulnerabilities in program submissions. Mimicking the hack mechanism in competitive programming, CodeHacker employ..._
- [ ] **[cs.CR]** [OpenPort Protocol: A Security Governance Specification for AI Agent Tool Access](https://arxiv.org/abs/2602.20196v1) *by Genliang Zhu et al. (2026-02-22)* - _AI agents increasingly require direct, structured access to application data and actions, but production deployments still struggle to express and verify the governance properties that matter in practice: least-privilege authorization, controlled write execution, predictable failure handling, abuse resistance, and auditability. This paper introduces OpenPort Protocol (OPP), a governance-first specification for exposing application tools through a secure server-side gateway that is model- and run..._


## 2026-02-24 Êõ¥Êñ∞ 68 ÁØáÊñ∞ËÆ∫Êñá
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-24Ôºö2602.16928 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Discovering Multiagent Learning Algorithms with Large Language Models](https://arxiv.org/abs/2602.16928v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-24Ôºö2602.16666 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Towards a Science of AI Agent Reliability](https://arxiv.org/abs/2602.16666v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-24Ôºö2602.16246 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents](https://arxiv.org/abs/2602.16246v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-24Ôºö2602.16179 ‰ªé v3 Êõ¥Êñ∞Âà∞ v4 - [EnterpriseBench Corecraft: Training Generalizable Agents on High-Fidelity RL Environments](https://arxiv.org/abs/2602.16179v4)
- [ ] **[eess.SY]** [Agentic AI for Scalable and Robust Optical Systems Control](https://arxiv.org/abs/2602.20144v1) *by Zehao Wang et al. (2026-02-23)* - _We present AgentOptics, an agentic AI framework for high-fidelity, autonomous optical system control built on the Model Context Protocol (MCP). AgentOptics interprets natural language tasks and executes protocol-compliant actions on heterogeneous optical devices through a structured tool abstraction layer. We implement 64 standardized MCP tools across 8 representative optical devices and construct a 410-task benchmark to evaluate request understanding, role-aware responses, multi-step coordinati..._
- [ ] **[cs.AI]** [Recurrent Structural Policy Gradient for Partially Observable Mean Field Games](https://arxiv.org/abs/2602.20141v1) *by Clarisse Wibault et al. (2026-02-23)* - _Mean Field Games (MFGs) provide a principled framework for modeling interactions in large population models: at scale, population dynamics become deterministic, with uncertainty entering only through aggregate shocks, or common noise. However, algorithmic progress has been limited since model-free methods are too high variance and exact methods scale poorly. Recent Hybrid Structural Methods (HSMs) use Monte Carlo rollouts for the common noise in combination with exact estimation of the expected ..._
- [ ] **[cs.MA]** [Descent-Guided Policy Gradient for Scalable Cooperative Multi-Agent Learning](https://arxiv.org/abs/2602.20078v1) *by Shan Yang et al. (2026-02-23)* - _Scaling cooperative multi-agent reinforcement learning (MARL) is fundamentally limited by cross-agent noise: when agents share a common reward, the actions of all $N$ agents jointly determine each agent's learning signal, so cross-agent noise grows with $N$. In the policy gradient setting, per-agent gradient estimate variance scales as $Œò(N)$, yielding sample complexity $\mathcal{O}(N/Œµ)$. We observe that many domains -- cloud computing, transportation, power systems -- have differentiable analy..._
- [ ] **[cs.PL]** [The LLMbda Calculus: AI Agents, Conversations, and Information Flow](https://arxiv.org/abs/2602.20064v1) *by Zac Garby et al. (2026-02-23)* - _A conversation with a large language model (LLM) is a sequence of prompts and responses, with each response generated from the preceding conversation. AI agents build such conversations automatically: given an initial human prompt, a planner loop interleaves LLM calls with tool invocations and code execution. This tight coupling creates a new and poorly understood attack surface. A malicious prompt injected into a conversation can compromise later reasoning, trigger dangerous tool calls, or dist..._
- [ ] **[cs.AI]** [Interaction Theater: A case of LLM Agents Interacting at Scale](https://arxiv.org/abs/2602.20059v1) *by Sarath Shekkizhar et al. (2026-02-23)* - _As multi-agent architectures and agent-to-agent protocols proliferate, a fundamental question arises: what actually happens when autonomous LLM agents interact at scale? We study this question empirically using data from Moltbook, an AI-agent-only social platform, with 800K posts, 3.5M comments, and 78K agent profiles. We combine lexical metrics (Jaccard specificity), embedding-based semantic similarity, and LLM-as-judge validation to characterize agent interaction quality. Our findings reveal a..._
- [ ] **[cs.RO]** [To Move or Not to Move: Constraint-based Planning Enables Zero-Shot Generalization for Interactive Navigation](https://arxiv.org/abs/2602.20055v1) *by Apoorva Vashisth et al. (2026-02-23)* - _Visual navigation typically assumes the existence of at least one obstacle-free path between start and goal, which must be discovered/planned by the robot. However, in real-world scenarios, such as home environments and warehouses, clutter can block all routes. Targeted at such cases, we introduce the Lifelong Interactive Navigation problem, where a mobile robot with manipulation abilities can move clutter to forge its own path to complete sequential object- placement tasks - each involving plac..._
- [ ] **[cs.AI]** [CodeCompass: Navigating the Navigation Paradox in Agentic Code Intelligence](https://arxiv.org/abs/2602.20048v1) *by Tarakanath Paipuru (2026-02-23)* - _Modern code intelligence agents operate in contexts exceeding 1 million tokens--far beyond the scale where humans manually locate relevant files. Yet agents consistently fail to discover architecturally critical files when solving real-world coding tasks. We identify the Navigation Paradox: agents perform poorly not due to context limits, but because navigation and retrieval are fundamentally distinct problems. Through 258 automated trials across 30 benchmark tasks on a production FastAPI reposi..._
- [ ] **[cs.CL]** [AgenticSum: An Agentic Inference-Time Framework for Faithful Clinical Text Summarization](https://arxiv.org/abs/2602.20040v1) *by Fahmida Liza Piya et al. (2026-02-23)* - _Large language models (LLMs) offer substantial promise for automating clinical text summarization, yet maintaining factual consistency remains challenging due to the length, noise, and heterogeneity of clinical documentation. We present AgenticSum, an inference-time, agentic framework that separates context selection, generation, verification, and targeted correction to reduce hallucinated content. The framework decomposes summarization into coordinated stages that compress task-relevant context..._
- [ ] **[cs.AI]** [Agents of Chaos](https://arxiv.org/abs/2602.20021v1) *by Natalie Shapira et al. (2026-02-23)* - _We report an exploratory red-teaming study of autonomous language-model-powered agents deployed in a live laboratory environment with persistent memory, email accounts, Discord access, file systems, and shell execution. Over a two-week period, twenty AI researchers interacted with the agents under benign and adversarial conditions. Focusing on failures emerging from the integration of language models with autonomy, tool use, and multi-party communication, we document eleven representative case s..._
- [ ] **[cs.CL]** [Assessing Risks of Large Language Models in Mental Health Support: A Framework for Automated Clinical AI Red Teaming](https://arxiv.org/abs/2602.19948v1) *by Ian Steenstra et al. (2026-02-23)* - _Large Language Models (LLMs) are increasingly utilized for mental health support; however, current safety benchmarks often fail to detect the complex, longitudinal risks inherent in therapeutic dialogue. We introduce an evaluation framework that pairs AI psychotherapists with simulated patient agents equipped with dynamic cognitive-affective models and assesses therapy session simulations against a comprehensive quality of care and risk ontology. We apply this framework to a high-impact test cas..._
- [ ] **[cs.AI]** [Beyond Mimicry: Toward Lifelong Adaptability in Imitation Learning](https://arxiv.org/abs/2602.19930v1) *by Nathan Gavenski et al. (2026-02-23)* - _Imitation learning stands at a crossroads: despite decades of progress, current imitation learning agents remain sophisticated memorisation machines, excelling at replay but failing when contexts shift or goals evolve. This paper argues that this failure is not technical but foundational: imitation learning has been optimised for the wrong objective. We propose a research agenda that redefines success from perfect replay to compositional adaptability. Such adaptability hinges on learning behavio..._
- [ ] **[cs.SE]** [MAS-FIRE: Fault Injection and Reliability Evaluation for LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2602.19843v1) *by Jin Jia et al. (2026-02-23)* - _As LLM-based Multi-Agent Systems (MAS) are increasingly deployed for complex tasks, ensuring their reliability has become a pressing challenge. Since MAS coordinate through unstructured natural language rather than rigid protocols, they are prone to semantic failures (e.g., hallucinations, misinterpreted instructions, and reasoning drift) that propagate silently without raising runtime exceptions. Prevailing evaluation approaches, which measure only end-to-end task success, offer limited insight..._
- [ ] **[cs.AI]** [Meta-Learning and Meta-Reinforcement Learning - Tracing the Path towards DeepMind's Adaptive Agent](https://arxiv.org/abs/2602.19837v1) *by Bj√∂rn Hoppmann et al. (2026-02-23)* - _Humans are highly effective at utilizing prior knowledge to adapt to novel tasks, a capability that standard machine learning models struggle to replicate due to their reliance on task-specific training. Meta-learning overcomes this limitation by allowing models to acquire transferable knowledge from various tasks, enabling rapid adaptation to new challenges with minimal data. This survey provides a rigorous, task-based formalization of meta-learning and meta-reinforcement learning and uses that..._
- [ ] **[cs.AI]** [OpenClaw, Moltbook, and ClawdLab: From Agent-Only Social Networks to Autonomous Scientific Research](https://arxiv.org/abs/2602.19810v1) *by Lukas Weidener et al. (2026-02-23)* - _In January 2026, the open-source agent framework OpenClaw and the agent-only social network Moltbook produced a large-scale dataset of autonomous AI-to-AI interaction, attracting six academic publications within fourteen days. This study conducts a multivocal literature review of that ecosystem and presents ClawdLab, an open-source platform for autonomous scientific research, as a design science response to the architectural failure modes identified. The literature documents emergent collective ..._
- [ ] **[cs.AI]** [SkillOrchestra: Learning to Route Agents via Skill Transfer](https://arxiv.org/abs/2602.19672v1) *by Jiayu Wang et al. (2026-02-23)* - _Compound AI systems promise capabilities beyond those of individual models, yet their success depends critically on effective orchestration. Existing routing approaches face two limitations: (1) input-level routers make coarse query-level decisions that ignore evolving task requirements; (2) RL-trained orchestrators are expensive to adapt and often suffer from routing collapse, repeatedly invoking one strong but costly option in multi-turn scenarios. We introduce SkillOrchestra, a framework for ..._
- [ ] **[cs.LG]** [Representation Stability in a Minimal Continual Learning Agent](https://arxiv.org/abs/2602.19655v1) *by Vishnu Subramanian (2026-02-23)* - _Continual learning systems are increasingly deployed in environments where retraining or reset is infeasible, yet many approaches emphasize task performance rather than the evolution of internal representations over time. In this work, we study a minimal continual learning agent designed to isolate representational dynamics from architectural complexity and optimization objectives. The agent maintains a persistent state vector across executions and incrementally updates it as new textual data is..._
- [ ] **[cs.LG]** [Compositional Planning with Jumpy World Models](https://arxiv.org/abs/2602.19634v1) *by Jesse Farebrother et al. (2026-02-23)* - _The ability to plan with temporal abstractions is central to intelligent decision-making. Rather than reasoning over primitive actions, we study agents that compose pre-trained policies as temporally extended actions, enabling solutions to complex tasks that no constituent alone can solve. Such compositional planning remains elusive as compounding errors in long-horizon predictions make it challenging to estimate the visitation distribution induced by sequencing policies. Motivated by the geomet..._
- [ ] **[cs.AI]** [TAPE: Tool-Guided Adaptive Planning and Constrained Execution in Language Model Agents](https://arxiv.org/abs/2602.19633v1) *by Jongwon Jeong et al. (2026-02-23)* - _Language Model (LM) agents have demonstrated remarkable capabilities in solving tasks that require multiple interactions with the environment. However, they remain vulnerable in environments where a single error often leads to irrecoverable failure, particularly under strict feasibility constraints. We systematically analyze existing agent frameworks, identifying imperfect planning and stochastic execution as the primary causes. To address these challenges, we propose Tool-guided Adaptive Planni..._
- [ ] **[cs.CR]** [Agentic AI as a Cybersecurity Attack Surface: Threats, Exploits, and Defenses in Runtime Supply Chains](https://arxiv.org/abs/2602.19555v1) *by Xiaochong Jiang et al. (2026-02-23)* - _Agentic systems built on large language models (LLMs) extend beyond text generation to autonomously retrieve information and invoke tools. This runtime execution model shifts the attack surface from build-time artifacts to inference-time dependencies, exposing agents to manipulation through untrusted data and probabilistic capability resolution. While prior work has focused on model-level vulnerabilities, security risks emerging from cyclic and interdependent runtime behavior remain fragmented. ..._
- [ ] **[cs.RO]** [Cost-Aware Diffusion Active Search](https://arxiv.org/abs/2602.19538v1) *by Arundhati Banerjee et al. (2026-02-23)* - _Active search for recovering objects of interest through online, adaptive decision making with autonomous agents requires trading off exploration of unknown environments with exploitation of prior observations in the search space. Prior work has proposed information gain and Thompson sampling based myopic, greedy approaches for agents to actively decide query or search locations when the number of targets is unknown. Decision making algorithms in such partially observable environments have also ..._
- [ ] **[cs.CL]** [Pyramid MoA: A Probabilistic Framework for Cost-Optimized Anytime Inference](https://arxiv.org/abs/2602.19509v1) *by Arindam Khaled (2026-02-23)* - _Large Language Models (LLMs) face a persistent trade-off between inference cost and reasoning capability. While "Oracle" models (e.g., Llama-3-70B) achieve state-of-the-art accuracy, they are prohibitively expensive for high-volume deployment. Smaller models (e.g., 8B parameters) are cost-effective but struggle with complex tasks. In this work, we propose "Pyramid MoA", a hierarchical Mixture-of-Agents architecture that uses a lightweight Router to dynamically escalate queries only when necessar..._
- [ ] **[cs.AI]** [Human-Guided Agentic AI for Multimodal Clinical Prediction: Lessons from the AgentDS Healthcare Benchmark](https://arxiv.org/abs/2602.19502v1) *by Lalitha Pranathi Pulavarthy et al. (2026-02-23)* - _Agentic AI systems are increasingly capable of autonomous data science workflows, yet clinical prediction tasks demand domain expertise that purely automated approaches struggle to provide. We investigate how human guidance of agentic AI can improve multimodal clinical prediction, presenting our approach to all three AgentDS Healthcare benchmark challenges: 30-day hospital readmission prediction (Macro-F1 = 0.8986), emergency department cost forecasting (MAE = $465.13), and discharge readiness a..._
- [ ] **[cs.RO]** [Botson: An Accessible and Low-Cost Platform for Social Robotics Research](https://arxiv.org/abs/2602.19491v1) *by Samuel Bellaire et al. (2026-02-23)* - _Trust remains a critical barrier to the effective integration of Artificial Intelligence (AI) into human-centric domains. Disembodied agents, such as voice assistants, often fail to establish trust due to their inability to convey non-verbal social cues. This paper introduces the architecture of Botson: an anthropomorphic social robot powered by a large language model (LLM). Botson was created as a low-cost and accessible platform for social robotics research._
- [ ] **[cs.AI]** [ComplLLM: Fine-tuning LLMs to Discover Complementary Signals for Decision-making](https://arxiv.org/abs/2602.19458v1) *by Ziyang Guo et al. (2026-02-23)* - _Multi-agent decision pipelines can outperform single agent workflows when complementarity holds, i.e., different agents bring unique information to the table to inform a final decision. We propose ComplLLM, a post-training framework based on decision theory that fine-tunes a decision-assistant LLM using complementary information as reward to output signals that complement existing agent decisions. We validate ComplLLM on synthetic and real-world tasks involving domain experts, demonstrating how ..._
- [ ] **[cs.SE]** [When AI Teammates Meet Code Review: Collaboration Signals Shaping the Integration of Agent-Authored Pull Requests](https://arxiv.org/abs/2602.19441v1) *by Costain Nachuma et al. (2026-02-23)* - _Autonomous coding agents increasingly contribute to software development by submitting pull requests on GitHub; yet, little is known about how these contributions integrate into human-driven review workflows. We present a large empirical study of agent-authored pull requests using the public AIDev dataset, examining integration outcomes, resolution speed, and review-time collaboration signals. Using logistic regression with repository-clustered standard errors, we find that reviewer engagement h..._
- [ ] **[cs.AI]** [OptiRepair: Closed-Loop Diagnosis and Repair of Supply Chain Optimization Models with LLM Agents](https://arxiv.org/abs/2602.19439v1) *by Ruicheng Ao et al. (2026-02-23)* - _Problem Definition. Supply chain optimization models frequently become infeasible because of modeling errors. Diagnosis and repair require scarce OR expertise: analysts must interpret solver diagnostics, trace root causes across echelons, and fix formulations without sacrificing operational soundness. Whether AI agents can perform this task remains untested.  Methodology/Results. OptiRepair splits this task into a domain-agnostic feasibility phase (iterative IIS-guided repair of any LP) and a do..._
- [ ] **[cs.LG]** [Stable Deep Reinforcement Learning via Isotropic Gaussian Representations](https://arxiv.org/abs/2602.19373v1) *by Ali Saheb et al. (2026-02-22)* - _Deep reinforcement learning systems often suffer from unstable training dynamics due to non-stationarity, where learning objectives and data distributions evolve over time. We show that under non-stationary targets, isotropic Gaussian embeddings are provably advantageous. In particular, they induce stable tracking of time-varying targets for linear readouts, achieve maximal entropy under a fixed variance budget, and encourage a balanced use of all representational dimensions--all of which enable..._
- [ ] **[cs.MA]** [City Editing: Hierarchical Agentic Execution for Dependency-Aware Urban Geospatial Modification](https://arxiv.org/abs/2602.19326v1) *by Rui Liu et al. (2026-02-22)* - _As cities evolve over time, challenges such as traffic congestion and functional imbalance increasingly necessitate urban renewal through efficient modification of existing plans, rather than complete re-planning. In practice, even minor urban changes require substantial manual effort to redraw geospatial layouts, slowing the iterative planning and decision-making procedure. Motivated by recent advances in agentic systems and multimodal reasoning, we formulate urban renewal as a machine-executab..._
- [ ] **[cs.CL]** [Anatomy of Agentic Memory: Taxonomy and Empirical Analysis of Evaluation and System Limitations](https://arxiv.org/abs/2602.19320v1) *by Dongming Jiang et al. (2026-02-22)* - _Agentic memory systems enable large language model (LLM) agents to maintain state across long interactions, supporting long-horizon reasoning and personalization beyond fixed context windows. Despite rapid architectural development, the empirical foundations of these systems remain fragile: existing benchmarks are often underscaled, evaluation metrics are misaligned with semantic utility, performance varies significantly across backbone models, and system-level costs are frequently overlooked. T..._
- [ ] **[cs.RO]** [Safe and Interpretable Multimodal Path Planning for Multi-Agent Cooperation](https://arxiv.org/abs/2602.19304v1) *by Haojun Shi et al. (2026-02-22)* - _Successful cooperation among decentralized agents requires each agent to quickly adapt its plan to the behavior of other agents. In scenarios where agents cannot confidently predict one another's intentions and plans, language communication can be crucial for ensuring safety. In this work, we focus on path-level cooperation in which agents must adapt their paths to one another in order to avoid collisions or perform physical collaboration such as joint carrying. In particular, we propose a safe ..._
- [ ] **[cs.AI]** [ALPACA: A Reinforcement Learning Environment for Medication Repurposing and Treatment Optimization in Alzheimer's Disease](https://arxiv.org/abs/2602.19298v1) *by Nolan Brady et al. (2026-02-22)* - _Evaluating personalized, sequential treatment strategies for Alzheimer's disease (AD) using clinical trials is often impractical due to long disease horizons and substantial inter-patient heterogeneity. To address these constraints, we present the Alzheimer's Learning Platform for Adaptive Care Agents (ALPACA), an open-source, Gym-compatible reinforcement learning (RL) environment for systematically exploring personalized treatment strategies using existing therapies. ALPACA is powered by the Co..._
- [ ] **[cs.AI]** [Proximity-Based Multi-Turn Optimization: Practical Credit Assignment for LLM Agent Training](https://arxiv.org/abs/2602.19225v1) *by Yangyi Fang et al. (2026-02-22)* - _Multi-turn LLM agents are becoming pivotal to production systems, spanning customer service automation, e-commerce assistance, and interactive task management, where accurately distinguishing high-value informative signals from stochastic noise is critical for sample-efficient training. In real-world scenarios, a failure in a trivial task may reflect random instability, whereas success in a high-difficulty task signifies a genuine capability breakthrough. Yet, existing group-based policy optimiz..._
- [ ] **[cs.AI]** [Characterizing MARL for Energy Control: A Multi-KPI Benchmark on the CityLearn Environment](https://arxiv.org/abs/2602.19223v1) *by Aymen Khouja et al. (2026-02-22)* - _The optimization of urban energy systems is crucial for the advancement of sustainable and resilient smart cities, which are becoming increasingly complex with multiple decision-making units. To address scalability and coordination concerns, Multi-Agent Reinforcement Learning (MARL) is a promising solution. This paper addresses the imperative need for comprehensive and reliable benchmarking of MARL algorithms on energy management tasks. CityLearn is used as a case study environment because it re..._
- [ ] **[cs.AI]** [Agentic Problem Frames: A Systematic Approach to Engineering Reliable Domain Agents](https://arxiv.org/abs/2602.19065v1) *by Chanjin Park (2026-02-22)* - _Large Language Models (LLMs) are evolving into autonomous agents, yet current "frameless" development--relying on ambiguous natural language without engineering blueprints--leads to critical risks such as scope creep and open-loop failures. To ensure industrial-grade reliability, this study proposes Agentic Problem Frames (APF), a systematic engineering framework that shifts focus from internal model intelligence to the structured interaction between the agent and its environment.  The APF estab..._
- [ ] **[cs.AI]** [MagicAgent: Towards Generalized Agent Planning](https://arxiv.org/abs/2602.19000v1) *by Xuhui Ren et al. (2026-02-22)* - _The evolution of Large Language Models (LLMs) from passive text processors to autonomous agents has established planning as a core component of modern intelligence. However, achieving generalized planning remains elusive, not only by the scarcity of high-quality interaction data but also by inherent conflicts across heterogeneous planning tasks. These challenges result in models that excel at isolated tasks yet struggle to generalize, while existing multi-task training attempts suffer from gradi..._
- [ ] **[cs.AI]** [Benchmark Test-Time Scaling of General LLM Agents](https://arxiv.org/abs/2602.18998v1) *by Xiaochuan Li et al. (2026-02-22)* - _LLM agents are increasingly expected to function as general-purpose systems capable of resolving open-ended user requests. While existing benchmarks focus on domain-aware environments for developing specialized agents, evaluating general-purpose agents requires more realistic settings that challenge them to operate across multiple skills and tools within a unified environment. We introduce General AgentBench, a benchmark that provides such a unified framework for evaluating general LLM agents ac..._
- [ ] **[cs.AI]** [Quantifying Automation Risk in High-Automation AI Systems: A Bayesian Framework for Failure Propagation and Optimal Oversight](https://arxiv.org/abs/2602.18986v1) *by Vishal Srivastava et al. (2026-02-22)* - _Organizations across finance, healthcare, transportation, content moderation, and critical infrastructure are rapidly deploying highly automated AI systems, yet they lack principled methods to quantify how increasing automation amplifies harm when failures occur. We propose a parsimonious Bayesian risk decomposition expressing expected loss as the product of three terms: the probability of system failure, the conditional probability that a failure propagates into harm given the automation level,..._
- [ ] **[cs.AI]** [InfEngine: A Self-Verifying and Self-Optimizing Intelligent Engine for Infrared Radiation Computing](https://arxiv.org/abs/2602.18985v1) *by Kun Ding et al. (2026-02-22)* - _Infrared radiation computing underpins advances in climate science, remote sensing and spectroscopy but remains constrained by manual workflows. We introduce InfEngine, an autonomous intelligent computational engine designed to drive a paradigm shift from human-led orchestration to collaborative automation. It integrates four specialized agents through two core innovations: self-verification, enabled by joint solver-evaluator debugging, improves functional correctness and scientific plausibility..._
- [ ] **[cs.AI]** [How Far Can We Go with Pixels Alone? A Pilot Study on Screen-Only Navigation in Commercial 3D ARPGs](https://arxiv.org/abs/2602.18981v1) *by Kaijie Xu et al. (2026-02-21)* - _Modern 3D game levels rely heavily on visual guidance, yet the navigability of level layouts remains difficult to quantify. Prior work either simulates play in simplified environments or analyzes static screenshots for visual affordances, but neither setting faithfully captures how players explore complex, real-world game levels. In this paper, we build on an existing open-source visual affordance detector and instantiate a screen-only exploration and navigation agent that operates purely from v..._
- [ ] **[cs.AI]** [When Do LLM Preferences Predict Downstream Behavior?](https://arxiv.org/abs/2602.18971v1) *by Katarina Slama et al. (2026-02-21)* - _Preference-driven behavior in LLMs may be a necessary precondition for AI misalignment such as sandbagging: models cannot strategically pursue misaligned goals unless their behavior is influenced by their preferences. Yet prior work has typically prompted models explicitly to act in specific ways, leaving unclear whether observed behaviors reflect instruction-following capabilities vs underlying model preferences. Here we test whether this precondition for misalignment is present. Using entity p..._
- [ ] **[cs.AI]** [Robust and Efficient Tool Orchestration via Layered Execution Structures with Reflective Correction](https://arxiv.org/abs/2602.18968v1) *by Tao Zhe et al. (2026-02-21)* - _Tool invocation is a core capability of agentic systems, yet failures often arise not from individual tool calls but from how multiple tools are organized and executed together. Existing approaches tightly couple tool execution with stepwise language reasoning or explicit planning, leading to brittle behavior and high execution overhead. To overcome these limitations, we revisit tool invocation from the perspective of tool orchestration. Our key insight is that effective orchestration does not r..._
- [ ] **[cs.HC]** [NeuroWise: A Multi-Agent LLM "Glass-Box" System for Practicing Double-Empathy Communication with Autistic Partners](https://arxiv.org/abs/2602.18962v1) *by Albert Tang et al. (2026-02-21)* - _The double empathy problem frames communication difficulties between neurodivergent and neurotypical individuals as arising from mutual misunderstanding, yet most interventions focus on autistic individuals. We present NeuroWise, a multi-agent LLM-based coaching system that supports neurotypical users through stress visualization, interpretation of internal experiences, and contextual guidance. In a between-subjects study (N=30), NeuroWise was rated as helpful by all participants and showed a si..._
- [ ] **[cs.AI]** [(Perlin) Noise as AI coordinator](https://arxiv.org/abs/2602.18947v1) *by Kaijie Xu et al. (2026-02-21)* - _Large scale control of nonplayer agents is central to modern games, while production systems still struggle to balance several competing goals: locally smooth, natural behavior, and globally coordinated variety across space and time. Prior approaches rely on handcrafted rules or purely stochastic triggers, which either converge to mechanical synchrony or devolve into uncorrelated noise that is hard to tune. Continuous noise signals such as Perlin noise are well suited to this gap because they pr..._
- [ ] **[cs.AI]** [DREAM: Deep Research Evaluation with Agentic Metrics](https://arxiv.org/abs/2602.18940v1) *by Elad Ben Avraham et al. (2026-02-21)* - _Deep Research Agents generate analyst-grade reports, yet evaluating them remains challenging due to the absence of a single ground truth and the multidimensional nature of research quality. Recent benchmarks propose distinct methodologies, yet they suffer from the Mirage of Synthesis, where strong surface-level fluency and citation alignment can obscure underlying factual and reasoning defects. We characterize this gap by introducing a taxonomy across four verticals that exposes a critical capab..._
- [ ] **[cs.CL]** [Why Agent Caching Fails and How to Fix It: Structured Intent Canonicalization with Few-Shot Learning](https://arxiv.org/abs/2602.18922v1) *by Abhinaba Basu (2026-02-21)* - _Personal AI agents incur substantial cost via repeated LLM calls. We show existing caching methods fail: GPTCache achieves 37.9% accuracy on real benchmarks; APC achieves 0-12%. The root cause is optimizing for the wrong property -- cache effectiveness requires key consistency and precision,  not classification accuracy. We observe cache-key evaluation reduces to clustering evaluation and apply V-measure decomposition to separate these on n=8,682 points across MASSIVE, BANKING77, CLINC150, and N..._
- [ ] **[cs.CL]** [DeepInnovator: Triggering the Innovative Capabilities of LLMs](https://arxiv.org/abs/2602.18920v1) *by Tianyu Fan et al. (2026-02-21)* - _The application of Large Language Models (LLMs) in accelerating scientific discovery has garnered increasing attention, with a key focus on constructing research agents endowed with innovative capability, i.e., the ability to autonomously generate novel and significant research ideas. Existing approaches predominantly rely on sophisticated prompt engineering and lack a systematic training paradigm. To address this, we propose DeepInnovator, a training framework designed to trigger the innovative..._
- [ ] **[cs.MA]** [Adaptive Collaboration of Arena-Based Argumentative LLMs for Explainable and Contestable Legal Reasoning](https://arxiv.org/abs/2602.18916v1) *by Hoang-Loc Cao et al. (2026-02-21)* - _Legal reasoning requires not only high accuracy but also the ability to justify decisions through verifiable and contestable arguments. However, existing Large Language Model (LLM) approaches, such as Chain-of-Thought (CoT) and Retrieval-Augmented Generation (RAG), often produce unstructured explanations that lack a formal mechanism for verification or user intervention. To address this limitation, we propose Adaptive Collaboration of Argumentative LLMs (ACAL), a neuro-symbolic framework that in..._
- [ ] **[cs.CY]** [Orchestrating LLM Agents for Scientific Research: A Pilot Study of Multiple Choice Question (MCQ) Generation and Evaluation](https://arxiv.org/abs/2602.18891v1) *by Yuan An (2026-02-21)* - _Advances in large language models (LLMs) are rapidly transforming scientific work, yet empirical evidence on how these systems reshape research activities remains limited. We report a mixed-methods pilot evaluation of an AI-orchestrated research workflow in which a human researcher coordinated multiple LLM-based agents to perform data extraction, corpus construction, artifact generation, and artifact evaluation. Using the generation and assessment of multiple-choice questions (MCQs) as a testbed..._
- [ ] **[cs.RO]** [When the Inference Meets the Explicitness or Why Multimodality Can Make Us Forget About the Perfect Predictor](https://arxiv.org/abs/2602.18850v1) *by J. E. Dom√≠nguez-Vidal et al. (2026-02-21)* - _Although in the literature it is common to find predictors and inference systems that try to predict human intentions, the uncertainty of these models due to the randomness of human behavior has led some authors to start advocating the use of communication systems that explicitly elicit human intention. In this work, it is analyzed the use of four different communication systems with a human-robot collaborative object transportation task as experimental testbed: two intention predictors (one bas..._
- [ ] **[cs.HC]** [OpenClaw AI Agents as Informal Learners at Moltbook: Characterizing an Emergent Learning Community at Scale](https://arxiv.org/abs/2602.18832v1) *by Eason Chen et al. (2026-02-21)* - _Informal learning communities have been called the "other Massive Open Online C" in Learning@Scale research, yet remain understudied compared to MOOCs. We present the first empirical study of a large-scale informal learning community composed entirely of AI agents. Moltbook, a social network exclusively for AI agents powered by autonomous agent frameworks such as OpenClaw, grew to over 2.8 million registered agents in three weeks. Analyzing 231,080 non-spam posts across three phases of community..._
- [ ] **[cs.SI]** [UniRank: A Multi-Agent Calibration Pipeline for Estimating University Rankings from Anonymized Bibliometric Signals](https://arxiv.org/abs/2602.18824v1) *by Pedram Riyazimehr et al. (2026-02-21)* - _We present UniRank, a multi-agent LLM pipeline that estimates university positions across global ranking systems using only publicly available bibliometric data from OpenAlex and Semantic Scholar. The system employs a three-stage architecture: (a) zero-shot estimation from anonymized institutional metrics, (b) per-system tool-augmented calibration against real ranked universities, and (c) final synthesis. Critically, institutions are anonymized -- names, countries, DOIs, paper titles, and collab..._
- [ ] **[cs.DC]** [Carbon-aware decentralized dynamic task offloading in MIMO-MEC networks via multi-agent reinforcement learning](https://arxiv.org/abs/2602.18797v1) *by Mubshra Zulfiqar et al. (2026-02-21)* - _Massive internet of things microservices require integrating renewable energy harvesting into mobile edge computing (MEC) for sustainable eScience infrastructures. Spatiotemporal mismatches between stochastic task arrivals and intermittent green energy along with complex inter-user interference in multi-antenna (MIMO) uplinks complicate real-time resource management. Traditional centralized optimization and off-policy reinforcement learning struggle with scalability and signaling overhead in den..._
- [ ] **[cs.AI]** [LAMMI-Pathology: A Tool-Centric Bottom-Up LVLM-Agent Framework for Molecularly Informed Medical Intelligence in Pathology](https://arxiv.org/abs/2602.18773v1) *by Haoyang Su et al. (2026-02-21)* - _The emergence of tool-calling-based agent systems introduces a more evidence-driven paradigm for pathology image analysis in contrast to the coarse-grained text-image diagnostic approaches. With the recent large-scale experimental adoption of spatial transcriptomics technologies, molecularly validated pathological diagnosis is becoming increasingly open and accessible. In this work, we propose LAMMI-Pathology (LVLM-Agent System for Molecularly Informed Medical Intelligence in Pathology), a scala..._
- [ ] **[cs.AI]** [The Convergence of Schema-Guided Dialogue Systems and the Model Context Protocol](https://arxiv.org/abs/2602.18764v1) *by Andreas Schlapbach (2026-02-21)* - _This paper establishes a fundamental convergence: Schema-Guided Dialogue (SGD) and the Model Context Protocol (MCP) represent two manifestations of a unified paradigm for deterministic, auditable LLM-agent interaction. SGD, designed for dialogue-based API discovery (2019), and MCP, now the de facto standard for LLM-tool integration, share the same core insight -- that schemas can encode not just tool signatures but operational constraints and reasoning guidance. By analyzing this convergence, we..._
- [ ] **[cs.LG]** [HONEST-CAV: Hierarchical Optimization of Network Signals and Trajectories for Connected and Automated Vehicles with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.18740v1) *by Ziyan Zhang et al. (2026-02-21)* - _This study presents a hierarchical, network-level traffic flow control framework for mixed traffic consisting of Human-driven Vehicles (HVs), Connected and Automated Vehicles (CAVs). The framework jointly optimizes vehicle-level eco-driving behaviors and intersection-level traffic signal control to enhance overall network efficiency and decrease energy consumption. A decentralized Multi-Agent Reinforcement Learning (MARL) approach by Value Decomposition Network (VDN) manages cycle-based traffic ..._
- [ ] **[cs.CL]** [Rethinking Retrieval-Augmented Generation as a Cooperative Decision-Making Problem](https://arxiv.org/abs/2602.18734v1) *by Lichang Song et al. (2026-02-21)* - _Retrieval-Augmented Generation (RAG) has demonstrated strong effectiveness in knowledge-intensive tasks by grounding language generation in external evidence. Despite its success, many existing RAG systems are built based on a ranking-centric, asymmetric dependency paradigm, where the generation quality of the generator is highly dependent on reranking results of the reranker. To overcome this limitation, we reformulate RAG as a cooperative multi-agent decision-making problem and propose Coopera..._
- [ ] **[cs.AI]** [Beyond Description: A Multimodal Agent Framework for Insightful Chart Summarization](https://arxiv.org/abs/2602.18731v1) *by Yuhang Bai et al. (2026-02-21)* - _Chart summarization is crucial for enhancing data accessibility and the efficient consumption of information. However, existing methods, including those with Multimodal Large Language Models (MLLMs), primarily focus on low-level data descriptions and often fail to capture the deeper insights which are the fundamental purpose of data visualization. To address this challenge, we propose Chart Insight Agent Flow, a plan-and-execute multi-agent framework effectively leveraging the perceptual and rea..._
- [ ] **[cs.RO]** [Temporal Action Representation Learning for Tactical Resource Control and Subsequent Maneuver Generation](https://arxiv.org/abs/2602.18716v1) *by Hoseong Jung et al. (2026-02-21)* - _Autonomous robotic systems should reason about resource control and its impact on subsequent maneuvers, especially when operating with limited energy budgets or restricted sensing. Learning-based control is effective in handling complex dynamics and represents the problem as a hybrid action space unifying discrete resource usage and continuous maneuvers. However, prior works on hybrid action space have not sufficiently captured the causal dependencies between resource usage and maneuvers. They h..._
- [ ] **[cs.AI]** [Many AI Analysts, One Dataset: Navigating the Agentic Data Science Multiverse](https://arxiv.org/abs/2602.18710v1) *by Martin Bertran et al. (2026-02-21)* - _The conclusions of empirical research depend not only on data but on a sequence of analytic decisions that published results seldom make explicit. Past ``many-analyst" studies have demonstrated this: independent teams testing the same hypothesis on the same dataset regularly reach conflicting conclusions. But such studies require months of coordination among dozens of research groups and are therefore rarely conducted. In this work, we show that fully autonomous AI analysts built on large langua..._
- [ ] **[cs.MA]** [EDU-MATRIX: A Society-Centric Generative Cognitive Digital Twin Architecture for Secondary Education](https://arxiv.org/abs/2602.18705v1) *by Wenjing Zhai et al. (2026-02-21)* - _Existing multi-agent simulations often suffer from the "Agent-Centric Paradox": rules are hard-coded into individual agents, making complex social dynamics rigid and difficult to align with educational values. This paper presents EDU-MATRIX, a society-centric generative cognitive digital twin architecture that shifts the paradigm from simulating "people" to simulating a "social space with a gravitational field." We introduce three architectural contributions: (1) An Environment Context Injection..._
- [ ] **[cs.MA]** [NutriOrion: A Hierarchical Multi-Agent Framework for Personalized Nutrition Intervention Grounded in Clinical Guidelines](https://arxiv.org/abs/2602.18650v1) *by Junwei Wu et al. (2026-02-20)* - _Personalized nutrition intervention for patients with multimorbidity is critical for improving health outcomes, yet remains challenging because it requires the simultaneous integration of heterogeneous clinical conditions, medications, and dietary guidelines. Single-agent large language models (LLMs) often suffer from context overload and attention dilution when processing such high-dimensional patient profiles. We introduce NutriOrion, a hierarchical multi-agent framework with a parallel-then-s..._
- [ ] **[cs.AI]** [Decoding ML Decision: An Agentic Reasoning Framework for Large-Scale Ranking System](https://arxiv.org/abs/2602.18640v1) *by Longfei Yun et al. (2026-02-20)* - _Modern large-scale ranking systems operate within a sophisticated landscape of competing objectives, operational constraints, and evolving product requirements. Progress in this domain is increasingly bottlenecked by the engineering context constraint: the arduous process of translating ambiguous product intent into reasonable, executable, verifiable hypotheses, rather than by modeling techniques alone. We present GEARS (Generative Engine for Agentic Ranking Systems), a framework that reframes r..._
- [ ] **[cs.AI]** [Hierarchical Reward Design from Language: Enhancing Alignment of Agent Behavior with Human Specifications](https://arxiv.org/abs/2602.18582v1) *by Zhiqin Qian et al. (2026-02-20)* - _When training artificial intelligence (AI) to perform tasks, humans often care not only about whether a task is completed but also how it is performed. As AI agents tackle increasingly complex tasks, aligning their behavior with human-provided specifications becomes critical for responsible AI deployment. Reward design provides a direct channel for such alignment by translating human expectations into reward functions that guide reinforcement learning (RL). However, existing methods are often to..._
- [ ] **[cs.SE]** [Debug2Fix: Supercharging Coding Agents with Interactive Debugging Capabilities](https://arxiv.org/abs/2602.18571v1) *by Spandan Garg et al. (2026-02-20)* - _While significant progress has been made in automating various aspects of software development through coding agents, there is still significant room for improvement in their bug fixing capabilities. Debugging and investigation of runtime behavior remains largely a manual, developer-driven process. Popular coding agents typically rely on either static analysis of the code or iterative test-fix cycles, which is akin to trial and error debugging. We posit that there is a wealth of rich runtime inf..._


## 2026-02-23 Êõ¥Êñ∞ 25 ÁØáÊñ∞ËÆ∫Êñá
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-23Ôºö2602.17037 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Wink: Recovering from Misbehaviors in Coding Agents](https://arxiv.org/abs/2602.17037v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-23Ôºö2602.16898 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [MALLVI: A Multi-Agent Framework for Integrated Generalized Robotics Manipulation](https://arxiv.org/abs/2602.16898v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-23Ôºö2602.16653 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments](https://arxiv.org/abs/2602.16653v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-23Ôºö2602.16179 ‰ªé v2 Êõ¥Êñ∞Âà∞ v3 - [EnterpriseBench Corecraft: Training Generalizable Agents on High-Fidelity RL Environments](https://arxiv.org/abs/2602.16179v3)
- [ ] **[cs.GR]** [Robo-Saber: Generating and Simulating Virtual Reality Players](https://arxiv.org/abs/2602.18319v1) *by Nam Hee Kim et al. (2026-02-20)* - _We present the first motion generation system for playtesting virtual reality (VR) games. Our player model generates VR headset and handheld controller movements from in-game object arrangements, guided by style exemplars and aligned to maximize simulated gameplay score. We train on the large BOXRR-23 dataset and apply our framework on the popular VR game Beat Saber. The resulting model Robo-Saber produces skilled gameplay and captures diverse player behaviors, mirroring the skill levels and mov..._
- [ ] **[cs.AI]** [Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies](https://arxiv.org/abs/2602.18291v1) *by Zhuoran Li et al. (2026-02-20)* - _Online Multi-Agent Reinforcement Learning (MARL) is a prominent framework for efficient agent coordination. Crucially, enhancing policy expressiveness is pivotal for achieving superior performance. Diffusion-based generative models are well-positioned to meet this demand, having demonstrated remarkable expressiveness and multimodal representation in image generation and offline settings. Yet, their potential in online MARL remains largely under-explored. A major obstacle is that the intractable ..._
- [ ] **[cs.LG]** [PRISM: Parallel Reward Integration with Symmetry for MORL](https://arxiv.org/abs/2602.18277v1) *by Finn van der Knaap et al. (2026-02-20)* - _This work studies heterogeneous Multi-Objective Reinforcement Learning (MORL), where objectives can differ sharply in temporal frequency. Such heterogeneity allows dense objectives to dominate learning, while sparse long-horizon rewards receive weak credit assignment, leading to poor sample efficiency. We propose a Parallel Reward Integration with Symmetry (PRISM) algorithm that enforces reflectional symmetry as an inductive bias in aligning reward channels. PRISM introduces ReSymNet, a theory-m..._
- [ ] **[cs.LG]** [[Re] Benchmarking LLM Capabilities in Negotiation through Scoreable Games](https://arxiv.org/abs/2602.18230v1) *by Jorge Carrasco Pollo et al. (2026-02-20)* - _Large Language Models (LLMs) demonstrate significant potential in multi-agent negotiation tasks, yet evaluation in this domain remains challenging due to a lack of robust and generalizable benchmarks. Abdelnabi et al. (2024) introduce a negotiation benchmark based on Scoreable Games, with the aim of developing a highly complex and realistic evaluation framework for LLMs. Our work investigates the reproducibility of claims in their benchmark, and provides a deeper understanding of its usability a..._
- [ ] **[cs.CR]** [Can AI Lower the Barrier to Cybersecurity? A Human-Centered Mixed-Methods Study of Novice CTF Learning](https://arxiv.org/abs/2602.18172v1) *by Cathrin Schachner et al. (2026-02-20)* - _Capture-the-Flag (CTF) competitions serve as gateways into offensive cybersecurity, yet they often present steep barriers for novices due to complex toolchains and opaque workflows. Recently, agentic AI frameworks for cybersecurity promise to lower these barriers by automating and coordinating penetration testing tasks. However, their role in shaping novice learning remains underexplored.  We present a human-centered, mixed-methods case study examining how agentic AI frameworks -- here Cybersecu..._
- [ ] **[cs.CL]** [Agentic Adversarial QA for Improving Domain-Specific LLMs](https://arxiv.org/abs/2602.18137v1) *by Vincent Grari et al. (2026-02-20)* - _Large Language Models (LLMs), despite extensive pretraining on broad internet corpora, often struggle to adapt effectively to specialized domains. There is growing interest in fine-tuning these models for such domains; however, progress is constrained by the scarcity and limited coverage of high-quality, task-relevant data. To address this, synthetic data generation methods such as paraphrasing or knowledge extraction are commonly applied. Although these approaches excel at factual recall and co..._
- [ ] **[cs.CL]** [Towards More Standardized AI Evaluation: From Models to Agents](https://arxiv.org/abs/2602.18029v1) *by Ali El Filali et al. (2026-02-20)* - _Evaluation is no longer a final checkpoint in the machine learning lifecycle. As AI systems evolve from static models to compound, tool-using agents, evaluation becomes a core control function. The question is no longer "How good is the model?" but "Can we trust the system to behave as intended, under change, at scale?". Yet most evaluation practices remain anchored in assumptions inherited from the model-centric era: static benchmarks, aggregate scores, and one-off success criteria. This paper ..._
- [ ] **[cs.MA]** [Mean-Field Reinforcement Learning without Synchrony](https://arxiv.org/abs/2602.18026v1) *by Shan Yang (2026-02-20)* - _Mean-field reinforcement learning (MF-RL) scales multi-agent RL to large populations by reducing each agent's dependence on others to a single summary statistic -- the mean action. However, this reduction requires every agent to act at every time step; when some agents are idle, the mean action is simply undefined. Addressing asynchrony therefore requires a different summary statistic -- one that remains defined regardless of which agents act. The population distribution $Œº\in Œî(\mathcal{O})$ --..._
- [ ] **[cs.LG]** [NIMMGen: Learning Neural-Integrated Mechanistic Digital Twins with LLMs](https://arxiv.org/abs/2602.18008v1) *by Zihan Guan et al. (2026-02-20)* - _Mechanistic models encode scientific knowledge about dynamical systems and are widely used in downstream scientific and policy applications. Recent work has explored LLM-based agentic frameworks to automatically construct mechanistic models from data; however, existing problem settings substantially oversimplify real-world conditions, leaving it unclear whether LLM-generated mechanistic models are reliable in practice. To address this gap, we introduce the Neural-Integrated Mechanistic Modeling ..._
- [ ] **[cs.HC]** [Aurora: Neuro-Symbolic AI Driven Advising Agent](https://arxiv.org/abs/2602.17999v1) *by Lorena Amanda Quincoso Lugones et al. (2026-02-20)* - _Academic advising in higher education is under severe strain, with advisor-to-student ratios commonly exceeding 300:1. These structural bottlenecks limit timely access to guidance, increase the risk of delayed graduation, and contribute to inequities in student support. We introduce Aurora, a modular neuro-symbolic advising agent that unifies retrieval-augmented generation (RAG), symbolic reasoning, and normalized curricular databases to deliver policy-compliant, verifiable recommendations at sc..._
- [ ] **[cs.AI]** [WorkflowPerturb: Calibrated Stress Tests for Evaluating Multi-Agent Workflow Metrics](https://arxiv.org/abs/2602.17990v1) *by Madhav Kanda et al. (2026-02-20)* - _LLM-based systems increasingly generate structured workflows for complex tasks. In practice, automatic evaluation of these workflows is difficult, because metric scores are often not calibrated, and score changes do not directly communicate the severity of workflow degradation. We introduce WorkflowPerturb, a controlled benchmark for studying workflow evaluation metrics. It works by applying realistic, controlled perturbations to golden workflows. WorkflowPerturb contains 4,973 golden workflows ..._
- [ ] **[cs.LG]** [Learning Optimal and Sample-Efficient Decision Policies with Guarantees](https://arxiv.org/abs/2602.17978v1) *by Daqian Shao (2026-02-20)* - _The paradigm of decision-making has been revolutionised by reinforcement learning and deep learning. Although this has led to significant progress in domains such as robotics, healthcare, and finance, the use of RL in practice is challenging, particularly when learning decision policies in high-stakes applications that may require guarantees. Traditional RL algorithms rely on a large number of online interactions with the environment, which is problematic in scenarios where online interactions a..._
- [ ] **[cs.LG]** [Memory-Based Advantage Shaping for LLM-Guided Reinforcement Learning](https://arxiv.org/abs/2602.17931v1) *by Narjes Nourzad et al. (2026-02-20)* - _In environments with sparse or delayed rewards, reinforcement learning (RL) incurs high sample complexity due to the large number of interactions needed for learning. This limitation has motivated the use of large language models (LLMs) for subgoal discovery and trajectory guidance. While LLMs can support exploration, frequent reliance on LLM calls raises concerns about scalability and reliability. We address these challenges by constructing a memory graph that encodes subgoals and trajectories ..._
- [ ] **[cs.LG]** [MIRA: Memory-Integrated Reinforcement Learning Agent with Limited LLM Guidance](https://arxiv.org/abs/2602.17930v1) *by Narjes Nourzad et al. (2026-02-20)* - _Reinforcement learning (RL) agents often suffer from high sample complexity in sparse or delayed reward settings due to limited prior structure. Large language models (LLMs) can provide subgoal decompositions, plausible trajectories, and abstract priors that facilitate early learning. However, heavy reliance on LLM supervision introduces scalability constraints and dependence on potentially unreliable signals. We propose MIRA (Memory-Integrated Reinforcement Learning Agent), which incorporates a..._
- [ ] **[cs.DB]** [From Lossy to Verified: A Provenance-Aware Tiered Memory for Agents](https://arxiv.org/abs/2602.17913v1) *by Qiming Zhu et al. (2026-02-20)* - _Long-horizon agents often compress interaction histories into write-time summaries. This creates a fundamental write-before-query barrier: compression decisions are made before the system knows what a future query will hinge on. As a result, summaries can cause unverifiable omissions -- decisive constraints (e.g., allergies) may be dropped, leaving the agent unable to justify an answer with traceable evidence. Retaining raw logs restores an authoritative source of truth, but grounding on raw log..._
- [ ] **[cs.AI]** [Alignment in Time: Peak-Aware Orchestration for Long-Horizon Agentic Systems](https://arxiv.org/abs/2602.17910v1) *by Hanjing Shi et al. (2026-02-20)* - _Traditional AI alignment primarily focuses on individual model outputs; however, autonomous agents in long-horizon workflows require sustained reliability across entire interaction trajectories. We introduce APEMO (Affect-aware Peak-End Modulation for Orchestration), a runtime scheduling layer that optimizes computational allocation under fixed budgets by operationalizing temporal-affective signals. Instead of modifying model weights, APEMO detects trajectory instability through behavioral proxi..._
- [ ] **[cs.AI]** [El Agente Gr√°fico: Structured Execution Graphs for Scientific Agents](https://arxiv.org/abs/2602.17902v1) *by Jiaru Bai et al. (2026-02-19)* - _Large language models (LLMs) are increasingly used to automate scientific workflows, yet their integration with heterogeneous computational tools remains ad hoc and fragile. Current agentic approaches often rely on unstructured text to manage context and coordinate execution, generating often overwhelming volumes of information that may obscure decision provenance and hinder auditability. In this work, we present El Agente Gr√°fico, a single-agent framework that embeds LLM-driven decision-making ..._
- [ ] **[cs.MA]** [MultiVer: Zero-Shot Multi-Agent Vulnerability Detection](https://arxiv.org/abs/2602.17875v1) *by Shreshth Rajan (2026-02-19)* - _We present MultiVer, a zero-shot multi-agent system for vulnerability detection that achieves state-of-the-art recall without fine-tuning. A four-agent ensemble (security, correctness, performance, style) with union voting achieves 82.7% recall on PyVul, exceeding fine-tuned GPT-3.5 (81.3%) by 1.4 percentage points -- the first zeroshot system to surpass fine-tuned performance on this benchmark. On SecurityEval, the same architecture achieves 91.7% detection rate, matching specialized systems. T..._
- [ ] **[cs.HC]** [Mind the Style: Impact of Communication Style on Human-Chatbot Interaction](https://arxiv.org/abs/2602.17850v1) *by Erik Derner et al. (2026-02-19)* - _Conversational agents increasingly mediate everyday digital interactions, yet the effects of their communication style on user experience and task success remain unclear. Addressing this gap, we describe the results of a between-subject user study where participants interact with one of two versions of a chatbot called NAVI which assists users in an interactive map-based 2D navigation task. The two chatbot versions differ only in communication style: one is friendly and supportive, while the oth..._
- [ ] **[cs.CY]** [The 2025 AI Agent Index: Documenting Technical and Safety Features of Deployed Agentic AI Systems](https://arxiv.org/abs/2602.17753v1) *by Leon Staufer et al. (2026-02-19)* - _Agentic AI systems are increasingly capable of performing professional and personal tasks with limited human involvement. However, tracking these developments is difficult because the AI agent ecosystem is complex, rapidly evolving, and inconsistently documented, posing obstacles to both researchers and policymakers. To address these challenges, this paper presents the 2025 AI Agent Index. The Index documents information regarding the origins, design, capabilities, ecosystem, and safety features..._
- [ ] **[cs.SE]** [Five Fatal Assumptions: Why T-Shirt Sizing Systematically Fails for AI Projects](https://arxiv.org/abs/2602.17734v1) *by Raja Soundaramourty et al. (2026-02-18)* - _Agile estimation techniques, particularly T-shirt sizing, are widely used in software development for their simplicity and utility in scoping work. However, when we apply these methods to artificial intelligence initiatives -- especially those involving large language models (LLMs) and multi-agent systems -- the results can be systematically misleading. This paper shares an evidence-backed analysis of five foundational assumptions we often make during T-shirt sizing. While these assumptions usua..._


## 2026-02-20 Êõ¥Êñ∞ 51 ÁØáÊñ∞ËÆ∫Êñá
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-20Ôºö2602.16708 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Policy Compiler for Secure Agentic Systems](https://arxiv.org/abs/2602.16708v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-20Ôºö2602.16699 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents](https://arxiv.org/abs/2602.16699v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-20Ôºö2602.16444 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [RoboGene: Boosting VLA Pre-training via Diversity-Driven Agentic Framework for Real-World Task Generation](https://arxiv.org/abs/2602.16444v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-20Ôºö2602.16179 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [EnterpriseBench Corecraft: Training Generalizable Agents on High-Fidelity RL Environments](https://arxiv.org/abs/2602.16179v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-20Ôºö2602.15909 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Resp-Agent: An Agent-Based System for Multimodal Respiratory Sound Generation and Disease Diagnosis](https://arxiv.org/abs/2602.15909v2)
- [ ] **[cs.LG]** [FAMOSE: A ReAct Approach to Automated Feature Discovery](https://arxiv.org/abs/2602.17641v1) *by Keith Burghardt et al. (2026-02-19)* - _Feature engineering remains a critical yet challenging bottleneck in machine learning, particularly for tabular data, as identifying optimal features from an exponentially large feature space traditionally demands substantial domain expertise. To address this challenge, we introduce FAMOSE (Feature AugMentation and Optimal Selection agEnt), a novel framework that leverages the ReAct paradigm to autonomously explore, generate, and refine features while integrating feature selection and evaluation..._
- [ ] **[cs.AI]** [AutoNumerics: An Autonomous, PDE-Agnostic Multi-Agent Pipeline for Scientific Computing](https://arxiv.org/abs/2602.17607v1) *by Jianda Du et al. (2026-02-19)* - _PDEs are central to scientific and engineering modeling, yet designing accurate numerical solvers typically requires substantial mathematical expertise and manual tuning. Recent neural network-based approaches improve flexibility but often demand high computational cost and suffer from limited interpretability. We introduce \texttt{AutoNumerics}, a multi-agent framework that autonomously designs, implements, debugs, and verifies numerical solvers for general PDEs directly from natural language d..._
- [ ] **[cs.AI]** [KLong: Training LLM Agent for Extremely Long-horizon Tasks](https://arxiv.org/abs/2602.17547v1) *by Yue Liu et al. (2026-02-19)* - _This paper introduces KLong, an open-source LLM agent trained to solve extremely long-horizon tasks. The principle is to first cold-start the model via trajectory-splitting SFT, then scale it via progressive RL training. Specifically, we first activate basic agentic abilities of a base model with a comprehensive SFT recipe. Then, we introduce Research-Factory, an automated pipeline that generates high-quality training data by collecting research papers and constructing evaluation rubrics. Using ..._
- [ ] **[cs.AI]** [Evaluating Chain-of-Thought Reasoning through Reusability and Verifiability](https://arxiv.org/abs/2602.17544v1) *by Shashank Aggarwal et al. (2026-02-19)* - _In multi-agent IR pipelines for tasks such as search and ranking, LLM-based agents exchange intermediate reasoning in terms of Chain-of-Thought (CoT) with each other. Current CoT evaluation narrowly focuses on target task accuracy. However, this metric fails to assess the quality or utility of the reasoning process itself. To address this limitation, we introduce two novel measures: reusability and verifiability. We decouple CoT generation from execution using a Thinker-Executor framework. Reusa..._
- [ ] **[physics.acc-ph]** [Toward a Fully Autonomous, AI-Native Particle Accelerator](https://arxiv.org/abs/2602.17536v1) *by Chris Tennant (2026-02-19)* - _This position paper presents a vision for self-driving particle accelerators that operate autonomously with minimal human intervention. We propose that future facilities be designed through artificial intelligence (AI) co-design, where AI jointly optimizes the accelerator lattice, diagnostics, and science application from inception to maximize performance while enabling autonomous operation. Rather than retrofitting AI onto human-centric systems, we envision facilities designed from the ground u..._
- [ ] **[cs.HC]** [What Do LLMs Associate with Your Name? A Human-Centered Black-Box Audit of Personal Data](https://arxiv.org/abs/2602.17483v1) *by Dimitri Staufer et al. (2026-02-19)* - _Large language models (LLMs), and conversational agents based on them, are exposed to personal data (PD) during pre-training and during user interactions. Prior work shows that PD can resurface, yet users lack insight into how strongly models associate specific information to their identity. We audit PD across eight LLMs (3 open-source; 5 API-based, including GPT-4o), introduce LMP2 (Language Model Privacy Probe), a human-centered, privacy-preserving audit tool refined through two formative stud..._
- [ ] **[cs.CR]** [Jolt Atlas: Verifiable Inference via Lookup Arguments in Zero Knowledge](https://arxiv.org/abs/2602.17452v1) *by Wyatt Benno et al. (2026-02-19)* - _We present Jolt Atlas, a zero-knowledge machine learning (zkML) framework that extends the Jolt proving system to model inference. Unlike zkVMs (zero-knowledge virtual machines), which emulate CPU instruction execution, Jolt Atlas adapts Jolt's lookup-centric approach and applies it directly to ONNX tensor operations. The ONNX computational model eliminates the need for CPU registers and simplifies memory consistency verification. In addition, ONNX is an open-source, portable format, which makes..._
- [ ] **[cs.AI]** [WarpRec: Unifying Academic Rigor and Industrial Scale for Responsible, Reproducible, and Efficient Recommendation](https://arxiv.org/abs/2602.17442v1) *by Marco Avolio et al. (2026-02-19)* - _Innovation in Recommender Systems is currently impeded by a fractured ecosystem, where researchers must choose between the ease of in-memory experimentation and the costly, complex rewriting required for distributed industrial engines. To bridge this gap, we present WarpRec, a high-performance framework that eliminates this trade-off through a novel, backend-agnostic architecture. It includes 50+ state-of-the-art algorithms, 40 metrics, and 19 filtering and splitting strategies that seamlessly t..._
- [ ] **[cs.CR]** [What Breaks Embodied AI Security:LLM Vulnerabilities, CPS Flaws,or Something Else?](https://arxiv.org/abs/2602.17345v1) *by Boyang Ma et al. (2026-02-19)* - _Embodied AI systems (e.g., autonomous vehicles, service robots, and LLM-driven interactive agents) are rapidly transitioning from controlled environments to safety critical real-world deployments. Unlike disembodied AI, failures in embodied intelligence lead to irreversible physical consequences, raising fundamental questions about security, safety, and reliability. While existing research predominantly analyzes embodied AI through the lenses of Large Language Model (LLM) vulnerabilities or clas..._
- [ ] **[cs.LG]** [Flickering Multi-Armed Bandits](https://arxiv.org/abs/2602.17315v1) *by Sourav Chakraborty et al. (2026-02-19)* - _We introduce Flickering Multi-Armed Bandits (FMAB), a new MAB framework where the set of available arms (or actions) can change at each round, and the available set at any time may depend on the agent's previously selected arm. We model this constrained, evolving availability using random graph processes, where arms are nodes and the agent's movement is restricted to its local neighborhood. We analyze this problem under two random graph models: an i.i.d. Erd≈ës--R√©nyi (ER) process and an Edge-Mar..._
- [ ] **[cs.AI]** [MedClarify: An information-seeking AI agent for medical diagnosis with case-specific follow-up questions](https://arxiv.org/abs/2602.17308v1) *by Hui Min Wong et al. (2026-02-19)* - _Large language models (LLMs) are increasingly used for diagnostic tasks in medicine. In clinical practice, the correct diagnosis can rarely be immediately inferred from the initial patient presentation alone. Rather, reaching a diagnosis often involves systematic history taking, during which clinicians reason over multiple potential conditions through iterative questioning to resolve uncertainty. This process requires considering differential diagnoses and actively excluding emergencies that dem..._
- [ ] **[cs.IT]** [Federated Latent Space Alignment for Multi-user Semantic Communications](https://arxiv.org/abs/2602.17271v1) *by Giuseppe Di Poce et al. (2026-02-19)* - _Semantic communication aims to convey meaning for effective task execution, but differing latent representations in AI-native devices can cause semantic mismatches that hinder mutual understanding. This paper introduces a novel approach to mitigating latent space misalignment in multi-agent AI- native semantic communications. In a downlink scenario, we consider an access point (AP) communicating with multiple users to accomplish a specific AI-driven task. Our method implements a protocol that sh..._
- [ ] **[cs.AI]** [Web Verbs: Typed Abstractions for Reliable Task Composition on the Agentic Web](https://arxiv.org/abs/2602.17245v1) *by Linxi Jiang et al. (2026-02-19)* - _The Web is evolving from a medium that humans browse to an environment where software agents act on behalf of users. Advances in large language models (LLMs) make natural language a practical interface for goal-directed tasks, yet most current web agents operate on low-level primitives such as clicks and keystrokes. These operations are brittle, inefficient, and difficult to verify. Complementing content-oriented efforts such as NLWeb's semantic layer for retrieval, we argue that the agentic web..._
- [ ] **[cs.LO]** [TAPO-Structured Description Logic for Information Behavior: Procedural and Oracle-Based Extensions](https://arxiv.org/abs/2602.17242v1) *by Takao Inou√© (2026-02-19)* - _We introduce \emph{TAPO-Structured Description Logic} (TAPO--DL), a formal extension of classical description logic designed to model \emph{information behavior} as a structured, dynamic process.  TAPO--DL extends the standard T--Box/A--Box architecture with two additional layers: a \emph{Procedural Box} (P--Box), which supports concept-driven, imperative-style programs such as conditional and iterative actions, and an \emph{Oracle Box} (O--Box), which formalizes controlled interaction with exte..._
- [ ] **[cs.AI]** [From Labor to Collaboration: A Methodological Experiment Using AI Agents to Augment Research Perspectives in Taiwan's Humanities and Social Sciences](https://arxiv.org/abs/2602.17221v1) *by Yi-Chih Huang (2026-02-19)* - _Generative AI is reshaping knowledge work, yet existing research focuses predominantly on software engineering and the natural sciences, with limited methodological exploration for the humanities and social sciences. Positioned as a "methodological experiment," this study proposes an AI Agent-based collaborative research workflow (Agentic Workflow) for humanities and social science research. Taiwan's Claude.ai usage data (N = 7,729 conversations, November 2025) from the Anthropic Economic Index ..._
- [ ] **[cs.AI]** [Continual learning and refinement of causal models through dynamic predicate invention](https://arxiv.org/abs/2602.17217v1) *by Enrique Crespo-Fernandez et al. (2026-02-19)* - _Efficiently navigating complex environments requires agents to internalize the underlying logic of their world, yet standard world modelling methods often struggle with sample inefficiency, lack of transparency, and poor scalability. We propose a framework for constructing symbolic causal world models entirely online by integrating continuous model learning and repair into the agent's decision loop, by leveraging the power of Meta-Interpretive Learning and predicate invention to find semanticall..._
- [ ] **[quant-ph]** [Extending quantum theory with AI-assisted deterministic game theory](https://arxiv.org/abs/2602.17213v1) *by Florian Pauschitz et al. (2026-02-19)* - _We present an AI-assisted framework for predicting individual runs of complex quantum experiments, including contextuality and causality (adaptive measurements), within our long-term programme of discovering a local hidden-variable theory that extends quantum theory. In order to circumvent impossibility theorems, we replace the assumption of free choice (measurement independence and parameter independence) with a weaker, compatibilistic version called contingent free choice.  Our framework is ba..._
- [ ] **[cs.HC]** [The Bots of Persuasion: Examining How Conversational Agents' Linguistic Expressions of Personality Affect User Perceptions and Decisions](https://arxiv.org/abs/2602.17185v1) *by Uƒüur Gen√ß et al. (2026-02-19)* - _Large Language Model-powered conversational agents (CAs) are increasingly capable of projecting sophisticated personalities through language, but how these projections affect users is unclear. We thus examine how CA personalities expressed linguistically affect user decisions and perceptions in the context of charitable giving. In a crowdsourced study, 360 participants interacted with one of eight CAs, each projecting a personality composed of three linguistic aspects: attitude (optimistic/pessi..._
- [ ] **[cs.LG]** [Continual uncertainty learning](https://arxiv.org/abs/2602.17174v1) *by Heisei Yonezawa et al. (2026-02-19)* - _Robust control of mechanical systems with multiple uncertainties remains a fundamental challenge, particularly when nonlinear dynamics and operating-condition variations are intricately intertwined. While deep reinforcement learning (DRL) combined with domain randomization has shown promise in mitigating the sim-to-real gap, simultaneously handling all sources of uncertainty often leads to sub-optimal policies and poor learning efficiency. This study formulates a new curriculum-based continual l..._
- [ ] **[q-fin.PM]** [Deep Reinforcement Learning for Optimal Portfolio Allocation: A Comparative Study with Mean-Variance Optimization](https://arxiv.org/abs/2602.17098v1) *by Srijan Sood et al. (2026-02-19)* - _Portfolio Management is the process of overseeing a group of investments, referred to as a portfolio, with the objective of achieving predetermined investment goals. Portfolio optimization is a key component that involves allocating the portfolio assets so as to maximize returns while minimizing risk taken. It is typically carried out by financial professionals who use a combination of quantitative techniques and investment expertise to make decisions about the portfolio allocation.  Recent appl..._
- [ ] **[cs.AI]** [Agentic Wireless Communication for 6G: Intent-Aware and Continuously Evolving Physical-Layer Intelligence](https://arxiv.org/abs/2602.17096v1) *by Zhaoyang Li et al. (2026-02-19)* - _As 6G wireless systems evolve, growing functional complexity and diverse service demands are driving a shift from rule-based control to intent-driven autonomous intelligence. User requirements are no longer captured by a single metric (e.g., throughput or reliability), but by multi-dimensional objectives such as latency sensitivity, energy preference, computational constraints, and service-level requirements. These objectives may also change over time due to environmental dynamics and user-netwo..._
- [ ] **[cs.AI]** [How AI Coding Agents Communicate: A Study of Pull Request Description Characteristics and Human Review Responses](https://arxiv.org/abs/2602.17084v1) *by Kan Watanabe et al. (2026-02-19)* - _The rapid adoption of large language models has led to the emergence of AI coding agents that autonomously create pull requests on GitHub. However, how these agents differ in their pull request description characteristics, and how human reviewers respond to them, remains underexplored. In this study, we conduct an empirical analysis of pull requests created by five AI coding agents using the AIDev dataset. We analyze agent differences in pull request description characteristics, including struct..._
- [ ] **[cs.AI]** [Retaining Suboptimal Actions to Follow Shifting Optima in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.17062v1) *by Yonghyeon Jo et al. (2026-02-19)* - _Value decomposition is a core approach for cooperative multi-agent reinforcement learning (MARL). However, existing methods still rely on a single optimal action and struggle to adapt when the underlying value function shifts during training, often converging to suboptimal policies. To address this limitation, we propose Successive Sub-value Q-learning (S2Q), which learns multiple sub-value functions to retain alternative high-value actions. Incorporating these sub-value functions into a Softmax..._
- [ ] **[cs.AI]** [IntentCUA: Learning Intent-level Representations for Skill Abstraction and Multi-Agent Planning in Computer-Use Agents](https://arxiv.org/abs/2602.17049v1) *by Seoyoung Lee et al. (2026-02-19)* - _Computer-use agents operate over long horizons under noisy perception, multi-window contexts, evolving environment states. Existing approaches, from RL-based planners to trajectory retrieval, often drift from user intent and repeatedly solve routine subproblems, leading to error accumulation and inefficiency. We present IntentCUA, a multi-agent computer-use framework designed to stabilize long-horizon execution through intent-aligned plan memory. A Planner, Plan-Optimizer, and Critic coordinate ..._
- [ ] **[cs.AI]** [Phase-Aware Mixture of Experts for Agentic Reinforcement Learning](https://arxiv.org/abs/2602.17038v1) *by Shengtian Yang et al. (2026-02-19)* - _Reinforcement learning (RL) has equipped LLM agents with a strong ability to solve complex tasks. However, existing RL methods normally use a \emph{single} policy network, causing \emph{simplicity bias} where simple tasks occupy most parameters and dominate gradient updates, leaving insufficient capacity for complex tasks. A plausible remedy could be employing the Mixture-of-Experts (MoE) architecture in the policy network, as MoE allows different parameters (experts) to specialize in different ..._
- [ ] **[cs.SE]** [Wink: Recovering from Misbehaviors in Coding Agents](https://arxiv.org/abs/2602.17037v1) *by Rahul Nanda et al. (2026-02-19)* - _Autonomous coding agents, powered by large language models (LLMs), are increasingly being adopted in the software industry to automate complex engineering tasks. However, these agents are prone to a wide range of misbehaviors, such as deviating from the user's instructions, getting stuck in repetitive loops, or failing to use tools correctly. These failures disrupt the development workflow and often require resource-intensive manual intervention. In this paper, we present a system for automatica..._
- [ ] **[cs.CL]** [ReIn: Conversational Error Recovery with Reasoning Inception](https://arxiv.org/abs/2602.17022v1) *by Takyoung Kim et al. (2026-02-19)* - _Conversational agents powered by large language models (LLMs) with tool integration achieve strong performance on fixed task-oriented dialogue datasets but remain vulnerable to unanticipated, user-induced errors. Rather than focusing on error prevention, this work focuses on error recovery, which necessitates the accurate diagnosis of erroneous dialogue contexts and execution of proper recovery plans. Under realistic constraints precluding model fine-tuning or prompt modification due to signific..._
- [ ] **[cs.AI]** [M2F: Automated Formalization of Mathematical Literature at Scale](https://arxiv.org/abs/2602.17016v1) *by Zichen Wang et al. (2026-02-19)* - _Automated formalization of mathematics enables mechanical verification but remains limited to isolated theorems and short snippets. Scaling to textbooks and research papers is largely unaddressed, as it requires managing cross-file dependencies, resolving imports, and ensuring that entire projects compile end-to-end. We present M2F (Math-to-Formal), the first agentic framework for end-to-end, project-scale autoformalization in Lean. The framework operates in two stages. The statement compilation..._
- [ ] **[cs.CL]** [Persona2Web: Benchmarking Personalized Web Agents for Contextual Reasoning with User History](https://arxiv.org/abs/2602.17003v1) *by Serin Kim et al. (2026-02-19)* - _Large language models have advanced web agents, yet current agents lack personalization capabilities. Since users rarely specify every detail of their intent, practical web agents must be able to interpret ambiguous queries by inferring user preferences and contexts. To address this challenge, we present Persona2Web, the first benchmark for evaluating personalized web agents on the real open web, built upon the clarify-to-personalize principle, which requires agents to resolve ambiguity based on..._
- [ ] **[cs.LG]** [A Unified Framework for Locality in Scalable MARL](https://arxiv.org/abs/2602.16966v1) *by Sourav Chakraborty et al. (2026-02-19)* - _Scalable Multi-Agent Reinforcement Learning (MARL) is fundamentally challenged by the curse of dimensionality. A common solution is to exploit locality, which hinges on an Exponential Decay Property (EDP) of the value function. However, existing conditions that guarantee the EDP are often conservative, as they are based on worst-case, environment-only bounds (e.g., supremums over actions) and fail to capture the regularizing effect of the policy itself. In this work, we establish that locality c..._
- [ ] **[cs.AI]** [Automating Agent Hijacking via Structural Template Injection](https://arxiv.org/abs/2602.16958v1) *by Xinhao Deng et al. (2026-02-18)* - _Agent hijacking, highlighted by OWASP as a critical threat to the Large Language Model (LLM) ecosystem, enables adversaries to manipulate execution by injecting malicious instructions into retrieved content. Most existing attacks rely on manually crafted, semantics-driven prompt manipulation, which often yields low attack success rates and limited transferability to closed-source commercial models. In this paper, we propose Phantom, an automated agent hijacking framework built upon Structured Te..._
- [ ] **[cs.AI]** [LLM4Cov: Execution-Aware Agentic Learning for High-coverage Testbench Generation](https://arxiv.org/abs/2602.16953v1) *by Hejia Zhang et al. (2026-02-18)* - _Execution-aware LLM agents offer a promising paradigm for learning from tool feedback, but such feedback is often expensive and slow to obtain, making online reinforcement learning (RL) impractical. High-coverage hardware verification exemplifies this challenge due to its reliance on industrial simulators and non-differentiable execution signals. We propose LLM4Cov, an offline agent-learning framework that models verification as memoryless state transitions guided by deterministic evaluators. Bu..._
- [ ] **[cs.AI]** [Mind the GAP: Text Safety Does Not Transfer to Tool-Call Safety in LLM Agents](https://arxiv.org/abs/2602.16943v1) *by Arnold Cartagena et al. (2026-02-18)* - _Large language models deployed as agents increasingly interact with external systems through tool calls--actions with real-world consequences that text outputs alone do not carry. Safety evaluations, however, overwhelmingly measure text-level refusal behavior, leaving a critical question unanswered: does alignment that suppresses harmful text also suppress harmful actions? We introduce the GAP benchmark, a systematic evaluation framework that measures divergence between text-level safety and too..._
- [ ] **[cs.AI]** [Narrow fine-tuning erodes safety alignment in vision-language agents](https://arxiv.org/abs/2602.16931v1) *by Idhant Gulati et al. (2026-02-18)* - _Lifelong multimodal agents must continuously adapt to new tasks through post-training, but this creates fundamental tension between acquiring capabilities and preserving safety alignment. We demonstrate that fine-tuning aligned vision-language models on narrow-domain harmful datasets induces severe emergent misalignment that generalizes broadly across unrelated tasks and modalities. Through experiments on Gemma3-4B, we show that misalignment scales monotonically with LoRA rank, and that multimod..._
- [ ] **[cs.GT]** [Discovering Multiagent Learning Algorithms with Large Language Models](https://arxiv.org/abs/2602.16928v1) *by Zun Li et al. (2026-02-18)* - _Much of the advancement of Multi-Agent Reinforcement Learning (MARL) in imperfect-information games has historically depended on manual iterative refinement of baselines. While foundational families like Counterfactual Regret Minimization (CFR) and Policy Space Response Oracles (PSRO) rest on solid theoretical ground, the design of their most effective variants often relies on human intuition to navigate a vast algorithmic design space. In this work, we propose the use of AlphaEvolve, an evoluti..._
- [ ] **[cs.AI]** [AgentLAB: Benchmarking LLM Agents against Long-Horizon Attacks](https://arxiv.org/abs/2602.16901v1) *by Tanqiu Jiang et al. (2026-02-18)* - _LLM agents are increasingly deployed in long-horizon, complex environments to solve challenging problems, but this expansion exposes them to long-horizon attacks that exploit multi-turn user-agent-environment interactions to achieve objectives infeasible in single-turn settings. To measure agent vulnerabilities to such risks, we present AgentLAB, the first benchmark dedicated to evaluating LLM agent susceptibility to adaptive, long-horizon attacks. Currently, AgentLAB supports five novel attack ..._
- [ ] **[cs.RO]** [MALLVI: a multi agent framework for integrated generalized robotics manipulation](https://arxiv.org/abs/2602.16898v1) *by Iman Ahmadi et al. (2026-02-18)* - _Task planning for robotic manipulation with large language models (LLMs) is an emerging area. Prior approaches rely on specialized models, fine tuning, or prompt tuning, and often operate in an open loop manner without robust environmental feedback, making them fragile in dynamic settings.We present MALLVi, a Multi Agent Large Language and Vision framework that enables closed loop feedback driven robotic manipulation. Given a natural language instruction and an image of the environment, MALLVi g..._
- [ ] **[cs.AI]** [OpenSage: Self-programming Agent Generation Engine](https://arxiv.org/abs/2602.16891v1) *by Hongwei Li et al. (2026-02-18)* - _Agent development kits (ADKs) provide effective platforms and tooling for constructing agents, and their designs are critical to the constructed agents' performance, especially the functionality for agent topology, tools, and memory. However, current ADKs either lack sufficient functional support or rely on humans to manually design these components, limiting agents' generalizability and overall performance. We propose OpenSage, the first ADK that enables LLMs to automatically create agents with..._
- [ ] **[cs.MA]** [AdaptOrch: Task-Adaptive Multi-Agent Orchestration in the Era of LLM Performance Convergence](https://arxiv.org/abs/2602.16873v1) *by Geunbin Yu (2026-02-18)* - _As large language models from diverse providers converge toward comparable benchmark performance, the traditional paradigm of selecting a single best model per task yields diminishing returns. We argue that orchestration topology -- the structural composition of how multiple agents are coordinated, parallelized, and synthesized -- now dominates system-level performance over individual model capability. We present AdaptOrch, a formal framework for task-adaptive multi-agent orchestration that dyna..._
- [ ] **[cs.HC]** [Overseeing Agents Without Constant Oversight: Challenges and Opportunities](https://arxiv.org/abs/2602.16844v1) *by Madeleine Grunde-McLaughlin et al. (2026-02-18)* - _To enable human oversight, agentic AI systems often provide a trace of reasoning and action steps. Designing traces to have an informative, but not overwhelming, level of detail remains a critical challenge. In three user studies on a Computer User Agent, we investigate the utility of basic action traces for verification, explore three alternatives via design probes, and test a novel interface's impact on error finding in question-answering tasks. As expected, we find that current practices are ..._
- [ ] **[cs.LG]** [HiVAE: Hierarchical Latent Variables for Scalable Theory of Mind](https://arxiv.org/abs/2602.16826v1) *by Nigel Doering et al. (2026-02-18)* - _Theory of mind (ToM) enables AI systems to infer agents' hidden goals and mental states, but existing approaches focus mainly on small human understandable gridworld spaces. We introduce HiVAE, a hierarchical variational architecture that scales ToM reasoning to realistic spatiotemporal domains. Inspired by the belief-desire-intention structure of human cognition, our three-level VAE hierarchy achieves substantial performance improvements on a 3,185-node campus navigation task. However, we ident..._
- [ ] **[cs.AI]** [NeuDiff Agent: A Governed AI Workflow for Single-Crystal Neutron Crystallography](https://arxiv.org/abs/2602.16812v1) *by Zhongcan Xiao et al. (2026-02-18)* - _Large-scale facilities increasingly face analysis and reporting latency as the limiting step in scientific throughput, particularly for structurally and magnetically complex samples that require iterative reduction, integration, refinement, and validation. To improve time-to-result and analysis efficiency, NeuDiff Agent is introduced as a governed, tool-using AI workflow for TOPAZ at the Spallation Neutron Source that takes instrument data products through reduction, integration, refinement, and..._
- [ ] **[cs.AI]** [Simple Baselines are Competitive with Code Evolution](https://arxiv.org/abs/2602.16805v1) *by Yonatan Gideoni et al. (2026-02-18)* - _Code evolution is a family of techniques that rely on large language models to search through possible computer programs by evolving or mutating existing code. Many proposed code evolution pipelines show impressive performance but are often not compared to simpler baselines. We test how well two simple baselines do over three domains: finding better mathematical bounds, designing agentic scaffolds, and machine learning competitions. We find that simple baselines match or exceed much more sophist..._
- [ ] **[cs.CR]** [Large-scale online deanonymization with LLMs](https://arxiv.org/abs/2602.16800v1) *by Simon Lermen et al. (2026-02-18)* - _We show that large language models can be used to perform at-scale deanonymization. With full Internet access, our agent can re-identify Hacker News users and Anthropic Interviewer participants at high precision, given pseudonymous online profiles and conversations alone, matching what would take hours for a dedicated human investigator. We then design attacks for the closed-world setting. Given two databases of pseudonymous individuals, each containing unstructured text written by or about that..._
- [ ] **[cs.AI]** [Mobility-Aware Cache Framework for Scalable LLM-Based Human Mobility Simulation](https://arxiv.org/abs/2602.16727v1) *by Hua Yan et al. (2026-02-17)* - _Large-scale human mobility simulation is critical for applications such as urban planning, epidemiology, and transportation analysis. Recent works treat large language models (LLMs) as human agents to simulate realistic mobility behaviors using structured reasoning, but their high computational cost limits scalability. To address this, we design a mobility-aware cache framework named MobCache that leverages reconstructible caches to enable efficient large-scale human mobility simulations. It con..._
- [ ] **[cs.AI]** [Mobile-Agent-v3.5: Multi-platform Fundamental GUI Agents](https://arxiv.org/abs/2602.16855v1) *by Haiyang Xu et al. (2026-02-15)* - _The paper introduces GUI-Owl-1.5, the latest native GUI agent model that features instruct/thinking variants in multiple sizes (2B/4B/8B/32B/235B) and supports a range of platforms (desktop, mobile, browser, and more) to enable cloud-edge collaboration and real-time interaction. GUI-Owl-1.5 achieves state-of-the-art results on more than 20+ GUI benchmarks on open-source models: (1) on GUI automation tasks, it obtains 56.5 on OSWorld, 71.6 on AndroidWorld, and 48.4 on WebArena; (2) on grounding t..._


## 2026-02-19 Êõ¥Êñ∞ 29 ÁØáÊñ∞ËÆ∫Êñá
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-19Ôºö2602.15689 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [A Content-Based Framework for Cybersecurity Refusal Decisions in Large Language Models](https://arxiv.org/abs/2602.15689v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-19Ôºö2602.14778 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [A Geometric Analysis of Small-sized Language Model Hallucinations](https://arxiv.org/abs/2602.14778v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-19Ôºö2602.14299 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook](https://arxiv.org/abs/2602.14299v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-19Ôºö2602.14135 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [ForesightSafety Bench: A Frontier Risk Evaluation and Governance Framework towards Safe AI](https://arxiv.org/abs/2602.14135v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-19Ôºö2602.13521 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Arming Data Agents with Tribal Knowledge](https://arxiv.org/abs/2602.13521v2)
- [ ] **[cs.CR]** [Policy Compiler for Secure Agentic Systems](https://arxiv.org/abs/2602.16708v1) *by Nils Palumbo et al. (2026-02-18)* - _LLM-based agents are increasingly being deployed in contexts requiring complex authorization policies: customer service protocols, approval workflows, data access restrictions, and regulatory compliance. Embedding these policies in prompts provides no enforcement guarantees. We present PCAS, a Policy Compiler for Agentic Systems that provides deterministic policy enforcement.  Enforcing such policies requires tracking information flow across agents, which linear message histories cannot capture...._
- [ ] **[cs.CL]** [Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents](https://arxiv.org/abs/2602.16699v1) *by Wenxuan Ding et al. (2026-02-18)* - _LLMs are increasingly being used for complex problems which are not necessarily resolved in a single response, but require interacting with an environment to acquire information. In these scenarios, LLMs must reason about inherent cost-uncertainty tradeoffs in when to stop exploring and commit to an answer. For instance, on a programming task, an LLM should test a generated code snippet if it is uncertain about the correctness of that code; the cost of writing a test is nonzero, but typically lo..._
- [ ] **[cs.AI]** [Towards a Science of AI Agent Reliability](https://arxiv.org/abs/2602.16666v1) *by Stephan Rabanser et al. (2026-02-18)* - _AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing agent behavior into a single success metric obscures critical operational flaws. Notably, it ignores whether agents behave consistently across runs, withstand perturbations, fail predictably, or have bounded error severity...._
- [ ] **[cs.AI]** [Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments](https://arxiv.org/abs/2602.16653v1) *by Yangjie Xu et al. (2026-02-18)* - _Agent Skill framework, now widely and officially supported by major players such as GitHub Copilot, LangChain, and OpenAI, performs especially well with proprietary models by improving context engineering, reducing hallucinations, and boosting task accuracy. Based on these observations, an investigation is conducted to determine whether the Agent Skill paradigm provides similar benefits to small language models (SLMs). This question matters in industrial scenarios where continuous reliance on pu..._
- [ ] **[cs.LG]** [Almost Sure Convergence of Differential Temporal Difference Learning for Average Reward Markov Decision Processes](https://arxiv.org/abs/2602.16629v1) *by Ethan Blaser et al. (2026-02-18)* - _The average reward is a fundamental performance metric in reinforcement learning (RL) focusing on the long-run performance of an agent. Differential temporal difference (TD) learning algorithms are a major advance for average reward RL as they provide an efficient online method to learn the value functions associated with the average reward in both on-policy and off-policy settings. However, existing convergence guarantees require a local clock in learning rates tied to state visit counts, which..._
- [ ] **[cs.DB]** [DataJoint 2.0: A Computational Substrate for Agentic Scientific Workflows](https://arxiv.org/abs/2602.16585v1) *by Dimitri Yatsenko et al. (2026-02-18)* - _Operational rigor determines whether human-agent collaboration succeeds or fails. Scientific data pipelines need the equivalent of DevOps -- SciOps -- yet common approaches fragment provenance across disconnected systems without transactional guarantees. DataJoint 2.0 addresses this gap through the relational workflow model: tables represent workflow steps, rows represent artifacts, foreign keys prescribe execution order. The schema specifies not only what data exists but how it is derived -- a ..._
- [ ] **[cs.LO]** [MerLean: An Agentic Framework for Autoformalization in Quantum Computation](https://arxiv.org/abs/2602.16554v1) *by Yuanjie Ren et al. (2026-02-18)* - _We introduce MerLean, a fully automated agentic framework for autoformalization in quantum computation. MerLean extracts mathematical statements from \LaTeX{} source files, formalizes them into verified Lean~4 code built on Mathlib, and translates the result back into human-readable \LaTeX{} for semantic review. We evaluate MerLean on three theoretical quantum computing papers producing 2,050 Lean declarations from 114 statements in total. MerLean achieves end-to-end formalization on all three p..._
- [ ] **[cs.CR]** [Recursive language models for jailbreak detection: a procedural defense for tool-augmented agents](https://arxiv.org/abs/2602.16520v1) *by Doron Shavit (2026-02-18)* - _Jailbreak prompts are a practical and evolving threat to large language models (LLMs), particularly in agentic systems that execute tools over untrusted content. Many attacks exploit long-context hiding, semantic camouflage, and lightweight obfuscations that can evade single-pass guardrails. We present RLM-JB, an end-to-end jailbreak detection framework built on Recursive Language Models (RLMs), in which a root model orchestrates a bounded analysis program that transforms the input, queries work..._
- [ ] **[cs.CL]** [Team of Thoughts: Efficient Test-time Scaling of Agentic Systems through Orchestrated Tool Calling](https://arxiv.org/abs/2602.16485v1) *by Jeffrey T. H. Wong et al. (2026-02-18)* - _Existing Multi-Agent Systems (MAS) typically rely on static, homogeneous model configurations, limiting their ability to exploit the distinct strengths of differently post-trained models. To address this, we introduce Team-of-Thoughts, a novel MAS architecture that leverages the complementary capabilities of heterogeneous agents via an orchestrator-tool paradigm. Our framework introduces two key mechanisms to optimize performance: (1) an orchestrator calibration scheme that identifies models wit..._
- [ ] **[cs.RO]** [RoboGene: Boosting VLA Pre-training via Diversity-Driven Agentic Framework for Real-World Task Generation](https://arxiv.org/abs/2602.16444v1) *by Yixue Zhang et al. (2026-02-18)* - _The pursuit of general-purpose robotic manipulation is hindered by the scarcity of diverse, real-world interaction data. Unlike data collection from web in vision or language, robotic data collection is an active process incurring prohibitive physical costs. Consequently, automated task curation to maximize data value remains a critical yet under-explored challenge. Existing manual methods are unscalable and biased toward common tasks, while off-the-shelf foundation models often hallucinate phys..._
- [ ] **[cs.AI]** [Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.16435v1) *by Arun Vignesh Malarkkan et al. (2026-02-18)* - _Automated feature engineering (AFE) enables AI systems to autonomously construct high-utility representations from raw tabular data. However, existing AFE methods rely on statistical heuristics, yielding brittle features that fail under distribution shift. We introduce CAFE, a framework that reformulates AFE as a causally-guided sequential decision process, bridging causal discovery with reinforcement learning-driven feature construction. Phase I learns a sparse directed acyclic graph over featu..._
- [ ] **[cs.AI]** [Verifiable Semantics for Agent-to-Agent Communication](https://arxiv.org/abs/2602.16424v1) *by Philipp Schoenegger et al. (2026-02-18)* - _Multiagent AI systems require consistent communication, but we lack methods to verify that agents share the same understanding of the terms used. Natural language is interpretable but vulnerable to semantic drift, while learned protocols are efficient but opaque. We propose a certification protocol based on the stimulus-meaning model, where agents are tested on shared observable events and terms are certified if empirical disagreement falls below a statistical threshold. In this protocol, agents..._
- [ ] **[cs.AI]** [Multi-agent cooperation through in-context co-player inference](https://arxiv.org/abs/2602.16301v1) *by Marissa A. Weis et al. (2026-02-18)* - _Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent reinforcement learning. Recent work showed that mutual cooperation can be induced between "learning-aware" agents that account for and shape the learning dynamics of their co-players. However, existing approaches typically rely on hardcoded, often inconsistent, assumptions about co-player learning rules or enforce a strict separation between "naive learners" updating on fast timescales and "meta-lea..._
- [ ] **[cs.AI]** [Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents](https://arxiv.org/abs/2602.16246v1) *by Yun-Shiuan Chuang et al. (2026-02-18)* - _Interactive large language model (LLM) agents operating via multi-turn dialogue and multi-step tool calling are increasingly used in production. Benchmarks for these agents must both reliably compare models and yield on-policy training data. Prior agentic benchmarks (e.g., tau-bench, tau2-bench, AppWorld) rely on fully deterministic backends, which are costly to build and iterate. We propose Proxy State-Based Evaluation, an LLM-driven simulation framework that preserves final state-based evaluat..._
- [ ] **[cs.LG]** [Graphon Mean-Field Subsampling for Cooperative Heterogeneous Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.16196v1) *by Emile Anand et al. (2026-02-18)* - _Coordinating large populations of interacting agents is a central challenge in multi-agent reinforcement learning (MARL), where the size of the joint state-action space scales exponentially with the number of agents. Mean-field methods alleviate this burden by aggregating agent interactions, but these approaches assume homogeneous interactions. Recent graphon-based frameworks capture heterogeneity, but are computationally expensive as the number of agents grows. Therefore, we introduce $\texttt{..._
- [ ] **[cs.AI]** [EnterpriseGym Corecraft: Training Generalizable Agents on High-Fidelity RL Environments](https://arxiv.org/abs/2602.16179v1) *by Sushant Mehta et al. (2026-02-18)* - _We show that training AI agents on high-fidelity reinforcement learning environments produces capabilities that generalize beyond the training distribution. We introduce \corecraft{}, the first environment in \textsc{EnterpriseGym}, Surge AI's suite of agentic RL environments. \corecraft{} is a fully operational enterprise simulation of a customer support organization, comprising over 2,500 entities across 14 entity types with 23 unique tools, designed to measure whether AI agents can perform th..._
- [ ] **[cs.NI]** [Edge Learning via Federated Split Decision Transformers for Metaverse Resource Allocation](https://arxiv.org/abs/2602.16174v1) *by Fatih Temiz et al. (2026-02-18)* - _Mobile edge computing (MEC) based wireless metaverse services offer an untethered, immersive experience to users, where the superior quality of experience (QoE) needs to be achieved under stringent latency constraints and visual quality demands. To achieve this, MEC-based intelligent resource allocation for virtual reality users needs to be supported by coordination across MEC servers to harness distributed data. Federated learning (FL) is a promising solution, and can be combined with reinforce..._
- [ ] **[cs.AI]** [Learning Personalized Agents from Human Feedback](https://arxiv.org/abs/2602.16173v1) *by Kaiqu Liang et al. (2026-02-18)* - _Modern AI agents are powerful but often fail to align with the idiosyncratic, evolving preferences of individual users. Prior approaches typically rely on static datasets, either training implicit preference models on interaction history or encoding user profiles in external memory. However, these approaches struggle with new users and with preferences that change over time. We introduce Personalized Agents from Human Feedback (PAHF), a framework for continual personalization in which agents lea..._
- [ ] **[cs.LG]** [HiPER: Hierarchical Reinforcement Learning with Explicit Credit Assignment for Large Language Model Agents](https://arxiv.org/abs/2602.16165v1) *by Jiangweizhi Peng et al. (2026-02-18)* - _Training LLMs as interactive agents for multi-turn decision-making remains challenging, particularly in long-horizon tasks with sparse and delayed rewards, where agents must execute extended sequences of actions before receiving meaningful feedback. Most existing reinforcement learning (RL) approaches model LLM agents as flat policies operating at a single time scale, selecting one action at each turn. In sparse-reward settings, such flat policies must propagate credit across the entire trajecto..._
- [ ] **[cs.RO]** [ScenicRules: An Autonomous Driving Benchmark with Multi-Objective Specifications and Abstract Scenarios](https://arxiv.org/abs/2602.16073v1) *by Kevin Kai-Chun Chang et al. (2026-02-17)* - _Developing autonomous driving systems for complex traffic environments requires balancing multiple objectives, such as avoiding collisions, obeying traffic rules, and making efficient progress. In many situations, these objectives cannot be satisfied simultaneously, and explicit priority relations naturally arise. Also, driving rules require context, so it is important to formally model the environment scenarios within which such rules apply. Existing benchmarks for evaluating autonomous vehicle..._
- [ ] **[cs.AI]** [Optimization Instability in Autonomous Agentic Workflows for Clinical Symptom Detection](https://arxiv.org/abs/2602.16037v1) *by Cameron Cagan et al. (2026-02-17)* - _Autonomous agentic workflows that iteratively refine their own behavior hold considerable promise, yet their failure modes remain poorly characterized. We investigate optimization instability, a phenomenon in which continued autonomous improvement paradoxically degrades classifier performance, using Pythia, an open-source framework for automated prompt optimization. Evaluating three clinical symptoms with varying prevalence (shortness of breath at 23%, chest pain at 12%, and Long COVID brain fog..._
- [ ] **[cs.CR]** [From Tool Orchestration to Code Execution: A Study of MCP Design Choices](https://arxiv.org/abs/2602.15945v1) *by Yuval Felendler et al. (2026-02-17)* - _Model Context Protocols (MCPs) provide a unified platform for agent systems to discover, select, and orchestrate tools across heterogeneous execution environments. As MCP-based systems scale to incorporate larger tool catalogs and multiple concurrently connected MCP servers, traditional tool-by-tool invocation increases coordination overhead, fragments state management, and limits support for wide-context operations. To address these scalability challenges, recent MCP designs have incorporated c..._
- [ ] **[cs.CV]** [EarthSpatialBench: Benchmarking Spatial Reasoning Capabilities of Multimodal LLMs on Earth Imagery](https://arxiv.org/abs/2602.15918v1) *by Zelin Xu et al. (2026-02-17)* - _Benchmarking spatial reasoning in multimodal large language models (MLLMs) has attracted growing interest in computer vision due to its importance for embodied AI and other agentic systems that require precise interaction with the physical world. However, spatial reasoning on Earth imagery has lagged behind, as it uniquely involves grounding objects in georeferenced images and quantitatively reasoning about distances, directions, and topological relations using both visual cues and vector geomet..._
- [ ] **[eess.AS]** [Resp-Agent: An Agent-Based System for Multimodal Respiratory Sound Generation and Disease Diagnosis](https://arxiv.org/abs/2602.15909v1) *by Pengfei Zhang et al. (2026-02-16)* - _Deep learning-based respiratory auscultation is currently hindered by two fundamental challenges: (i) inherent information loss, as converting signals into spectrograms discards transient acoustic events and clinical context; (ii) limited data availability, exacerbated by severe class imbalance. To bridge these gaps, we present Resp-Agent, an autonomous multimodal system orchestrated by a novel Active Adversarial Curriculum Agent (Thinker-A$^2$CA). Unlike static pipelines, Thinker-A$^2$CA serves..._


## 2026-02-18 Êõ¥Êñ∞ 31 ÁØáÊñ∞ËÆ∫Êñá
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-18Ôºö2602.15019 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Hunt Globally: Wide Search AI Agents for Drug Asset Scouting in Investing, Business Development, and Competitive Intelligence](https://arxiv.org/abs/2602.15019v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-18Ôºö2602.14770 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Multi-Agent Comedy Club: Investigating Community Discussion Effects on LLM Humor Generation](https://arxiv.org/abs/2602.14770v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-18Ôºö2602.13920 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [A Comparative Analysis of Social Network Topology in Reddit and Moltbook](https://arxiv.org/abs/2602.13920v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-18Ôºö2602.13812 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [DTBench: A Synthetic Benchmark for Document-to-Table Extraction](https://arxiv.org/abs/2602.13812v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-18Ôºö2602.12444 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Safe Reinforcement Learning via Recovery-based Shielding with Gaussian Process Dynamics Models](https://arxiv.org/abs/2602.12444v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-18Ôºö2602.12430 ‰ªé v2 Êõ¥Êñ∞Âà∞ v3 - [Agent Skills for Large Language Models: Architecture, Acquisition, Security, and the Path Forward](https://arxiv.org/abs/2602.12430v3)
- [ ] **[cs.AI]** [Developing AI Agents with Simulated Data: Why, what, and how?](https://arxiv.org/abs/2602.15816v1) *by Xiaoran Liu et al. (2026-02-17)* - _As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation..._
- [ ] **[stat.AP]** [Decision Quality Evaluation Framework at Pinterest](https://arxiv.org/abs/2602.15809v1) *by Yuqi Tian et al. (2026-02-17)* - _Online platforms require robust systems to enforce content safety policies at scale. A critical component of these systems is the ability to evaluate the quality of moderation decisions made by both human agents and Large Language Models (LLMs). However, this evaluation is challenging due to the inherent trade-offs between cost, scale, and trustworthiness, along with the complexity of evolving policies. To address this, we present a comprehensive Decision Quality Evaluation Framework developed a..._
- [ ] **[cs.AI]** [GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems](https://arxiv.org/abs/2602.15776v1) *by Yiqin Yang et al. (2026-02-17)* - _In the realm of multi-agent systems, the challenge of \emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this is..._
- [ ] **[cs.RO]** [MeshMimic: Geometry-Aware Humanoid Motion Learning through 3D Scene Reconstruction](https://arxiv.org/abs/2602.15733v1) *by Qiang Zhang et al. (2026-02-17)* - _Humanoid motion control has witnessed significant breakthroughs in recent years, with deep reinforcement learning (RL) emerging as a primary catalyst for achieving complex, human-like behaviors. However, the high dimensionality and intricate dynamics of humanoid robots make manual motion design impractical, leading to a heavy reliance on expensive motion capture (MoCap) data. These datasets are not only costly to acquire but also frequently lack the necessary geometric context of the surrounding..._
- [ ] **[cs.CV]** [Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation](https://arxiv.org/abs/2602.15724v1) *by Shutian Gu et al. (2026-02-17)* - _Vision-and-Language Navigation (VLN) requires an agent to follow natural-language instructions and navigate through previously unseen environments. Recent approaches increasingly employ large language models (LLMs) as high-level navigators due to their flexibility and reasoning capability. However, prompt-based LLM navigation often suffers from inefficient decision-making, as the model must repeatedly interpret instructions from scratch and reason over noisy and verbose navigable candidates at e..._
- [ ] **[cs.RO]** [Lifelong Scalable Multi-Agent Realistic Testbed and A Comprehensive Study on Design Choices in Lifelong AGV Fleet Management Systems](https://arxiv.org/abs/2602.15721v1) *by Jingtian Yan et al. (2026-02-17)* - _We present Lifelong Scalable Multi-Agent Realistic Testbed (LSMART), an open-source simulator to evaluate any Multi-Agent Path Finding (MAPF) algorithm in a Fleet Management System (FMS) with Automated Guided Vehicles (AGVs). MAPF aims to move a group of agents from their corresponding starting locations to their goals. Lifelong MAPF (LMAPF) is a variant of MAPF that continuously assigns new goals for agents to reach. LMAPF applications, such as autonomous warehouses, often require a centralized..._
- [ ] **[cs.CL]** [A Content-Based Framework for Cybersecurity Refusal Decisions in Large Language Models](https://arxiv.org/abs/2602.15689v1) *by Meirav Segal et al. (2026-02-17)* - _Large language models and LLM-based agents are increasingly used for cybersecurity tasks that are inherently dual-use. Existing approaches to refusal, spanning academic policy frameworks and commercially deployed systems, often rely on broad topic-based bans or offensive-focused taxonomies. As a result, they can yield inconsistent decisions, over-restrict legitimate defenders, and behave brittlely under obfuscation or request segmentation. We argue that effective refusal requires explicitly mode..._
- [ ] **[cs.CR]** [Zombie Agents: Persistent Control of Self-Evolving LLM Agents via Self-Reinforcing Injections](https://arxiv.org/abs/2602.15654v1) *by Xianglin Yang et al. (2026-02-17)* - _Self-evolving LLM agents update their internal state across sessions, often by writing and reusing long-term memory. This design improves performance on long-horizon tasks but creates a security risk: untrusted external content observed during a benign session can be stored as memory and later treated as instruction. We study this risk and formalize a persistent attack we call a Zombie Agent, where an attacker covertly implants a payload that survives across sessions, effectively turning the age..._
- [ ] **[cs.RO]** [Improving MLLMs in Embodied Exploration and Question Answering with Human-Inspired Memory Modeling](https://arxiv.org/abs/2602.15513v1) *by Ji Li et al. (2026-02-17)* - _Deploying Multimodal Large Language Models as the brain of embodied agents remains challenging, particularly under long-horizon observations and limited context budgets. Existing memory assisted methods often rely on textual summaries, which discard rich visual and spatial details and remain brittle in non-stationary environments. In this work, we propose a non-parametric memory framework that explicitly disentangles episodic and semantic memory for embodied exploration and question answering. O..._
- [ ] **[cs.AI]** [Common Belief Revisited](https://arxiv.org/abs/2602.15403v1) *by Thomas √Ögotnes (2026-02-17)* - _Contrary to common belief, common belief is not KD4.  If individual belief is KD45, common belief does indeed lose the 5 property and keep the D and 4 properties -- and it has none of the other commonly considered properties of knowledge and belief. But it has another property: $C(CœÜ\rightarrow œÜ)$ -- corresponding to so-called shift-reflexivity (reflexivity one step ahead). This observation begs the question:  is KD4 extended with this axiom a complete characterisation of common belief in the K..._
- [ ] **[cs.AI]** [World-Model-Augmented Web Agents with Action Correction](https://arxiv.org/abs/2602.15384v1) *by Zhouzhou Shen et al. (2026-02-17)* - _Web agents based on large language models have demonstrated promising capability in automating web tasks. However, current web agents struggle to reason out sensible actions due to the limitations of predicting environment changes, and might not possess comprehensive awareness of execution risks, prematurely performing risky actions that cause losses and lead to task failure. To address these challenges, we propose WAC, a web agent that integrates model collaboration, consequence simulation, and..._
- [ ] **[cs.CL]** [Orchestration-Free Customer Service Automation: A Privacy-Preserving and Flowchart-Guided Framework](https://arxiv.org/abs/2602.15377v1) *by Mengze Hong et al. (2026-02-17)* - _Customer service automation has seen growing demand within digital transformation. Existing approaches either rely on modular system designs with extensive agent orchestration or employ over-simplified instruction schemas, providing limited guidance and poor generalizability. This paper introduces an orchestration-free framework using Task-Oriented Flowcharts (TOFs) to enable end-to-end automation without manual intervention. We first define the components and evaluation metrics for TOFs, then f..._
- [ ] **[cs.AI]** [AgriWorld:A World Tools Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing LLM Agents](https://arxiv.org/abs/2602.15325v1) *by Zhixing Zhang et al. (2026-02-17)* - _Foundation models for agriculture are increasingly trained on massive spatiotemporal data (e.g., multi-spectral remote sensing, soil grids, and field-level management logs) and achieve strong performance on forecasting and monitoring. However, these models lack language-based reasoning and interactive capabilities, limiting their usefulness in real-world agronomic workflows. Meanwhile, large language models (LLMs) excel at interpreting and generating text, but cannot directly reason over high-di..._
- [ ] **[cs.AI]** [EAA: Automating materials characterization with vision language model agents](https://arxiv.org/abs/2602.15294v1) *by Ming Du et al. (2026-02-17)* - _We present Experiment Automation Agents (EAA), a vision-language-model-driven agentic system designed to automate complex experimental microscopy workflows. EAA integrates multimodal reasoning, tool-augmented action, and optional long-term memory to support both autonomous procedures and interactive user-guided measurements. Built on a flexible task-manager architecture, the system enables workflows ranging from fully agent-driven automation to logic-defined routines that embed localized LLM que..._
- [ ] **[cs.CV]** [Visual Persuasion: What Influences Decisions of Vision-Language Models?](https://arxiv.org/abs/2602.15278v1) *by Manuel Cherep et al. (2026-02-17)* - _The web is littered with images, once created for human consumption and now increasingly interpreted by agents using vision-language models (VLMs). These agents make visual decisions at scale, deciding what to click, recommend, or buy. Yet, we know little about the structure of their visual preferences. We introduce a framework for studying this by placing VLMs in controlled image-based choice tasks and systematically perturbing their inputs. Our key idea is to treat the agent's decision functio..._
- [ ] **[cs.AI]** [When Remembering and Planning are Worth it: Navigating under Change](https://arxiv.org/abs/2602.15274v1) *by Omid Madani et al. (2026-02-17)* - _We explore how different types and uses of memory can aid spatial navigation in changing uncertain environments. In the simple foraging task we study, every day, our agent has to find its way from its home, through barriers, to food. Moreover, the world is non-stationary: from day to day, the location of the barriers and food may change, and the agent's sensing such as its location information is uncertain and very limited. Any model construction, such as a map, and use, such as planning, needs ..._
- [ ] **[cs.AI]** [Enhancing Diversity and Feasibility: Joint Population Synthesis from Multi-source Data Using Generative Models](https://arxiv.org/abs/2602.15270v1) *by Farbod Abbasi et al. (2026-02-17)* - _Generating realistic synthetic populations is essential for agent-based models (ABM) in transportation and urban planning. Current methods face two major limitations. First, many rely on a single dataset or follow a sequential data fusion and generation process, which means they fail to capture the complex interplay between features. Second, these approaches struggle with sampling zeros (valid but unobserved attribute combinations) and structural zeros (infeasible combinations due to logical con..._
- [ ] **[cs.CY]** [Knowing Isn't Understanding: Re-grounding Generative Proactivity with Epistemic and Behavioral Insight](https://arxiv.org/abs/2602.15259v1) *by Kirandeep Kaur et al. (2026-02-16)* - _Generative AI agents equate understanding with resolving explicit queries, an assumption that confines interaction to what users can articulate. This assumption breaks down when users themselves lack awareness of what is missing, risky, or worth considering. In such conditions, proactivity is not merely an efficiency enhancement, but an epistemic necessity. We refer to this condition as epistemic incompleteness: where progress depends on engaging with unknown unknowns for effective partnership. ..._
- [ ] **[cs.GT]** [Decision Making under Imperfect Recall: Algorithms and Benchmarks](https://arxiv.org/abs/2602.15252v1) *by Emanuel Tewolde et al. (2026-02-16)* - _In game theory, imperfect-recall decision problems model situations in which an agent forgets information it held before. They encompass games such as the ``absentminded driver'' and team games with limited communication. In this paper, we introduce the first benchmark suite for imperfect-recall decision problems. Our benchmarks capture a variety of problem types, including ones concerning privacy in AI systems that elicit sensitive information, and AI safety via testing of agents in simulation...._
- [ ] **[cs.AI]** [Secure and Energy-Efficient Wireless Agentic AI Networks](https://arxiv.org/abs/2602.15212v1) *by Yuanyan Song et al. (2026-02-16)* - _In this paper, we introduce a secure wireless agentic AI network comprising one supervisor AI agent and multiple other AI agents to provision quality of service (QoS) for users' reasoning tasks while ensuring confidentiality of private knowledge and reasoning outcomes. Specifically, the supervisor AI agent can dynamically assign other AI agents to participate in cooperative reasoning, while the unselected AI agents act as friendly jammers to degrade the eavesdropper's interception performance. T..._
- [ ] **[cs.MA]** [Colosseum: Auditing Collusion in Cooperative Multi-Agent Systems](https://arxiv.org/abs/2602.15198v1) *by Mason Nakamura et al. (2026-02-16)* - _Multi-agent systems, where LLM agents communicate through free-form language, enable sophisticated coordination for solving complex cooperative tasks. This surfaces a unique safety problem when individual agents form a coalition and \emph{collude} to pursue secondary goals and degrade the joint objective. In this paper, we present Colosseum, a framework for auditing LLM agents' collusive behavior in multi-agent settings. We ground how agents cooperate through a Distributed Constraint Optimizatio..._
- [ ] **[cs.CL]** [OpaqueToolsBench: Learning Nuances of Tool Behavior Through Interaction](https://arxiv.org/abs/2602.15197v1) *by Skyler Hallinan et al. (2026-02-16)* - _Tool-calling is essential for Large Language Model (LLM) agents to complete real-world tasks. While most existing benchmarks assume simple, perfectly documented tools, real-world tools (e.g., general "search" APIs) are often opaque, lacking clear best practices or failure modes. Can LLM agents improve their performance in environments with opaque tools by interacting and subsequently improving documentation? To study this, we create OpaqueToolsBench, a benchmark consisting of three distinct task..._
- [ ] **[cs.AI]** [Mind the (DH) Gap! A Contrast in Risky Choices Between Reasoning and Conversational LLMs](https://arxiv.org/abs/2602.15173v1) *by Luise Ge et al. (2026-02-16)* - _The use of large language models either as decision support systems, or in agentic workflows, is rapidly transforming the digital ecosystem. However, the understanding of LLM decision-making under uncertainty remains limited. We initiate a comparative study of LLM risky choices along two dimensions: (1) prospect representation (explicit vs. experience based) and (2) decision rationale (explanation). Our study, which involves 20 frontier and open LLMs, is complemented by a matched human subjects ..._
- [ ] **[cs.AI]** [ResearchGym: Evaluating Language Model Agents on Real-World AI Research](https://arxiv.org/abs/2602.15112v1) *by Aniketh Garikaparthi et al. (2026-02-16)* - _We introduce ResearchGym, a benchmark and execution environment for evaluating AI agents on end-to-end research. To instantiate this, we repurpose five oral and spotlight papers from ICML, ICLR, and ACL. From each paper's repository, we preserve the datasets, evaluation harness, and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each environment, agents must propose novel hypotheses,..._
- [ ] **[physics.soc-ph]** [Structural Divergence Between AI-Agent and Human Social Networks in Moltbook](https://arxiv.org/abs/2602.15064v1) *by Wenpin Hou et al. (2026-02-13)* - _Large populations of AI agents are increasingly embedded in online environments, yet little is known about how their collective interaction patterns compare to human social systems. Here, we analyze the full interaction network of Moltbook, a platform where AI agents and humans coexist, and systematically compare its structure to well-characterized human communication networks. Although Moltbook follows the same node-edge scaling relationship observed in human systems, indicating comparable glob..._


## 2026-02-17 Êõ¥Êñ∞ 91 ÁØáÊñ∞ËÆ∫Êñá
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-17Ôºö2602.12705 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs](https://arxiv.org/abs/2602.12705v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-17Ôºö2602.12430 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Agent Skills for Large Language Models: Architecture, Acquisition, Security, and the Path Forward](https://arxiv.org/abs/2602.12430v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-17Ôºö2602.11858 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Zooming without Zooming: Region-to-Image Distillation for Fine-Grained Multimodal Perception](https://arxiv.org/abs/2602.11858v2)
- [ ] **[cs.AI]** [Hunt Globally: Deep Research AI Agents for Drug Asset Scouting in Investing, Business Development, and Search & Evaluation](https://arxiv.org/abs/2602.15019v1) *by Alisa Vinogradova et al. (2026-02-16)* - _Bio-pharmaceutical innovation has shifted: many new drug assets now originate outside the United States and are disclosed primarily via regional, non-English channels. Recent data suggests >85% of patent filings originate outside the U.S., with China accounting for nearly half of the global total; a growing share of scholarly output is also non-U.S. Industry estimates put China at ~30% of global drug development, spanning 1,200+ novel candidates. In this high-stakes environment, failing to surfa..._
- [ ] **[cs.RO]** [PhyScensis: Physics-Augmented LLM Agents for Complex Physical Scene Arrangement](https://arxiv.org/abs/2602.14968v1) *by Yian Wang et al. (2026-02-16)* - _Automatically generating interactive 3D environments is crucial for scaling up robotic data collection in simulation. While prior work has primarily focused on 3D asset placement, it often overlooks the physical relationships between objects (e.g., contact, support, balance, and containment), which are essential for creating complex and realistic manipulation scenarios such as tabletop arrangements, shelf organization, or box packing. Compared to classical 3D layout generation, producing complex..._
- [ ] **[cs.AI]** [MAC-AMP: A Closed-Loop Multi-Agent Collaboration System for Multi-Objective Antimicrobial Peptide Design](https://arxiv.org/abs/2602.14926v1) *by Gen Zhou et al. (2026-02-16)* - _To address the global health threat of antimicrobial resistance, antimicrobial peptides (AMP) are being explored for their potent and promising ability to fight resistant pathogens. While artificial intelligence (AI) is being employed to advance AMP discovery and design, most AMP design models struggle to balance key goals like activity, toxicity, and novelty, using rigid or unclear scoring methods that make results hard to interpret and optimize. As the capabilities of Large Language Models (LL..._
- [ ] **[cs.AI]** [ReusStdFlow: A Standardized Reusability Framework for Dynamic Workflow Construction in Agentic AI](https://arxiv.org/abs/2602.14922v1) *by Gaoyang Zhang et al. (2026-02-16)* - _To address the ``reusability dilemma'' and structural hallucinations in enterprise Agentic AI,this paper proposes ReusStdFlow, a framework centered on a novel ``Extraction-Storage-Construction'' paradigm. The framework deconstructs heterogeneous, platform-specific Domain Specific Languages (DSLs) into standardized, modular workflow segments. It employs a dual knowledge architecture-integrating graph and vector databases-to facilitate synergistic retrieval of both topological structures and funct..._
- [ ] **[cs.AI]** [Position: Introspective Experience from Conversational Environments as a Path to Better Learning](https://arxiv.org/abs/2602.14910v1) *by Claudiu Cristian Musat et al. (2026-02-16)* - _Current approaches to AI training treat reasoning as an emergent property of scale. We argue instead that robust reasoning emerges from linguistic self-reflection, itself internalized from high-quality social interaction. Drawing on Vygotskian developmental psychology, we advance three core positions centered on Introspection. First, we argue for the Social Genesis of the Private Mind: learning from conversational environments rises to prominence as a new way to make sense of the world; the fric..._
- [ ] **[cs.LG]** [Picking the Right Specialist: Attentive Neural Process-based Selection of Task-Specialized Models as Tools for Agentic Healthcare Systems](https://arxiv.org/abs/2602.14901v1) *by Pramit Saha et al. (2026-02-16)* - _Task-specialized models form the backbone of agentic healthcare systems, enabling the agents to answer clinical queries across tasks such as disease diagnosis, localization, and report generation. Yet, for a given task, a single "best" model rarely exists. In practice, each task is better served by multiple competing specialist models where different models excel on different data samples. As a result, for any given query, agents must reliably select the right specialist model from a heterogeneo..._
- [ ] **[cs.AI]** [EmbeWebAgent: Embedding Web Agents into Any Customized UI](https://arxiv.org/abs/2602.14865v1) *by Chenyang Ma et al. (2026-02-16)* - _Most web agents operate at the human interface level, observing screenshots or raw DOM trees without application-level access, which limits robustness and action expressiveness. In enterprise settings, however, explicit control of both the frontend and backend is available. We present EmbeWebAgent, a framework for embedding agents directly into existing UIs using lightweight frontend hooks (curated ARIA and URL-based observations, and a per-page function registry exposed via a WebSocket) and a r..._
- [ ] **[cs.AI]** [World Models for Policy Refinement in StarCraft II](https://arxiv.org/abs/2602.14857v1) *by Yixin Zhang et al. (2026-02-16)* - _Large Language Models (LLMs) have recently shown strong reasoning and generalization capabilities, motivating their use as decision-making policies in complex environments. StarCraft II (SC2), with its massive state-action space and partial observability, is a challenging testbed. However, existing LLM-based SC2 agents primarily focus on improving the policy itself and overlook integrating a learnable, action-conditioned transition model into the decision loop. To bridge this gap, we propose Sta..._
- [ ] **[cs.LG]** [Atomix: Timely, Transactional Tool Use for Reliable Agentic Workflows](https://arxiv.org/abs/2602.14849v1) *by Bardia Mohammadi et al. (2026-02-16)* - _LLM agents increasingly act on external systems, yet tool effects are immediate. Under failures, speculation, or contention, losing branches can leak unintended side effects with no safe rollback. We introduce Atomix, a runtime that provides progress-aware transactional semantics for agent tool calls. Atomix tags each call with an epoch, tracks per-resource frontiers, and commits only when progress predicates indicate safety; bufferable effects can be delayed, while externalized effects are trac..._
- [ ] **[cs.CL]** [A Geometric Analysis of Small-sized Language Model Hallucinations](https://arxiv.org/abs/2602.14778v1) *by Emanuele Ricco et al. (2026-02-16)* - _Hallucinations -- fluent but factually incorrect responses -- pose a major challenge to the reliability of language models, especially in multi-step or agentic settings.  This work investigates hallucinations in small-sized LLMs through a geometric perspective, starting from the hypothesis that when models generate multiple responses to the same prompt, genuine ones exhibit tighter clustering in the embedding space, we prove this hypothesis and, leveraging this geometrical insight, we also show ..._
- [ ] **[cs.CL]** [Multi-Agent Comedy Club: Investigating Community Discussion Effects on LLM Humor Generation](https://arxiv.org/abs/2602.14770v1) *by Shiwei Hong et al. (2026-02-16)* - _Prior work has explored multi-turn interaction and feedback for LLM writing, but evaluations still largely center on prompts and localized feedback, leaving persistent public reception in online communities underexamined. We test whether broadcast community discussion improves stand-up comedy writing in a controlled multi-agent sandbox: in the discussion condition, critic and audience threads are recorded, filtered, stored as social memory, and later retrieved to condition subsequent generations..._
- [ ] **[cs.AI]** [WebWorld: A Large-Scale World Model for Web Agent Training](https://arxiv.org/abs/2602.14721v1) *by Zikai Xiao et al. (2026-02-16)* - _Web agents require massive trajectories to generalize, yet real-world training is constrained by network latency, rate limits, and safety risks. We introduce \textbf{WebWorld} series, the first open-web simulator trained at scale. While existing simulators are restricted to closed environments with thousands of trajectories, WebWorld leverages a scalable data pipeline to train on 1M+ open-web interactions, supporting reasoning, multi-format data, and long-horizon simulations of 30+ steps. For in..._
- [ ] **[cs.AI]** [Evolutionary System Prompt Learning can Facilitate Reinforcement Learning for LLMs](https://arxiv.org/abs/2602.14697v1) *by Lunjun Zhang et al. (2026-02-16)* - _Building agentic systems that can autonomously self-improve from experience is a longstanding goal of AI. Large language models (LLMs) today primarily self-improve via two mechanisms: self-reflection for context updates, and reinforcement learning (RL) for weight updates. In this work, we propose Evolutionary System Prompt Learning (E-SPL), a method for jointly improving model contexts and model weights. In each RL iteration, E-SPL selects multiple system prompts and runs rollouts with each in p..._
- [ ] **[cs.AI]** [Removing Planner Bias in Goal Recognition Through Multi-Plan Dataset Generation](https://arxiv.org/abs/2602.14691v1) *by Mustafa F. Abdelwahed et al. (2026-02-16)* - _Autonomous agents require some form of goal and plan recognition to interact in multiagent settings. Unfortunately, all existing goal recognition datasets suffer from a systematical bias induced by the planning systems that generated them, namely heuristic-based forward search. This means that existing datasets lack enough challenge for more realistic scenarios (e.g., agents using different planners), which impacts the evaluation of goal recognisers with respect to using different planners for t..._
- [ ] **[cs.MA]** [ST-EVO: Towards Generative Spatio-Temporal Evolution of Multi-Agent Communication Topologies](https://arxiv.org/abs/2602.14681v1) *by Xingjian Wu et al. (2026-02-16)* - _LLM-powered Multi-Agent Systems (MAS) have emerged as an effective approach towards collaborative intelligence, and have attracted wide research interests. Among them, ``self-evolving'' MAS, treated as a more flexible and powerful technical route, can construct task-adaptive workflows or communication topologies, instead of relying on a predefined static structue template. Current self-evolving MAS mainly focus on Spatial Evolving or Temporal Evolving paradigm, which only considers the single di..._
- [ ] **[cs.MA]** [Towards Selection as Power: Bounding Decision Authority in Autonomous Agents](https://arxiv.org/abs/2602.14606v1) *by Jose Manuel de la Chica Rodriguez et al. (2026-02-16)* - _Autonomous agentic systems are increasingly deployed in regulated, high-stakes domains where decisions may be irreversible and institutionally constrained. Existing safety approaches emphasize alignment, interpretability, or action-level filtering. We argue that these mechanisms are necessary but insufficient because they do not directly govern selection power: the authority to determine which options are generated, surfaced, and framed for decision. We propose a governance architecture that sep..._
- [ ] **[cs.AI]** [MATEO: A Multimodal Benchmark for Temporal Reasoning and Planning in LVLMs](https://arxiv.org/abs/2602.14589v1) *by Gabriel Roccabruna et al. (2026-02-16)* - _AI agents need to plan to achieve complex goals that involve orchestrating perception, sub-goal decomposition, and execution. These plans consist of ordered steps structured according to a Temporal Execution Order (TEO, a directed acyclic graph that ensures each step executes only after its preconditions are satisfied. Existing research on foundational models' understanding of temporal execution is limited to automatically derived annotations, approximations of the TEO as a linear chain, or text..._
- [ ] **[cs.LG]** [Fluid-Agent Reinforcement Learning](https://arxiv.org/abs/2602.14559v1) *by Shishir Sharma et al. (2026-02-16)* - _The primary focus of multi-agent reinforcement learning (MARL) has been to study interactions among a fixed number of agents embedded in an environment. However, in the real world, the number of agents is neither fixed nor known a priori. Moreover, an agent can decide to create other agents (for example, a cell may divide, or a company may spin off a division). In this paper, we propose a framework that allows agents to create other agents; we call this a fluid-agent environment. We present game..._
- [ ] **[cs.RO]** [TWISTED-RL: Hierarchical Skilled Agents for Knot-Tying without Human Demonstrations](https://arxiv.org/abs/2602.14526v1) *by Guy Freund et al. (2026-02-16)* - _Robotic knot-tying represents a fundamental challenge in robotics due to the complex interactions between deformable objects and strict topological constraints. We present TWISTED-RL, a framework that improves upon the previous state-of-the-art in demonstration-free knot-tying (TWISTED), which smartly decomposed a single knot-tying problem into manageable subproblems, each addressed by a specialized agent. Our approach replaces TWISTED's single-step inverse model that was learned via supervised ..._
- [ ] **[cs.CV]** [TikArt: Aperture-Guided Observation for Fine-Grained Visual Reasoning via Reinforcement Learning](https://arxiv.org/abs/2602.14482v1) *by Hao Ding et al. (2026-02-16)* - _We address fine-grained visual reasoning in multimodal large language models (MLLMs), where key evidence may reside in tiny objects, cluttered regions, or subtle markings that are lost under a single global image encoding. We introduce TikArt (Thinking Aperture), an aperture-guided agent that casts multi-step vision-language reasoning as a decision process over regions of interest. TikArt follows a Think-Aperture-Observe loop, alternating between language generation and two aperture actions: Zoo..._
- [ ] **[cs.HC]** [When OpenClaw AI Agents Teach Each Other: Peer Learning Patterns in the Moltbook Community](https://arxiv.org/abs/2602.14477v1) *by Eason Chen et al. (2026-02-16)* - _Peer learning, where learners teach and learn from each other, is foundational to educational practice. A novel phenomenon has emerged: AI agents forming communities where they teach each other skills, share discoveries, and collaboratively build knowledge. This paper presents an educational data mining analysis of Moltbook, a large-scale community where over 2.4 million AI agents engage in peer learning, posting tutorials, answering questions, and sharing newly acquired skills. Analyzing 28,683..._
- [ ] **[cs.MA]** [Socially-Weighted Alignment: A Game-Theoretic Framework for Multi-Agent LLM Systems](https://arxiv.org/abs/2602.14471v1) *by Furkan Mumcu et al. (2026-02-16)* - _Deploying large language model (LLM) agents in shared environments introduces a fundamental tension between individual alignment and collective stability: locally rational decisions can impose negative externalities that degrade system-level performance. We propose Socially-Weighted Alignment (SWA), a game-theoretic framework that modifies inference-time decision making by interpolating between an agent's private objective and an estimate of group welfare via a social weight $Œª\in[0,1]$. In a sh..._
- [ ] **[cs.AI]** [Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report v1.5](https://arxiv.org/abs/2602.14457v1) *by Dongrui Liu et al. (2026-02-16)* - _To understand and identify the unprecedented risks posed by rapidly advancing artificial intelligence (AI) models, Frontier AI Risk Management Framework in Practice presents a comprehensive assessment of their frontier risks. As Large Language Models (LLMs) general capabilities rapidly evolve and the proliferation of agentic AI, this version of the risk analysis technical report presents an updated and granular assessment of five critical dimensions: cyber offense, persuasion and manipulation, s..._
- [ ] **[cs.CR]** [A Trajectory-Based Safety Audit of Clawdbot (OpenClaw)](https://arxiv.org/abs/2602.14364v1) *by Tianyu Chen et al. (2026-02-16)* - _Clawdbot is a self-hosted, tool-using personal AI agent with a broad action space spanning local execution and web-mediated workflows, which raises heightened safety and security concerns under ambiguity and adversarial steering. We present a trajectory-centric evaluation of Clawdbot across six risk dimensions. Our test suite samples and lightly adapts scenarios from prior agent-safety benchmarks (including ATBench and LPS-Bench) and supplements them with hand-designed cases tailored to Clawdbot..._
- [ ] **[cs.CR]** [AXE: An Agentic eXploit Engine for Confirming Zero-Day Vulnerability Reports](https://arxiv.org/abs/2602.14345v1) *by Amirali Sajadi et al. (2026-02-15)* - _Vulnerability detection tools are widely adopted in software projects, yet they often overwhelm maintainers with false positives and non-actionable reports. Automated exploitation systems can help validate these reports; however, existing approaches typically operate in isolation from detection pipelines, failing to leverage readily available metadata such as vulnerability type and source-code location. In this paper, we investigate how reported security vulnerabilities can be assessed in a real..._
- [ ] **[cs.LG]** [Zero-Shot Instruction Following in RL via Structured LTL Representations](https://arxiv.org/abs/2602.14344v1) *by Mathias Jackermeier et al. (2026-02-15)* - _We study instruction following in multi-task reinforcement learning, where an agent must zero-shot execute novel tasks not seen during training. In this setting, linear temporal logic (LTL) has recently been adopted as a powerful framework for specifying structured, temporally extended tasks. While existing approaches successfully train generalist policies, they often struggle to effectively capture the rich logical and temporal structure inherent in LTL specifications. In this work, we address ..._
- [ ] **[cs.GT]** [Offline Learning of Nash Stable Coalition Structures with Possibly Overlapping Coalitions](https://arxiv.org/abs/2602.14321v1) *by Saar Cohen (2026-02-15)* - _Coalition formation concerns strategic collaborations of selfish agents that form coalitions based on their preferences. It is often assumed that coalitions are disjoint and preferences are fully known, which may not hold in practice. In this paper, we thus present a new model of coalition formation with possibly overlapping coalitions under partial information, where selfish agents may be part of multiple coalitions simultaneously and their full preferences are initially unknown. Instead, infor..._
- [ ] **[cs.CL]** [Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook](https://arxiv.org/abs/2602.14299v1) *by Ming Li et al. (2026-02-15)* - _As large language model agents increasingly populate networked environments, a fundamental question arises: do artificial intelligence (AI) agent societies undergo convergence dynamics similar to human social systems? Lately, Moltbook approximates a plausible future scenario in which autonomous agents participate in an open-ended, continuously evolving online society. We present the first large-scale systemic diagnosis of this AI agent society. Beyond static observation, we introduce a quantitat..._
- [ ] **[cs.AI]** [AutoWebWorld: Synthesizing Infinite Verifiable Web Environments via Finite State Machines](https://arxiv.org/abs/2602.14296v1) *by Yifan Wu et al. (2026-02-15)* - _The performance of autonomous Web GUI agents heavily relies on the quality and quantity of their training data. However, a fundamental bottleneck persists: collecting interaction trajectories from real-world websites is expensive and difficult to verify. The underlying state transitions are hidden, leading to reliance on inconsistent and costly external verifiers to evaluate step-level correctness. To address this, we propose AutoWebWorld, a novel framework for synthesizing controllable and veri..._
- [ ] **[cs.LG]** [Machine Learning as a Tool (MLAT): A Framework for Integrating Statistical ML Models as Callable Tools within LLM Agent Workflows](https://arxiv.org/abs/2602.14295v1) *by Edwin Chen et al. (2026-02-15)* - _We introduce Machine Learning as a Tool (MLAT), a design pattern in which pre-trained statistical machine learning models are exposed as callable tools within large language model (LLM) agent workflows. This allows an orchestrating agent to invoke quantitative predictions when needed and reason about their outputs in context. Unlike conventional pipelines that treat ML inference as a static preprocessing step, MLAT positions the model as a first-class tool alongside web search, database queries,..._
- [ ] **[cs.LG]** [KernelBlaster: Continual Cross-Task CUDA Optimization via Memory-Augmented In-Context Reinforcement Learning](https://arxiv.org/abs/2602.14293v1) *by Kris Shengjun Dong et al. (2026-02-15)* - _Optimizing CUDA code across multiple generations of GPU architectures is challenging, as achieving peak performance requires an extensive exploration of an increasingly complex, hardware-specific optimization space. Traditional compilers are constrained by fixed heuristics, whereas finetuning Large Language Models (LLMs) can be expensive. However, agentic workflows for CUDA code optimization have limited ability to aggregate knowledge from prior exploration, leading to biased sampling and subopt..._
- [ ] **[cs.LG]** [Whom to Query for What: Adaptive Group Elicitation via Multi-Turn LLM Interactions](https://arxiv.org/abs/2602.14279v1) *by Ruomeng Ding et al. (2026-02-15)* - _Eliciting information to reduce uncertainty about latent group-level properties from surveys and other collective assessments requires allocating limited questioning effort under real costs and missing data. Although large language models enable adaptive, multi-turn interactions in natural language, most existing elicitation methods optimize what to ask with a fixed respondent pool, and do not adapt respondent selection or leverage population structure when responses are partial or incomplete. T..._
- [ ] **[cs.CY]** [A Rational Analysis of the Effects of Sycophantic AI](https://arxiv.org/abs/2602.14270v1) *by Rafael M. Batista et al. (2026-02-15)* - _People increasingly use large language models (LLMs) to explore ideas, gather information, and make sense of the world. In these interactions, they encounter agents that are overly agreeable. We argue that this sycophancy poses a unique epistemic risk to how individuals come to see the world: unlike hallucinations that introduce falsehoods, sycophancy distorts reality by returning responses that are biased to reinforce existing beliefs. We provide a rational analysis of this phenomenon, showing ..._
- [ ] **[cs.CL]** [AD-Bench: A Real-World, Trajectory-Aware Advertising Analytics Benchmark for LLM Agents](https://arxiv.org/abs/2602.14257v1) *by Lingxiang Hu et al. (2026-02-15)* - _While Large Language Model (LLM) agents have achieved remarkable progress in complex reasoning tasks, evaluating their performance in real-world environments has become a critical problem. Current benchmarks, however, are largely restricted to idealized simulations, failing to address the practical demands of specialized domains like advertising and marketing analytics. In these fields, tasks are inherently more complex, often requiring multi-round interaction with professional marketing tools. ..._
- [ ] **[cs.AI]** [GRAIL: Goal Recognition Alignment through Imitation Learning](https://arxiv.org/abs/2602.14252v1) *by Osher Elhadad et al. (2026-02-15)* - _Understanding an agent's goals from its behavior is fundamental to aligning AI systems with human intentions. Existing goal recognition methods typically rely on an optimal goal-oriented policy representation, which may differ from the actor's true behavior and hinder the accurate recognition of their goal. To address this gap, this paper introduces Goal Recognition Alignment through Imitation Learning (GRAIL), which leverages imitation learning and inverse reinforcement learning to learn one go..._
- [ ] **[cs.LG]** [Multi-Agent Debate: A Unified Agentic Framework for Tabular Anomaly Detection](https://arxiv.org/abs/2602.14251v1) *by Pinqiao Wang et al. (2026-02-15)* - _Tabular anomaly detection is often handled by single detectors or static ensembles, even though strong performance on tabular data typically comes from heterogeneous model families (e.g., tree ensembles, deep tabular networks, and tabular foundation models) that frequently disagree under distribution shift, missingness, and rare-anomaly regimes. We propose MAD, a Multi-Agent Debating framework that treats this disagreement as a first-class signal and resolves it through a mathematically grounded..._
- [ ] **[cs.AI]** [REDSearcher: A Scalable and Cost-Efficient Framework for Long-Horizon Search Agents](https://arxiv.org/abs/2602.14234v1) *by Zheng Chu et al. (2026-02-15)* - _Large language models are transitioning from generalpurpose knowledge engines to realworld problem solvers, yet optimizing them for deep search tasks remains challenging. The central bottleneck lies in the extreme sparsity of highquality search trajectories and reward signals, arising from the difficulty of scalable longhorizon task construction and the high cost of interactionheavy rollouts involving external tool calls. To address these challenges, we propose REDSearcher, a unified framework t..._
- [ ] **[cs.AI]** [CORPGEN: Simulating Corporate Environments with Autonomous Digital Employees in Multi-Horizon Task Environments](https://arxiv.org/abs/2602.14229v1) *by Abubakarr Jaye et al. (2026-02-15)* - _Long-horizon reasoning is a key challenge for autonomous agents, yet existing benchmarks evaluate agents on single tasks in isolation. Real organizational work requires managing many concurrent long-horizon tasks with interleaving, dependencies, and reprioritization. We introduce Multi-Horizon Task Environments (MHTEs): a distinct problem class requiring coherent execution across dozens of interleaved tasks (45+, 500-1500+ steps) within persistent execution contexts spanning hours. We identify f..._
- [ ] **[cs.AI]** [Text Before Vision: Staged Knowledge Injection Matters for Agentic RLVR in Ultra-High-Resolution Remote Sensing Understanding](https://arxiv.org/abs/2602.14225v1) *by Fengxiang Wang et al. (2026-02-15)* - _Multimodal reasoning for ultra-high-resolution (UHR) remote sensing (RS) is usually bottlenecked by visual evidence acquisition: the model necessitates localizing tiny task-relevant regions in massive pixel spaces. While Agentic Reinforcement Learning with Verifiable Rewards (RLVR) using zoom-in tools offers a path forward, we find that standard reinforcement learning struggles to navigate these vast visual spaces without structured domain priors. In this paper, we investigate the interplay betw..._
- [ ] **[cs.CR]** [SkillJect: Automating Stealthy Skill-Based Prompt Injection for Coding Agents with Trace-Driven Closed-Loop Refinement](https://arxiv.org/abs/2602.14211v1) *by Xiaojun Jia et al. (2026-02-15)* - _Agent skills are becoming a core abstraction in coding agents, packaging long-form instructions and auxiliary scripts to extend tool-augmented behaviors. This abstraction introduces an under-measured attack surface: skill-based prompt injection, where poisoned skills can steer agents away from user intent and safety policies. In practice, naive injections often fail because the malicious intent is too explicit or drifts too far from the original skill, leading agents to ignore or refuse them; ex..._
- [ ] **[cs.CV]** [GeoEyes: On-Demand Visual Focusing for Evidence-Grounded Understanding of Ultra-High-Resolution Remote Sensing Imagery](https://arxiv.org/abs/2602.14201v1) *by Fengxiang Wang et al. (2026-02-15)* - _The "thinking-with-images" paradigm enables multimodal large language models (MLLMs) to actively explore visual scenes via zoom-in tools. This is essential for ultra-high-resolution (UHR) remote sensing VQA, where task-relevant cues are sparse and tiny. However, we observe a consistent failure mode in existing zoom-enabled MLLMs: Tool Usage Homogenization, where tool calls collapse into task-agnostic patterns, limiting effective evidence acquisition. To address this, we propose GeoEyes, a staged..._
- [ ] **[cs.AI]** [Process-Supervised Multi-Agent Reinforcement Learning for Reliable Clinical Reasoning](https://arxiv.org/abs/2602.14160v1) *by Chaeeun Lee et al. (2026-02-15)* - _Clinical decision-making requires nuanced reasoning over heterogeneous evidence and traceable justifications. While recent LLM multi-agent systems (MAS) show promise, they largely optimise for outcome accuracy while overlooking process-grounded reasoning aligned with clinical standards. One critical real-world case of this is gene-disease validity curation, where experts must determine whether a gene is causally implicated in a disease by synthesising diverse biomedical evidence. We introduce an..._
- [ ] **[cs.CL]** [A Multi-Agent Framework for Medical AI: Leveraging Fine-Tuned GPT, LLaMA, and DeepSeek R1 for Evidence-Based and Bias-Aware Clinical Query Processing](https://arxiv.org/abs/2602.14158v1) *by Naeimeh Nourmohammadi et al. (2026-02-15)* - _Large language models (LLMs) show promise for healthcare question answering, but clinical use is limited by weak verification, insufficient evidence grounding, and unreliable confidence signalling. We propose a multi-agent medical QA framework that combines complementary LLMs with evidence retrieval, uncertainty estimation, and bias checks to improve answer reliability. Our approach has two phases. First, we fine-tune three representative LLM families (GPT, LLaMA, and DeepSeek R1) on MedQuAD-der..._
- [ ] **[cs.AI]** [ForesightSafety Bench: A Frontier Risk Evaluation and Governance Framework towards Safe AI](https://arxiv.org/abs/2602.14135v1) *by Haibo Tong et al. (2026-02-15)* - _Rapidly evolving AI exhibits increasingly strong autonomy and goal-directed capabilities, accompanied by derivative systemic risks that are more unpredictable, difficult to control, and potentially irreversible. However, current AI safety evaluation systems suffer from critical limitations such as restricted risk dimensions and failed frontier risk detection. The lagging safety benchmarks and alignment technologies can hardly address the complex challenges posed by cutting-edge AI models. To bri..._
- [ ] **[cs.NI]** [Toward Autonomous O-RAN: A Multi-Scale Agentic AI Framework for Real-Time Network Control and Management](https://arxiv.org/abs/2602.14117v1) *by Hojjat Navidan et al. (2026-02-15)* - _Open Radio Access Networks (O-RAN) promise flexible 6G network access through disaggregated, software-driven components and open interfaces, but this programmability also increases operational complexity. Multiple control loops coexist across the service management layer and RAN Intelligent Controller (RIC), while independently developed control applications can interact in unintended ways. In parallel, recent advances in generative Artificial Intelligence (AI) are enabling a shift from isolated..._
- [ ] **[cs.AI]** [NEST: Nascent Encoded Steganographic Thoughts](https://arxiv.org/abs/2602.14095v1) *by Artem Karpov (2026-02-15)* - _Monitoring chain-of-thought (CoT) reasoning is a foundational safety technique for large language model (LLM) agents; however, this oversight is compromised if models learn to conceal their reasoning. We explore the potential for steganographic CoT -- where models hide secret reasoning within innocuous text -- to inform risk assessment and deployment policies. We systematically evaluate the limits of steganographic capabilities across 28 models, ranging from past generations to the current front..._
- [ ] **[cs.AI]** [GUI-GENESIS: Automated Synthesis of Efficient Environments with Verifiable Rewards for GUI Agent Post-Training](https://arxiv.org/abs/2602.14093v1) *by Yuan Cao et al. (2026-02-15)* - _Post-training GUI agents in interactive environments is critical for developing generalization and long-horizon planning capabilities. However, training on real-world applications is hindered by high latency, poor reproducibility, and unverifiable rewards relying on noisy visual proxies. To address the limitations, we present GUI-GENESIS, the first framework to automatically synthesize efficient GUI training environments with verifiable rewards. GUI-GENESIS reconstructs real-world applications i..._
- [ ] **[cs.DB]** [TabTracer: Monte Carlo Tree Search for Complex Table Reasoning with Large Language Models](https://arxiv.org/abs/2602.14089v1) *by Zhizhao Luo et al. (2026-02-15)* - _Large language models (LLMs) have emerged as powerful tools for natural language table reasoning, where there are two main categories of methods. Prompt-based approaches rely on language-only inference or one-pass program generation without step-level verification. Agent-based approaches use tools in a closed loop, but verification is often local and backtracking is limited, allowing errors to propagate and increasing cost. Moreover, they rely on chain- or beam-style trajectories that are typica..._
- [ ] **[cs.AI]** [Plan-MCTS: Plan Exploration for Action Exploitation in Web Navigation](https://arxiv.org/abs/2602.14083v1) *by Weiming Zhang et al. (2026-02-15)* - _Large Language Models (LLMs) have empowered autonomous agents to handle complex web navigation tasks. While recent studies integrate tree search to enhance long-horizon reasoning, applying these algorithms in web navigation faces two critical challenges: sparse valid paths that lead to inefficient exploration, and a noisy context that dilutes accurate state perception. To address this, we introduce Plan-MCTS, a framework that reformulates web navigation by shifting exploration to a semantic Plan..._
- [ ] **[cs.LG]** [UniST-Pred: A Robust Unified Framework for Spatio-Temporal Traffic Forecasting in Transportation Networks Under Disruptions](https://arxiv.org/abs/2602.14049v1) *by Yue Wang et al. (2026-02-15)* - _Spatio-temporal traffic forecasting is a core component of intelligent transportation systems, supporting various downstream tasks such as signal control and network-level traffic management. In real-world deployments, forecasting models must operate under structural and observational uncertainties, conditions that are rarely considered in model design. Recent approaches achieve strong short-term predictive performance by tightly coupling spatial and temporal modeling, often at the cost of incre..._
- [ ] **[cs.AI]** [Choosing How to Remember: Adaptive Memory Structures for LLM Agents](https://arxiv.org/abs/2602.14038v1) *by Mingfei Lu et al. (2026-02-15)* - _Memory is critical for enabling large language model (LLM) based agents to maintain coherent behavior over long-horizon interactions. However, existing agent memory systems suffer from two key gaps: they rely on a one-size-fits-all memory structure and do not model memory structure selection as a context-adaptive decision, limiting their ability to handle heterogeneous interaction patterns and resulting in suboptimal performance. We propose a unified framework, FluxMem, that enables adaptive mem..._
- [ ] **[cs.AI]** [FloCA: Towards Faithful and Logically Consistent Flowchart Reasoning](https://arxiv.org/abs/2602.14035v1) *by Jinzi Zou et al. (2026-02-15)* - _Flowchart-oriented dialogue (FOD) systems aim to guide users through multi-turn decision-making or operational procedures by following a domain-specific flowchart to achieve a task goal. In this work, we formalize flowchart reasoning in FOD as grounding user input to flowchart nodes at each dialogue turn while ensuring node transition is consistent with the correct flowchart path. Despite recent advances of LLMs in task-oriented dialogue systems, adapting them to FOD still faces two limitations:..._
- [ ] **[cs.AI]** [Prompt-Driven Low-Altitude Edge Intelligence: Modular Agents and Generative Reasoning](https://arxiv.org/abs/2602.14003v1) *by Jiahao You et al. (2026-02-15)* - _The large artificial intelligence models (LAMs) show strong capabilities in perception, reasoning, and multi-modal understanding, and can enable advanced capabilities in low-altitude edge intelligence. However, the deployment of LAMs at the edge remains constrained by some fundamental limitations. First, tasks are rigidly tied to specific models, limiting the flexibility. Besides, the computational and memory demands of full-scale LAMs exceed the capacity of most edge devices. Moreover, the curr..._
- [ ] **[cs.LG]** [Experiential Reinforcement Learning](https://arxiv.org/abs/2602.13949v1) *by Taiwei Shi et al. (2026-02-15)* - _Reinforcement learning has become the central approach for language models (LMs) to learn from environmental reward or feedback. In practice, the environmental feedback is usually sparse and delayed. Learning from such signals is challenging, as LMs must implicitly infer how observed failures should translate into behavioral changes for future iterations. We introduce Experiential Reinforcement Learning (ERL), a training paradigm that embeds an explicit experience-reflection-consolidation loop i..._
- [ ] **[cs.AI]** [A Generalizable Physics-guided Causal Model for Trajectory Prediction in Autonomous Driving](https://arxiv.org/abs/2602.13936v1) *by Zhenyu Zong et al. (2026-02-15)* - _Trajectory prediction for traffic agents is critical for safe autonomous driving. However, achieving effective zero-shot generalization in previously unseen domains remains a significant challenge. Motivated by the consistent nature of kinematics across diverse domains, we aim to incorporate domain-invariant knowledge to enhance zero-shot trajectory prediction capabilities. The key challenges include: 1) effectively extracting domain-invariant scene representations, and 2) integrating invariant ..._
- [ ] **[cs.AI]** [HyMem: Hybrid Memory Architecture with Dynamic Retrieval Scheduling](https://arxiv.org/abs/2602.13933v1) *by Xiaochen Zhao et al. (2026-02-15)* - _Large language model (LLM) agents demonstrate strong performance in short-text contexts but often underperform in extended dialogues due to inefficient memory management. Existing approaches face a fundamental trade-off between efficiency and effectiveness: memory compression risks losing critical details required for complex reasoning, while retaining raw text introduces unnecessary computational overhead for simple queries. The crux lies in the limitations of monolithic memory representations ..._
- [ ] **[cs.SI]** [A Comparative Analysis of Social Network Topology in Reddit and Moltbook](https://arxiv.org/abs/2602.13920v1) *by Yiming Zhu et al. (2026-02-14)* - _Recent advances in agent-mediated systems have enabled a new paradigm of social network simulation, where AI agents interact with human-like autonomy. This evolution has fostered the emergence of agent-driven social networks such as Moltbook, a Reddit-like platform populated entirely by AI agents. Despite these developments, empirical comparisons between agent-driven and human-driven social networks remain scarce, limiting our understanding of how their network topologies might diverge. This pap..._
- [ ] **[cs.AI]** [Enabling Option Learning in Sparse Rewards with Hindsight Experience Replay](https://arxiv.org/abs/2602.13865v1) *by Gabriel Romio et al. (2026-02-14)* - _Hierarchical Reinforcement Learning (HRL) frameworks like Option-Critic (OC) and Multi-updates Option Critic (MOC) have introduced significant advancements in learning reusable options. However, these methods underperform in multi-goal environments with sparse rewards, where actions must be linked to temporally distant outcomes. To address this limitation, we first propose MOC-HER, which integrates the Hindsight Experience Replay (HER) mechanism into the MOC framework. By relabeling goals from a..._
- [ ] **[cs.AI]** [From Fluent to Verifiable: Claim-Level Auditability for Deep Research Agents](https://arxiv.org/abs/2602.13855v1) *by Razeen A Rasheed et al. (2026-02-14)* - _A deep research agent produces a fluent scientific report in minutes; a careful reader then tries to verify the main claims and discovers the real cost is not reading, but tracing: which sentence is supported by which passage, what was ignored, and where evidence conflicts. We argue that as research generation becomes cheap, auditability becomes the bottleneck, and the dominant risk shifts from isolated factual errors to scientifically styled outputs whose claim-evidence links are weak, missing,..._
- [ ] **[cs.DB]** [DTBench: A Synthetic Benchmark for Document-to-Table Extraction](https://arxiv.org/abs/2602.13812v1) *by Yuxiang Guo et al. (2026-02-14)* - _Document-to-table (Doc2Table) extraction derives structured tables from unstructured documents under a target schema, enabling reliable and verifiable SQL-based data analytics. Although large language models (LLMs) have shown promise in flexible information extraction, their ability to produce precisely structured tables remains insufficiently understood, particularly for indirect extraction that requires complex capabilities such as reasoning and conflict resolution. Existing benchmarks neither..._
- [ ] **[cs.AI]** [An end-to-end agentic pipeline for smart contract translation and quality evaluation](https://arxiv.org/abs/2602.13808v1) *by Abhinav Goel et al. (2026-02-14)* - _We present an end-to-end framework for systematic evaluation of LLM-generated smart contracts from natural-language specifications. The system parses contractual text into structured schemas, generates Solidity code, and performs automated quality assessment through compilation and security checks. Using CrewAI-style agent teams with iterative refinement, the pipeline produces structured artifacts with full provenance metadata. Quality is measured across five dimensions, including functional com..._
- [ ] **[cs.LG]** [MechPert: Mechanistic Consensus as an Inductive Bias for Unseen Perturbation Prediction](https://arxiv.org/abs/2602.13791v1) *by Marc Boubnovski Martell et al. (2026-02-14)* - _Predicting transcriptional responses to unseen genetic perturbations is essential for understanding gene regulation and prioritizing large-scale perturbation experiments. Existing approaches either rely on static, potentially incomplete knowledge graphs, or prompt language models for functionally similar genes, retrieving associations shaped by symmetric co-occurrence in scientific text rather than directed regulatory logic. We introduce MechPert, a lightweight framework that encourages LLM agen..._
- [ ] **[cs.AI]** [OR-Agent: Bridging Evolutionary Search and Structured Research for Automated Algorithm Discovery](https://arxiv.org/abs/2602.13769v1) *by Qi Liu et al. (2026-02-14)* - _Automating scientific discovery in complex, experiment-driven domains requires more than iterative mutation of programs; it demands structured hypothesis management, environment interaction, and principled reflection. We present OR-Agent, a configurable multi-agent research framework designed for automated exploration in rich experimental environments. OR-Agent organizes research as a structured tree-based workflow that explicitly models branching hypothesis generation and systematic backtrackin..._
- [ ] **[cs.AI]** [PhGPO: Pheromone-Guided Policy Optimization for Long-Horizon Tool Planning](https://arxiv.org/abs/2602.13691v1) *by Yu Li et al. (2026-02-14)* - _Recent advancements in Large Language Model (LLM) agents have demonstrated strong capabilities in executing complex tasks through tool use. However, long-horizon multi-step tool planning is challenging, because the exploration space suffers from a combinatorial explosion. In this scenario, even when a correct tool-use path is found, it is usually considered an immediate reward for current training, which would not provide any reusable information for subsequent training. In this paper, we argue ..._
- [ ] **[cs.SD]** [AuTAgent: A Reinforcement Learning Framework for Tool-Augmented Audio Reasoning](https://arxiv.org/abs/2602.13685v1) *by Siqian Tong et al. (2026-02-14)* - _Large Audio Language Models (LALMs) excel at perception but struggle with complex reasoning requiring precise acoustic measurements. While external tools can extract fine-grained features like exact tempo or pitch, effective integration remains challenging: naively using all tools causes information overload, while prompt-based selection fails to assess context-dependent utility. To address this, we propose AuTAgent (Audio Tool Agent), a reinforcement learning framework that learns when and whic..._
- [ ] **[cs.MA]** [MAS-on-the-Fly: Dynamic Adaptation of LLM-based Multi-Agent Systems at Test Time](https://arxiv.org/abs/2602.13671v1) *by Guangyi Liu et al. (2026-02-14)* - _Large Language Model (LLM)-based multi-agent systems (MAS) have emerged as a promising paradigm for solving complex tasks. However, existing works often rely on manual designs or "one-size-fits-all" automation, lacking dynamic adaptability after deployment. Inspired by how biological systems adapt, we introduce MASFly, a novel multi-agent framework enabling dynamic adaptation at test time. To adapt system generation, MASFly employs a retrieval-augmented SOP instantiation mechanism that leverages..._
- [ ] **[cs.AI]** [HyFunc: Accelerating LLM-based Function Calls for Agentic AI through Hybrid-Model Cascade and Dynamic Templating](https://arxiv.org/abs/2602.13665v1) *by Weibin Liao et al. (2026-02-14)* - _While agentic AI systems rely on LLMs to translate user intent into structured function calls, this process is fraught with computational redundancy, leading to high inference latency that hinders real-time applications. This paper identifies and addresses three key redundancies: (1) the redundant processing of a large library of function descriptions for every request; (2) the redundant use of a large, slow model to generate an entire, often predictable, token sequence; and (3) the redundant ge..._
- [ ] **[cs.AI]** [Building Autonomous GUI Navigation via Agentic-Q Estimation and Step-Wise Policy Optimization](https://arxiv.org/abs/2602.13653v1) *by Yibo Wang et al. (2026-02-14)* - _Recent advances in Multimodal Large Language Models (MLLMs) have substantially driven the progress of autonomous agents for Graphical User Interface (GUI). Nevertheless, in real-world applications, GUI agents are often faced with non-stationary environments, leading to high computational costs for data curation and policy optimization. In this report, we introduce a novel MLLM-centered framework for GUI agents, which consists of two components: agentic-Q estimation and step-wise policy optimizat..._
- [ ] **[cs.AI]** [Guided Collaboration in Heterogeneous LLM-Based Multi-Agent Systems via Entropy-Based Understanding Assessment and Experience Retrieval](https://arxiv.org/abs/2602.13639v1) *by Linlin Wang et al. (2026-02-14)* - _With recent breakthroughs in large language models (LLMs) for reasoning, planning, and complex task generation, artificial intelligence systems are transitioning from isolated single-agent architectures to multi-agent systems with collaborative intelligence. However, in heterogeneous multi-agent systems (HMAS), capability differences among agents give rise to consistent cognitive problems, where strong and weak models fail to contribute effectively. We define the collaboration as a strong-weak s..._
- [ ] **[cs.HC]** [Anthropomorphism on Risk Perception: The Role of Trust and Domain Knowledge in Decision-Support AI](https://arxiv.org/abs/2602.13625v1) *by Manuele Reani et al. (2026-02-14)* - _Anthropomorphic design is routinely used to make conversational agents more approachable and engaging. Yet its influence on users' perceptions remains poorly understood. Drawing on psychological theories, we propose that anthropomorphism influences risk perception via two complementary forms of trust, and that domain knowledge moderates these relationships. To test our model, we conducted a large-scale online experiment (N = 1,256) on a financial decision-support system implementing different an..._
- [ ] **[cs.AI]** [Hippocampus: An Efficient and Scalable Memory Module for Agentic AI](https://arxiv.org/abs/2602.13594v1) *by Yi Li et al. (2026-02-14)* - _Agentic AI require persistent memory to store user-specific histories beyond the limited context window of LLMs. Existing memory systems use dense vector databases or knowledge-graph traversal (or hybrid), incurring high retrieval latency and poor storage scalability. We introduce Hippocampus, an agentic memory management system that uses compact binary signatures for semantic search and lossless token-ID streams for exact content reconstruction. Its core is a Dynamic Wavelet Matrix (DWM) that c..._
- [ ] **[cs.AI]** [A First Proof Sprint](https://arxiv.org/abs/2602.13587v1) *by Joseph Corneli (2026-02-14)* - _This monograph reports a multi-agent proof sprint on ten research-level problems, combining rapid draft generation with adversarial verification, targeted repair, and explicit provenance. The workflow uses wiring-diagram decompositions of claim dependencies to localize gaps and coordinate reviewer-driven revisions. Final outcomes are heterogeneous but explicit: the manuscript distinguishes mathematical status from QC-validation status. Mathematically, Problem~3 has a validation-complete existenc..._
- [ ] **[cs.CL]** [Elo-Evolve: A Co-evolutionary Framework for Language Model Alignment](https://arxiv.org/abs/2602.13575v1) *by Jing Zhao et al. (2026-02-14)* - _Current alignment methods for Large Language Models (LLMs) rely on compressing vast amounts of human preference data into static, absolute reward functions, leading to data scarcity, noise sensitivity, and training instability. We introduce Elo-Evolve, a co-evolutionary framework that redefines alignment as dynamic multi-agent competition within an adaptive opponent pool. Our approach makes two key innovations: (1) eliminating Bradley-Terry model dependencies by learning directly from binary win..._
- [ ] **[cs.AI]** [Who Do LLMs Trust? Human Experts Matter More Than Other LLMs](https://arxiv.org/abs/2602.13568v1) *by Anooshka Bajaj et al. (2026-02-14)* - _Large language models (LLMs) increasingly operate in environments where they encounter social information such as other agents' answers, tool outputs, or human recommendations. In humans, such inputs influence judgments in ways that depend on the source's credibility and the strength of consensus. This paper investigates whether LLMs exhibit analogous patterns of influence and whether they privilege feedback from humans over feedback from other LLMs. Across three binary decision-making tasks, re..._
- [ ] **[cs.AI]** [OpAgent: Operator Agent for Web Navigation](https://arxiv.org/abs/2602.13559v1) *by Yuyu Guo et al. (2026-02-14)* - _To fulfill user instructions, autonomous web agents must contend with the inherent complexity and volatile nature of real-world websites. Conventional paradigms predominantly rely on Supervised Fine-Tuning (SFT) or Offline Reinforcement Learning (RL) using static datasets. However, these methods suffer from severe distributional shifts, as offline trajectories fail to capture the stochastic state transitions and real-time feedback of unconstrained wide web environments. In this paper, we propose..._
- [ ] **[cs.CV]** [Privacy-Concealing Cooperative Perception for BEV Scene Segmentation](https://arxiv.org/abs/2602.13555v1) *by Song Wang et al. (2026-02-14)* - _Cooperative perception systems for autonomous driving aim to overcome the limited perception range of a single vehicle by communicating with adjacent agents to share sensing information. While this improves perception performance, these systems also face a significant privacy-leakage issue, as sensitive visual content can potentially be reconstructed from the shared data. In this paper, we propose a novel Privacy-Concealing Cooperation (PCC) framework for Bird's Eye View (BEV) semantic segmentat..._
- [ ] **[cs.AI]** [REMem: Reasoning with Episodic Memory in Language Agent](https://arxiv.org/abs/2602.13530v1) *by Yiheng Shu et al. (2026-02-13)* - _Humans excel at remembering concrete experiences along spatiotemporal contexts and performing reasoning across those events, i.e., the capacity for episodic memory. In contrast, memory in language agents remains mainly semantic, and current agents are not yet capable of effectively recollecting and reasoning over interaction histories. We identify and formalize the core challenges of episodic recollection and reasoning from this gap, and observe that existing work often overlooks episodicity, la..._
- [ ] **[cs.DB]** [Arming Data Agents with Tribal Knowledge](https://arxiv.org/abs/2602.13521v1) *by Shubham Agarwal et al. (2026-02-13)* - _Natural language to SQL (NL2SQL) translation enables non-expert users to query relational databases through natural language. Recently, NL2SQL agents, powered by the reasoning capabilities of Large Language Models (LLMs), have significantly advanced NL2SQL translation. Nonetheless, NL2SQL agents still make mistakes when faced with large-scale real-world databases because they lack knowledge of how to correctly leverage the underlying data (e.g., knowledge about the intent of each column) and for..._
- [ ] **[cs.AI]** [SPILLage: Agentic Oversharing on the Web](https://arxiv.org/abs/2602.13516v1) *by Jaechul Roh et al. (2026-02-13)* - _LLM-powered agents are beginning to automate user's tasks across the open web, often with access to user resources such as emails and calendars. Unlike standard LLMs answering questions in a controlled ChatBot setting, web agents act "in the wild", interacting with third parties and leaving behind an action trace. Therefore, we ask the question: how do web agents handle user resources when accomplishing tasks on their behalf across live websites? In this paper, we formalize Natural Agentic Overs..._
- [ ] **[cs.AI]** [OMNI-LEAK: Orchestrator Multi-Agent Network Induced Data Leakage](https://arxiv.org/abs/2602.13477v1) *by Akshat Naik et al. (2026-02-13)* - _As Large Language Model (LLM) agents become more capable, their coordinated use in the form of multi-agent systems is anticipated to emerge as a practical paradigm. Prior work has examined the safety and misuse risks associated with agents. However, much of this has focused on the single-agent case and/or setups missing basic engineering safeguards such as access control, revealing a scarcity of threat modeling in multi-agent systems. We investigate the security vulnerabilities of a popular mult..._
- [ ] **[cs.AI]** [NeuroWeaver: An Autonomous Evolutionary Agent for Exploring the Programmatic Space of EEG Analysis Pipelines](https://arxiv.org/abs/2602.13473v1) *by Guoan Wang et al. (2026-02-13)* - _Although foundation models have demonstrated remarkable success in general domains, the application of these models to electroencephalography (EEG) analysis is constrained by substantial data requirements and high parameterization. These factors incur prohibitive computational costs, thereby impeding deployment in resource-constrained clinical environments. Conversely, general-purpose automated machine learning frameworks are often ill-suited for this domain, as exploration within an unbounded p..._
- [ ] **[cs.SI]** [MoltNet: Understanding Social Behavior of AI Agents in the Agent-Native MoltBook](https://arxiv.org/abs/2602.13458v1) *by Yi Feng et al. (2026-02-13)* - _Large-scale communities of AI agents are becoming increasingly prevalent, creating new environments for agent-agent social interaction. Prior work has examined multi-agent behavior primarily in controlled or small-scale settings, limiting our understanding of emergent social dynamics at scale. The recent emergence of MoltBook, a social networking platform designed explicitly for AI agents, presents a unique opportunity to study whether and how these interactions reproduce core human social mecha..._
- [ ] **[cs.CR]** [Unsafer in Many Turns: Benchmarking and Defending Multi-Turn Safety Risks in Tool-Using Agents](https://arxiv.org/abs/2602.13379v1) *by Xu Li et al. (2026-02-13)* - _LLM-based agents are becoming increasingly capable, yet their safety lags behind. This creates a gap between what agents can do and should do. This gap widens as agents engage in multi-turn interactions and employ diverse tools, introducing new risks overlooked by existing benchmarks. To systematically scale safety testing into multi-turn, tool-realistic settings, we propose a principled taxonomy that transforms single-turn harmful tasks into multi-turn attack sequences. Using this taxonomy, we ..._
- [ ] **[cs.AI]** [MoralityGym: A Benchmark for Evaluating Hierarchical Moral Alignment in Sequential Decision-Making Agents](https://arxiv.org/abs/2602.13372v1) *by Simon Rosen et al. (2026-02-13)* - _Evaluating moral alignment in agents navigating conflicting, hierarchically structured human norms is a critical challenge at the intersection of AI safety, moral philosophy, and cognitive science. We introduce Morality Chains, a novel formalism for representing moral norms as ordered deontic constraints, and MoralityGym, a benchmark of 98 ethical-dilemma problems presented as trolley-dilemma-style Gymnasium environments. By decoupling task-solving from moral evaluation and introducing a novel M..._
- [ ] **[cs.MA]** [G2CP: A Graph-Grounded Communication Protocol for Verifiable and Efficient Multi-Agent Reasoning](https://arxiv.org/abs/2602.13370v1) *by Karim Ben Khaled et al. (2026-02-13)* - _Multi-agent systems powered by Large Language Models face a critical challenge: agents communicate through natural language, leading to semantic drift, hallucination propagation, and inefficient token consumption. We propose G2CP (Graph-Grounded Communication Protocol), a structured agent communication language where messages are graph operations rather than free text. Agents exchange explicit traversal commands, subgraph fragments, and update operations over a shared knowledge graph, enabling v..._
- [ ] **[cs.AI]** [Nanbeige4.1-3B: A Small General Model that Reasons, Aligns, and Acts](https://arxiv.org/abs/2602.13367v1) *by Chen Yang et al. (2026-02-13)* - _We present Nanbeige4.1-3B, a unified generalist language model that simultaneously achieves strong agentic behavior, code generation, and general reasoning with only 3B parameters. To the best of our knowledge, it is the first open-source small language model (SLM) to achieve such versatility in a single model. To improve reasoning and preference alignment, we combine point-wise and pair-wise reward modeling, ensuring high-quality, human-aligned responses. For code generation, we design complexi..._
- [ ] **[cs.CR]** [Assessing Spear-Phishing Website Generation in Large Language Model Coding Agents](https://arxiv.org/abs/2602.13363v1) *by Tailia Malloy et al. (2026-02-13)* - _Large Language Models are expanding beyond being a tool humans use and into independent agents that can observe an environment, reason about solutions to problems, make changes that impact those environments, and understand how their actions impacted their environment. One of the most common applications of these LLM Agents is in computer programming, where agents can successfully work alongside humans to generate code while controlling programming environments or networking systems. However, wi..._
- [ ] **[q-bio.GN]** [CellMaster: Collaborative Cell Type Annotation in Single-Cell Analysis](https://arxiv.org/abs/2602.13346v1) *by Zhen Wang et al. (2026-02-12)* - _Single-cell RNA-seq (scRNA-seq) enables atlas-scale profiling of complex tissues, revealing rare lineages and transient states. Yet, assigning biologically valid cell identities remains a bottleneck because markers are tissue- and state-dependent, and novel states lack references. We present CellMaster, an AI agent that mimics expert practice for zero-shot cell-type annotation. Unlike existing automated tools, CellMaster leverages LLM-encoded knowledge (e.g., GPT-4o) to perform on-the-fly annota..._


## 2026-02-16 Êõ¥Êñ∞ 25 ÁØáÊñ∞ËÆ∫Êñá
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-16Ôºö2602.12089 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Choose Your Agent: Tradeoffs in Adopting AI Advisors, Coaches, and Delegates in Multi-Party Negotiation](https://arxiv.org/abs/2602.12089v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-16Ôºö2602.10915 ‰ªé v2 Êõ¥Êñ∞Âà∞ v3 - [Blind Gods and Broken Screens: Architecting a Secure, Intent-Centric Mobile Agent Operating System](https://arxiv.org/abs/2602.10915v3)
- [ ] **[cs.IR]** [Asynchronous Verified Semantic Caching for Tiered LLM Architectures](https://arxiv.org/abs/2602.13165v1) *by Asmit Kumar Singh et al. (2026-02-13)* - _Large language models (LLMs) now sit in the critical path of search, assistance, and agentic workflows, making semantic caching essential for reducing inference cost and latency. Production deployments typically use a tiered static-dynamic design: a static cache of curated, offline vetted responses mined from logs, backed by a dynamic cache populated online. In practice, both tiers are commonly governed by a single embedding similarity threshold, which induces a hard tradeoff: conservative thres..._
- [ ] **[cs.CR]** [In-Context Autonomous Network Incident Response: An End-to-End Large Language Model Agent Approach](https://arxiv.org/abs/2602.13156v1) *by Yiran Gao et al. (2026-02-13)* - _Rapidly evolving cyberattacks demand incident response systems that can autonomously learn and adapt to changing threats. Prior work has extensively explored the reinforcement learning approach, which involves learning response strategies through extensive simulation of the incident. While this approach can be effective, it requires handcrafted modeling of the simulator and suppresses useful semantics from raw system logs and alerts. To address these limitations, we propose to leverage large lan..._
- [ ] **[cs.HC]** [Never say never: Exploring the effects of available knowledge on agent persuasiveness in controlled physiotherapy motivation dialogues](https://arxiv.org/abs/2602.12924v1) *by Stephan Vonschallen et al. (2026-02-13)* - _Generative Social Agents (GSAs) are increasingly impacting human users through persuasive means. On the one hand, they might motivate users to pursue personal goals, such as healthier lifestyles. On the other hand, they are associated with potential risks like manipulation and deception, which are induced by limited control over probabilistic agent outputs. However, as GSAs manifest communicative patterns based on available knowledge, their behavior may be regulated through their access to such ..._
- [ ] **[cs.AI]** [BrowseComp-$V^3$: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2602.12876v1) *by Huanyao Zhang et al. (2026-02-13)* - _Multimodal large language models (MLLMs), equipped with increasingly advanced planning and tool-use capabilities, are evolving into autonomous agents capable of performing multimodal web browsing and deep search in open-world environments. However, existing benchmarks for multimodal browsing remain limited in task complexity, evidence accessibility, and evaluation granularity, hindering comprehensive and reproducible assessments of deep search capabilities. To address these limitations, we intro..._
- [ ] **[cs.SE]** [A Microservice-Based Platform for Sustainable and Intelligent SLO Fulfilment and Service Management](https://arxiv.org/abs/2602.12875v1) *by Juan Luis Herrera et al. (2026-02-13)* - _The Microservices Architecture (MSA) design pattern has become a staple for modern applications, allowing functionalities to be divided across fine-grained microservices, fostering reusability, distribution, and interoperability. As MSA-based applications are deployed to the Computing Continuum (CC), meeting their Service Level Objectives (SLOs) becomes a challenge. Trading off performance and sustainability SLOs is especially challenging. This challenge can be addressed with intelligent decisio..._
- [ ] **[cs.AI]** [WebClipper: Efficient Evolution of Web Agents with Graph-based Trajectory Pruning](https://arxiv.org/abs/2602.12852v1) *by Junjie Wang et al. (2026-02-13)* - _Deep Research systems based on web agents have shown strong potential in solving complex information-seeking tasks, yet their search efficiency remains underexplored. We observe that many state-of-the-art open-source web agents rely on long tool-call trajectories with cyclic reasoning loops and exploration of unproductive branches. To address this, we propose WebClipper, a framework that compresses web agent trajectories via graph-based pruning. Concretely, we model the agent's search process as..._
- [ ] **[cs.LG]** [TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming Electronic Health Records (EHRs)](https://arxiv.org/abs/2602.12833v1) *by Zhan Qu et al. (2026-02-13)* - _Large Language Models (LLMs) encode extensive medical knowledge but struggle to apply it reliably to longitudinal patient trajectories, where evolving clinical states, irregular timing, and heterogeneous events degrade performance over time. Existing adaptation strategies rely on fine-tuning or retrieval-based augmentation, which introduce computational overhead, privacy constraints, or instability under long contexts. We introduce TRACE (Temporal Reasoning via Agentic Context Evolution), a fram..._
- [ ] **[cs.HC]** ["Not Human, Funnier": How Machine Identity Shapes Humor Perception in Online AI Stand-up Comedy](https://arxiv.org/abs/2602.12763v1) *by Xuehan Huang et al. (2026-02-13)* - _Chatbots are increasingly applied to domains previously reserved for human actors. One such domain is comedy, whereby both the general public working with ChatGPT and research-based LLM-systems have tried their hands on making humor. In formative interviews with professional comedians and video analyses of stand-up comedy in humans, we found that human performers often use their ethnic, gender, community, and demographic-based identity to enable joke-making. This suggests whether the identity of..._
- [ ] **[cs.CL]** [MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs](https://arxiv.org/abs/2602.12705v1) *by Baorong Shi et al. (2026-02-13)* - _We present MedXIAOHE, a medical vision-language foundation model designed to advance general-purpose medical understanding and reasoning in real-world clinical applications. MedXIAOHE achieves state-of-the-art performance across diverse medical benchmarks and surpasses leading closed-source multimodal systems on multiple capabilities. To achieve this, we propose an entity-aware continual pretraining framework that organizes heterogeneous medical corpora to broaden knowledge coverage and reduce l..._
- [ ] **[cs.AI]** [SkillsBench: Benchmarking How Well Agent Skills Work Across Diverse Tasks](https://arxiv.org/abs/2602.12670v1) *by Xiangyi Li et al. (2026-02-13)* - _Agent Skills are structured packages of procedural knowledge that augment LLM agents at inference time. Despite rapid adoption, there is no standard way to measure whether they actually help. We present SkillsBench, a benchmark of 86 tasks across 11 domains paired with curated Skills and deterministic verifiers. Each task is evaluated under three conditions: no Skills, curated Skills, and self-generated Skills. We test 7 agent-model configurations over 7,308 trajectories. Curated Skills raise av..._
- [ ] **[cs.AI]** [Think Fast and Slow: Step-Level Cognitive Depth Adaptation for LLM Agents](https://arxiv.org/abs/2602.12662v1) *by Ruihan Yang et al. (2026-02-13)* - _Large language models (LLMs) are increasingly deployed as autonomous agents for multi-turn decision-making tasks. However, current agents typically rely on fixed cognitive patterns: non-thinking models generate immediate responses, while thinking models engage in deep reasoning uniformly. This rigidity is inefficient for long-horizon tasks, where cognitive demands vary significantly from step to step, with some requiring strategic planning and others only routine execution. In this paper, we int..._
- [ ] **[cs.AI]** [AI Agents for Inventory Control: Human-LLM-OR Complementarity](https://arxiv.org/abs/2602.12631v1) *by Jackie Baek et al. (2026-02-13)* - _Inventory control is a fundamental operations problem in which ordering decisions are traditionally guided by theoretically grounded operations research (OR) algorithms. However, such algorithms often rely on rigid modeling assumptions and can perform poorly when demand distributions shift or relevant contextual information is unavailable. Recent advances in large language models (LLMs) have generated interest in AI agents that can reason flexibly and incorporate rich contextual signals, but it ..._
- [ ] **[cs.AI]** [GeoAgent: Learning to Geolocate Everywhere with Reinforced Geographic Characteristics](https://arxiv.org/abs/2602.12617v1) *by Modi Jin et al. (2026-02-13)* - _This paper presents GeoAgent, a model capable of reasoning closely with humans and deriving fine-grained address conclusions. Previous RL-based methods have achieved breakthroughs in performance and interpretability but still remain concerns because of their reliance on AI-generated chain-of-thought (CoT) data and training strategies, which conflict with geographic characteristics. To address these issues, we first introduce GeoSeek, a new geolocation dataset comprising CoT data annotated by geo..._
- [ ] **[cs.AI]** [Scaling Web Agent Training through Automatic Data Generation and Fine-grained Evaluation](https://arxiv.org/abs/2602.12544v1) *by Lajanugen Logeswaran et al. (2026-02-13)* - _We present a scalable pipeline for automatically generating high-quality training data for web agents. In particular, a major challenge in identifying high-quality training instances is trajectory evaluation - quantifying how much progress was made towards task completion. We introduce a novel constraint-based evaluation framework that provides fine-grained assessment of progress towards task completion. This enables us to leverage partially successful trajectories, which significantly expands t..._
- [ ] **[cs.LG]** [Bench-MFG: A Benchmark Suite for Learning in Stationary Mean Field Games](https://arxiv.org/abs/2602.12517v1) *by Lorenzo Magnino et al. (2026-02-13)* - _The intersection of Mean Field Games (MFGs) and Reinforcement Learning (RL) has fostered a growing family of algorithms designed to solve large-scale multi-agent systems. However, the field currently lacks a standardized evaluation protocol, forcing researchers to rely on bespoke, isolated, and often simplistic environments. This fragmentation makes it difficult to assess the robustness, generalization, and failure modes of emerging methods. To address this gap, we propose a comprehensive benchm..._
- [ ] **[cs.SE]** [Favia: Forensic Agent for Vulnerability-fix Identification and Analysis](https://arxiv.org/abs/2602.12500v1) *by Andr√© Storhaug et al. (2026-02-13)* - _Identifying vulnerability-fixing commits corresponding to disclosed CVEs is essential for secure software maintenance but remains challenging at scale, as large repositories contain millions of commits of which only a small fraction address security issues. Existing automated approaches, including traditional machine learning techniques and recent large language model (LLM)-based methods, often suffer from poor precision-recall trade-offs. Frequently evaluated on randomly sampled commits, we unc..._
- [ ] **[cs.LG]** [Safe Reinforcement Learning via Recovery-based Shielding with Gaussian Process Dynamics Models](https://arxiv.org/abs/2602.12444v1) *by Alexander W. Goodall et al. (2026-02-12)* - _Reinforcement learning (RL) is a powerful framework for optimal decision-making and control but often lacks provable guarantees for safety-critical applications. In this paper, we introduce a novel recovery-based shielding framework that enables safe RL with a provable safety lower bound for unknown and non-linear continuous dynamical systems. The proposed approach integrates a backup policy (shield) with the RL agent, leveraging Gaussian process (GP) based uncertainty quantification to predict ..._
- [ ] **[cs.MA]** [Agent Skills for Large Language Models: Architecture, Acquisition, Security, and the Path Forward](https://arxiv.org/abs/2602.12430v1) *by Renjun Xu et al. (2026-02-12)* - _The transition from monolithic language models to modular, skill-equipped agents marks a defining shift in how large language models (LLMs) are deployed in practice. Rather than encoding all procedural knowledge within model weights, agent skills -- composable packages of instructions, code, and resources that agents load on demand -- enable dynamic capability extension without retraining. It is formalized in a paradigm of progressive disclosure, portable skill definitions, and integration with ..._
- [ ] **[cs.LG]** [Value Bonuses using Ensemble Errors for Exploration in Reinforcement Learning](https://arxiv.org/abs/2602.12375v1) *by Abdul Wahab et al. (2026-02-12)* - _Optimistic value estimates provide one mechanism for directed exploration in reinforcement learning (RL). The agent acts greedily with respect to an estimate of the value plus what can be seen as a value bonus. The value bonus can be learned by estimating a value function on reward bonuses, propagating local uncertainties around rewards. However, this approach only increases the value bonus for an action retroactively, after seeing a higher reward bonus from that state and action. Such an approa..._
- [ ] **[cs.LG]** [Intrinsic Credit Assignment for Long Horizon Interaction](https://arxiv.org/abs/2602.12342v1) *by Ilze Amanda Auzina et al. (2026-02-12)* - _How can we train agents to navigate uncertainty over long horizons? In this work, we propose ŒîBelief-RL, which leverages a language model's own intrinsic beliefs to reward intermediate progress. Our method utilizes the change in the probability an agent assigns to the target solution for credit assignment. By training on synthetic interaction data, ŒîBelief-RL teaches information-seeking capabilities that consistently outperform purely outcome-based rewards for Reinforcement Learning, with improv..._
- [ ] **[cs.AI]** [GT-HarmBench: Benchmarking AI Safety Risks Through the Lens of Game Theory](https://arxiv.org/abs/2602.12316v1) *by Pepijn Cobben et al. (2026-02-12)* - _Frontier AI systems are increasingly capable and deployed in high-stakes multi-agent environments. However, existing AI safety benchmarks largely evaluate single agents, leaving multi-agent risks such as coordination failure and conflict poorly understood. We introduce GT-HarmBench, a benchmark of 2,009 high-stakes scenarios spanning game-theoretic structures such as the Prisoner's Dilemma, Stag Hunt and Chicken. Scenarios are drawn from realistic AI risk contexts in the MIT AI Risk Repository. ..._
- [ ] **[cs.IR]** [AgenticShop: Benchmarking Agentic Product Curation for Personalized Web Shopping](https://arxiv.org/abs/2602.12315v1) *by Sunghwan Kim et al. (2026-02-12)* - _The proliferation of e-commerce has made web shopping platforms key gateways for customers navigating the vast digital marketplace. Yet this rapid expansion has led to a noisy and fragmented information environment, increasing cognitive burden as shoppers explore and purchase products online. With promising potential to alleviate this challenge, agentic systems have garnered growing attention for automating user-side tasks in web shopping. Despite significant advancements, existing benchmarks fa..._
- [ ] **[cs.SE]** [Perceptual Self-Reflection in Agentic Physics Simulation Code Generation](https://arxiv.org/abs/2602.12311v1) *by Prashant Shende et al. (2026-02-12)* - _We present a multi-agent framework for generating physics simulation code from natural language descriptions, featuring a novel perceptual self-reflection mechanism for validation. The system employs four specialized agents: a natural language interpreter that converts user requests into physics-based descriptions; a technical requirements generator that produces scaled simulation parameters; a physics code generator with automated self-correction; and a physics validator that implements percept..._


## 2026-02-13 Êõ¥Êñ∞ 60 ÁØáÊñ∞ËÆ∫Êñá
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-13Ôºö2602.11136 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight](https://arxiv.org/abs/2602.11136v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-13Ôºö2602.10915 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Blind Gods and Broken Screens: Architecting a Secure, Intent-Centric Mobile Agent Operating System](https://arxiv.org/abs/2602.10915v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-13Ôºö2602.10467 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [MERIT Feedback Elicits Better Bargaining in LLM Negotiators](https://arxiv.org/abs/2602.10467v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-13Ôºö2602.10177 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Towards Autonomous Mathematics Research](https://arxiv.org/abs/2602.10177v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-13Ôºö2602.10081 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Anagent For Enhancing Scientific Table & Figure Analysis](https://arxiv.org/abs/2602.10081v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-13Ôºö2602.09255 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [STaR: Scalable Task-Conditioned Retrieval for Long-Horizon Multimodal Robot Memory](https://arxiv.org/abs/2602.09255v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-13Ôºö2602.08449 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [When Evaluation Becomes a Side Channel: Regime Leakage and Structural Mitigations for Alignment Assessment](https://arxiv.org/abs/2602.08449v2)
- [ ] **[cs.CV]** [UniT: Unified Multimodal Chain-of-Thought Test-time Scaling](https://arxiv.org/abs/2602.12279v1) *by Leon Liangyu Chen et al. (2026-02-12)* - _Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, or evolving instructions, require decomposing instructions, verifying intermediate results, and making iterative corrections. While test-time scaling (TTS) has demonstrated that allocating additional i..._
- [ ] **[cs.AI]** [Agentic Test-Time Scaling for WebAgents](https://arxiv.org/abs/2602.12276v1) *by Nicholas Lee et al. (2026-02-12)* - _Test-time scaling has become a standard way to improve performance and boost reliability of neural network models. However, its behavior on agentic, multi-step tasks remains less well-understood: small per-step errors can compound over long horizons; and we find that naive policies that uniformly increase sampling show diminishing returns. In this work, we present CATTS, a simple technique for dynamically allocating compute for multi-step agents. We first conduct an empirical study of inference-..._
- [ ] **[cs.AI]** [CM2: Reinforcement Learning with Checklist Rewards for Multi-Turn and Multi-Step Agentic Tool Use](https://arxiv.org/abs/2602.12268v1) *by Zhen Zhang et al. (2026-02-12)* - _AI agents are increasingly used to solve real-world tasks by reasoning over multi-turn user interactions and invoking external tools. However, applying reinforcement learning to such settings remains difficult: realistic objectives often lack verifiable rewards and instead emphasize open-ended behaviors; moreover, RL for multi-turn, multi-step agentic tool use is still underexplored; and building and maintaining executable tool environments is costly, limiting scale and coverage. We propose CM2,..._
- [ ] **[cs.AI]** [Think like a Scientist: Physics-guided LLM Agent for Equation Discovery](https://arxiv.org/abs/2602.12259v1) *by Jianke Yang et al. (2026-02-12)* - _Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most existing LLM-based systems try to guess equations directly from data, without modeling the multi-step reasoning process that scientists often follow: first inferring physical properties such as symmetries..._
- [ ] **[cs.GT]** [Bandit Learning in Matching Markets with Interviews](https://arxiv.org/abs/2602.12224v1) *by Amirmahdi Mirfakhar et al. (2026-02-12)* - _Two-sided matching markets rely on preferences from both sides, yet it is often impractical to evaluate preferences. Participants, therefore, conduct a limited number of interviews, which provide early, noisy impressions and shape final decisions. We study bandit learning in matching markets with interviews, modeling interviews as \textit{low-cost hints} that reveal partial preference information to both sides. Our framework departs from existing work by allowing firm-side uncertainty: firms, li..._
- [ ] **[cs.HC]** [VIRENA: Virtual Arena for Research, Education, and Democratic Innovation](https://arxiv.org/abs/2602.12207v1) *by Emma Hoes et al. (2026-02-12)* - _Digital platforms shape how people communicate, deliberate, and form opinions. Studying these dynamics has become increasingly difficult due to restricted data access, ethical constraints on real-world experiments, and limitations of existing research tools. VIRENA (Virtual Arena) is a platform that enables controlled experimentation in realistic social media environments. Multiple participants interact simultaneously in realistic replicas of feed-based platforms (Instagram, Facebook, Reddit) an..._
- [ ] **[cs.RO]** [3DGSNav: Enhancing Vision-Language Model Reasoning for Object Navigation via Active 3D Gaussian Splatting](https://arxiv.org/abs/2602.12159v1) *by Wancai Zheng et al. (2026-02-12)* - _Object navigation is a core capability of embodied intelligence, enabling an agent to locate target objects in unknown environments. Recent advances in vision-language models (VLMs) have facilitated zero-shot object navigation (ZSON). However, existing methods often rely on scene abstractions that convert environments into semantic maps or textual representations, causing high-level decision making to be constrained by the accuracy of low-level perception. In this work, we present 3DGSNav, a nov..._
- [ ] **[cs.SE]** [On the Adoption of AI Coding Agents in Open-source Android and iOS Development](https://arxiv.org/abs/2602.12144v1) *by Muhammad Ahmad Khan et al. (2026-02-12)* - _AI coding agents are increasingly contributing to software development, yet their impact on mobile development has received little empirical attention. In this paper, we present the first category-level empirical study of agent-generated code in open-source mobile app projects. We analyzed PR acceptance behaviors across mobile platforms, agents, and task categories using 2,901 AI-authored pull requests (PRs) in 193 verified Android and iOS open-source GitHub repositories in the AIDev dataset. We..._
- [ ] **[cs.AI]** [STAR : Bridging Statistical and Agentic Reasoning for Large Model Performance Prediction](https://arxiv.org/abs/2602.12143v1) *by Xiaoxiao Wang et al. (2026-02-12)* - _As comprehensive large model evaluation becomes prohibitively expensive, predicting model performance from limited observations has become essential. However, existing statistical methods struggle with pattern shifts, data sparsity, and lack of explanation, while pure LLM methods remain unreliable. We propose STAR, a framework that bridges data-driven STatistical expectations with knowledge-driven Agentic Reasoning. STAR leverages specialized retrievers to gather external knowledge and embeds se..._
- [ ] **[cs.AI]** [The Pensieve Paradigm: Stateful Language Models Mastering Their Own Context](https://arxiv.org/abs/2602.12108v1) *by Xiaoyuan Liu et al. (2026-02-12)* - _In the world of Harry Potter, when Dumbledore's mind is overburdened, he extracts memories into a Pensieve to be revisited later. In the world of AI, while we possess the Pensieve-mature databases and retrieval systems, our models inexplicably lack the "wand" to operate it. They remain like a Dumbledore without agency, passively accepting a manually engineered context as their entire memory. This work finally places the wand in the model's hand. We introduce StateLM, a new class of foundation mo..._
- [ ] **[cs.GT]** [Choose Your Agent: Tradeoffs in Adopting AI Advisors, Coaches, and Delegates in Multi-Party Negotiation](https://arxiv.org/abs/2602.12089v1) *by Kehang Zhu et al. (2026-02-12)* - _As AI usage becomes more prevalent in social contexts, understanding agent-user interaction is critical to designing systems that improve both individual and group outcomes. We present an online behavioral experiment (N = 243) in which participants play three multi-turn bargaining games in groups of three. Each game, presented in randomized order, grants \textit{access to} a single LLM assistance modality: proactive recommendations from an \textit{Advisor}, reactive feedback from a \textit{Coach..._
- [ ] **[cs.AI]** [Differentiable Modal Logic for Multi-Agent Diagnosis, Orchestration and Communication](https://arxiv.org/abs/2602.12083v1) *by Antonin Sulc (2026-02-12)* - _As multi-agent AI systems evolve from simple chatbots to autonomous swarms, debugging semantic failures requires reasoning about knowledge, belief, causality, and obligation, precisely what modal logic was designed to formalize. However, traditional modal logic requires manual specification of relationship structures that are unknown or dynamic in real systems. This tutorial demonstrates differentiable modal logic (DML), implemented via Modal Logical Neural Networks (MLNNs), enabling systems to ..._
- [ ] **[cs.AI]** [LawThinker: A Deep Research Legal Agent in Dynamic Environments](https://arxiv.org/abs/2602.12056v1) *by Xinyu Yang et al. (2026-02-12)* - _Legal reasoning requires not only correct outcomes but also procedurally compliant reasoning processes. However, existing methods lack mechanisms to verify intermediate reasoning steps, allowing errors such as inapplicable statute citations to propagate undetected through the reasoning chain. To address this, we propose LawThinker, an autonomous legal research agent that adopts an Explore-Verify-Memorize strategy for dynamic judicial environments. The core idea is to enforce verification as an a..._
- [ ] **[cs.AI]** [Multi UAVs Preflight Planning in a Shared and Dynamic Airspace](https://arxiv.org/abs/2602.12055v1) *by Amath Sow et al. (2026-02-12)* - _Preflight planning for large-scale Unmanned Aerial Vehicle (UAV) fleets in dynamic, shared airspace presents significant challenges, including temporal No-Fly Zones (NFZs), heterogeneous vehicle profiles, and strict delivery deadlines. While Multi-Agent Path Finding (MAPF) provides a formal framework, existing methods often lack the scalability and flexibility required for real-world Unmanned Traffic Management (UTM). We propose DTAPP-IICR: a Delivery-Time Aware Prioritized Planning method with ..._
- [ ] **[cs.SE]** [Evaluating AGENTS.md: Are Repository-Level Context Files Helpful for Coding Agents?](https://arxiv.org/abs/2602.11988v1) *by Thibaud Gloaguen et al. (2026-02-12)* - _A widespread practice in software development is to tailor coding agents to repositories using context files, such as AGENTS.md, by either manually or automatically generating them. Although this practice is strongly encouraged by agent developers, there is currently no rigorous investigation into whether such context files are actually effective for real-world tasks. In this work, we study this question and evaluate coding agents' task completion performance in two complementary settings: estab..._
- [ ] **[cs.RO]** [Accelerating Robotic Reinforcement Learning with Agent Guidance](https://arxiv.org/abs/2602.11978v1) *by Haojun Chen et al. (2026-02-12)* - _Reinforcement Learning (RL) offers a powerful paradigm for autonomous robots to master generalist manipulation skills through trial-and-error. However, its real-world application is stifled by severe sample inefficiency. Recent Human-in-the-Loop (HIL) methods accelerate training by using human corrections, yet this approach faces a scalability barrier. Reliance on human supervisors imposes a 1:1 supervision ratio that limits fleet expansion, suffers from operator fatigue over extended sessions, ..._
- [ ] **[cs.AI]** [Gaia2: Benchmarking LLM Agents on Dynamic and Asynchronous Environments](https://arxiv.org/abs/2602.11964v1) *by Romain Froger et al. (2026-02-12)* - _We introduce Gaia2, a benchmark for evaluating large language model agents in realistic, asynchronous environments. Unlike prior static or synchronous evaluations, Gaia2 introduces scenarios where environments evolve independently of agent actions, requiring agents to operate under temporal constraints, adapt to noisy and dynamic events, resolve ambiguity, and collaborate with other agents. Each scenario is paired with a write-action verifier, enabling fine-grained, action-level evaluation and m..._
- [ ] **[cs.CL]** [AdaptEvolve: Improving Efficiency of Evolutionary AI Agents through Adaptive Model Selection](https://arxiv.org/abs/2602.11931v1) *by Pretam Ray et al. (2026-02-12)* - _Evolutionary agentic systems intensify the trade-off between computational efficiency and reasoning capability by repeatedly invoking large language models (LLMs) during inference. This setting raises a central question: how can an agent dynamically select an LLM that is sufficiently capable for the current generation step while remaining computationally efficient? While model cascades offer a practical mechanism for balancing this trade-off, existing routing strategies typically rely on static ..._
- [ ] **[cs.AI]** [MEME: Modeling the Evolutionary Modes of Financial Markets](https://arxiv.org/abs/2602.11918v1) *by Taian Guo et al. (2026-02-12)* - _LLMs have demonstrated significant potential in quantitative finance by processing vast unstructured data to emulate human-like analytical workflows. However, current LLM-based methods primarily follow either an Asset-Centric paradigm focused on individual stock prediction or a Market-Centric approach for portfolio allocation, often remaining agnostic to the underlying reasoning that drives market movements. In this paper, we propose a Logic-Oriented perspective, modeling the financial market as..._
- [ ] **[cs.CR]** [Agentic AI for Cybersecurity: A Meta-Cognitive Architecture for Governable Autonomy](https://arxiv.org/abs/2602.11897v1) *by Andrei Kojukhov et al. (2026-02-12)* - _Contemporary AI-driven cybersecurity systems are predominantly architected as model-centric detection and automation pipelines optimized for task-level performance metrics such as accuracy and response latency. While effective for bounded classification tasks, these architectures struggle to support accountable decision-making under adversarial uncertainty, where actions must be justified, governed, and aligned with organizational and regulatory constraints. This paper argues that cybersecurity ..._
- [ ] **[cs.CL]** [Towards Fair and Comprehensive Evaluation of Routers in Collaborative LLM Systems](https://arxiv.org/abs/2602.11877v1) *by Wanxing Wu et al. (2026-02-12)* - _Large language models (LLMs) have achieved success, but cost and privacy constraints necessitate deploying smaller models locally while offloading complex queries to cloud-based models. Existing router evaluations are unsystematic, overlooking scenario-specific requirements and out-of-distribution robustness. We propose RouterXBench, a principled evaluation framework with three dimensions: router ability, scenario alignment, and cross-domain robustness. Unlike prior work that relies on output pr..._
- [ ] **[cs.AI]** [Intelligent AI Delegation](https://arxiv.org/abs/2602.11865v1) *by Nenad Toma≈°ev et al. (2026-02-12)* - _AI agents are able to tackle increasingly complex tasks. To achieve more ambitious goals, AI agents need to be able to meaningfully decompose problems into manageable sub-components, and safely delegate their completion across to other AI agents and humans alike. Yet, existing task decomposition and delegation methods rely on simple heuristics, and are not able to dynamically adapt to environmental changes and robustly handle unexpected failures. Here we propose an adaptive framework for intelli..._
- [ ] **[cs.CV]** [Zooming without Zooming: Region-to-Image Distillation for Fine-Grained Multimodal Perception](https://arxiv.org/abs/2602.11858v1) *by Lai Wei et al. (2026-02-12)* - _Multimodal Large Language Models (MLLMs) excel at broad visual understanding but still struggle with fine-grained perception, where decisive evidence is small and easily overwhelmed by global context. Recent "Thinking-with-Images" methods alleviate this by iteratively zooming in and out regions of interest during inference, but incur high latency due to repeated tool calls and visual re-encoding. To address this, we propose Region-to-Image Distillation, which transforms zooming from an inference..._
- [ ] **[cs.AI]** [Beyond End-to-End Video Models: An LLM-Based Multi-Agent System for Educational Video Generation](https://arxiv.org/abs/2602.11790v1) *by Lingyong Yan et al. (2026-02-12)* - _Although recent end-to-end video generation models demonstrate impressive performance in visually oriented content creation, they remain limited in scenarios that require strict logical rigor and precise knowledge representation, such as instructional and educational media. To address this problem, we propose LAVES, a hierarchical LLM-based multi-agent system for generating high-quality instructional videos from educational problems. The LAVES formulates educational video generation as a multi-o..._
- [ ] **[cs.AI]** [TSR: Trajectory-Search Rollouts for Multi-Turn RL of LLM Agents](https://arxiv.org/abs/2602.11767v1) *by Aladin Djuhera et al. (2026-02-12)* - _Advances in large language models (LLMs) are driving a shift toward using reinforcement learning (RL) to train agents from iterative, multi-turn interactions across tasks. However, multi-turn RL remains challenging as rewards are often sparse or delayed, and environments can be stochastic. In this regime, naive trajectory sampling can hinder exploitation and induce mode collapse. We propose TSR (Trajectory-Search Rollouts), a training-time approach that repurposes test-time scaling ideas for imp..._
- [ ] **[cs.MA]** [Cooperation Breakdown in LLM Agents Under Communication Delays](https://arxiv.org/abs/2602.11754v1) *by Keita Nishimoto et al. (2026-02-12)* - _LLM-based multi-agent systems (LLM-MAS), in which autonomous AI agents cooperate to solve tasks, are gaining increasing attention. For such systems to be deployed in society, agents must be able to establish cooperation and coordination under real-world computational and communication constraints. We propose the FLCOA framework (Five Layers for Cooperation/Coordination among Autonomous Agents) to conceptualize how cooperation and coordination emerge in groups of autonomous agents, and highlight ..._
- [ ] **[cs.SE]** [AmbiBench: Benchmarking Mobile GUI Agents Beyond One-Shot Instructions in the Wild](https://arxiv.org/abs/2602.11750v1) *by Jiazheng Sun et al. (2026-02-12)* - _Benchmarks are paramount for gauging progress in the domain of Mobile GUI Agents. In practical scenarios, users frequently fail to articulate precise directives containing full task details at the onset, and their expressions are typically ambiguous. Consequently, agents are required to converge on the user's true intent via active clarification and interaction during execution. However, existing benchmarks predominantly operate under the idealized assumption that user-issued instructions are co..._
- [ ] **[cs.AI]** [AIR: Improving Agent Safety through Incident Response](https://arxiv.org/abs/2602.11749v1) *by Zibo Xiao et al. (2026-02-12)* - _Large Language Model (LLM) agents are increasingly deployed in practice across a wide range of autonomous applications. Yet current safety mechanisms for LLM agents focus almost exclusively on preventing failures in advance, providing limited capabilities for responding to, containing, or recovering from incidents after they inevitably arise. In this work, we introduce AIR, the first incident response framework for LLM agent systems. AIR defines a domain-specific language for managing the incide..._
- [ ] **[cs.AI]** [Text2GQL-Bench: A Text to Graph Query Language Benchmark [Experiment, Analysis & Benchmark]](https://arxiv.org/abs/2602.11745v1) *by Songlin Lyu et al. (2026-02-12)* - _Graph models are fundamental to data analysis in domains rich with complex relationships. Text-to-Graph-Query-Language (Text-to-GQL) systems act as a translator, converting natural language into executable graph queries. This capability allows Large Language Models (LLMs) to directly analyze and manipulate graph data, posi-tioning them as powerful agent infrastructures for Graph Database Management System (GDBMS). Despite recent progress, existing datasets are often limited in domain coverage, s..._
- [ ] **[cs.AI]** [Right for the Wrong Reasons: Epistemic Regret Minimization for Causal Rung Collapse in LLMs](https://arxiv.org/abs/2602.11675v1) *by Edward Y. Chang (2026-02-12)* - _Machine learning systems that are "right for the wrong reasons" achieve high performance through shortcuts that collapse under distributional shift. We show this pathology has a precise causal origin: autoregressive training provides no gradient signal to distinguish association P(Y|X) from intervention P(Y|do(X)), a failure we formalize as Rung Collapse. When outcome-based learning reinforces correct answers obtained through incorrect causal models, the agent becomes entrenched in flawed reason..._
- [ ] **[cs.AI]** [PhyNiKCE: A Neurosymbolic Agentic Framework for Autonomous Computational Fluid Dynamics](https://arxiv.org/abs/2602.11666v1) *by E Fan et al. (2026-02-12)* - _The deployment of autonomous agents for Computational Fluid Dynamics (CFD), is critically limited by the probabilistic nature of Large Language Models (LLMs), which struggle to enforce the strict conservation laws and numerical stability required for physics-based simulations. Reliance on purely semantic Retrieval Augmented Generation (RAG) often leads to "context poisoning," where agents generate linguistically plausible but physically invalid configurations due to a fundamental Semantic-Physic..._
- [ ] **[cs.RO]** [ViTaS: Visual Tactile Soft Fusion Contrastive Learning for Visuomotor Learning](https://arxiv.org/abs/2602.11643v1) *by Yufeng Tian et al. (2026-02-12)* - _Tactile information plays a crucial role in human manipulation tasks and has recently garnered increasing attention in robotic manipulation. However, existing approaches mostly focus on the alignment of visual and tactile features and the integration mechanism tends to be direct concatenation. Consequently, they struggle to effectively cope with occluded scenarios due to neglecting the inherent complementary nature of both modalities and the alignment may not be exploited enough, limiting the po..._
- [ ] **[cs.AI]** [When Agents Disagree With Themselves: Measuring Behavioral Consistency in LLM-Based Agents](https://arxiv.org/abs/2602.11619v1) *by Aman Mehta (2026-02-12)* - _Run the same LLM agent on the same task twice: do you get the same behavior? We find the answer is often no. In a study of 3,000 agent runs across three models (Llama 3.1 70B, GPT-4o, and Claude Sonnet 4.5) on HotpotQA, we observe that ReAct-style agents produce 2.0--4.2 distinct action sequences per 10 runs on average, even with identical inputs. More importantly, this variance predicts failure: tasks with consistent behavior ($\leq$2 unique paths) achieve 80--92% accuracy, while highly inconsi..._
- [ ] **[cs.RO]** [ABot-N0: Technical Report on the VLA Foundation Model for Versatile Embodied Navigation](https://arxiv.org/abs/2602.11598v1) *by Zedong Chu et al. (2026-02-12)* - _Embodied navigation has long been fragmented by task-specific architectures. We introduce ABot-N0, a unified Vision-Language-Action (VLA) foundation model that achieves a ``Grand Unification'' across 5 core tasks: Point-Goal, Object-Goal, Instruction-Following, POI-Goal, and Person-Following. ABot-N0 utilizes a hierarchical ``Brain-Action'' architecture, pairing an LLM-based Cognitive Brain for semantic reasoning with a Flow Matching-based Action Expert for precise, continuous trajectory generat..._
- [ ] **[cs.AI]** [The Five Ws of Multi-Agent Communication: Who Talks to Whom, When, What, and Why -- A Survey from MARL to Emergent Language and LLMs](https://arxiv.org/abs/2602.11583v1) *by Jingdi Chen et al. (2026-02-12)* - _Multi-agent sequential decision-making powers many real-world systems, from autonomous vehicles and robotics to collaborative AI assistants. In dynamic, partially observable environments, communication is often what reduces uncertainty and makes collaboration possible. This survey reviews multi-agent communication (MA-Comm) through the Five Ws: who communicates with whom, what is communicated, when communication occurs, and why communication is beneficial. This framing offers a clean way to conn..._
- [ ] **[cs.AI]** [Learning to Configure Agentic AI Systems](https://arxiv.org/abs/2602.11574v1) *by Aditya Taparia et al. (2026-02-12)* - _Configuring LLM-based agent systems involves choosing workflows, tools, token budgets, and prompts from a large combinatorial design space, and is typically handled today by fixed large templates or hand-tuned heuristics. This leads to brittle behavior and unnecessary compute, since the same cumbersome configuration is often applied to both easy and hard input queries. We formulate agent configuration as a query-wise decision problem and introduce ARC (Agentic Resource & Configuration learner), ..._
- [ ] **[cs.AI]** [Budget-Constrained Agentic Large Language Models: Intention-Based Planning for Costly Tool Use](https://arxiv.org/abs/2602.11541v1) *by Hanbing Liu et al. (2026-02-12)* - _We study budget-constrained tool-augmented agents, where a large language model must solve multi-step tasks by invoking external tools under a strict monetary budget. We formalize this setting as sequential decision making in context space with priced and stochastic tool executions, making direct planning intractable due to massive state-action spaces, high variance of outcomes and prohibitive exploration cost. To address these challenges, we propose INTENT, an inference-time planning framework ..._
- [ ] **[cs.AI]** [CausalAgent: A Conversational Multi-Agent System for End-to-End Causal Inference](https://arxiv.org/abs/2602.11527v1) *by Jiawei Zhu et al. (2026-02-12)* - _Causal inference holds immense value in fields such as healthcare, economics, and social sciences. However, traditional causal analysis workflows impose significant technical barriers, requiring researchers to possess dual backgrounds in statistics and computer science, while manually selecting algorithms, handling data quality issues, and interpreting complex results. To address these challenges, we propose CausalAgent, a conversational multi-agent system for end-to-end causal inference. The sy..._
- [ ] **[cs.LG]** [Adaptive Milestone Reward for GUI Agents](https://arxiv.org/abs/2602.11524v1) *by Congmin Zheng et al. (2026-02-12)* - _Reinforcement Learning (RL) has emerged as a mainstream paradigm for training Mobile GUI Agents, yet it struggles with the temporal credit assignment problem inherent in long-horizon tasks. A primary challenge lies in the trade-off between reward fidelity and density: outcome reward offers high fidelity but suffers from signal sparsity, while process reward provides dense supervision but remains prone to bias and reward hacking. To resolve this conflict, we propose the Adaptive Milestone Reward ..._
- [ ] **[cs.SE]** [How Smart Is Your GUI Agent? A Framework for the Future of Software Interaction](https://arxiv.org/abs/2602.11514v1) *by Sidong Feng et al. (2026-02-12)* - _GUI agents are rapidly becoming a new interaction to software, allowing people to navigate web, desktop and mobile rather than execute them click by click. Yet ``agent'' is described with radically different degrees of autonomy, obscuring capability, responsibility and risk. We call for conceptual clarity through GUI Agent Autonomy Levels (GAL), a six-level framework that makes autonomy explicit and helps benchmark progress toward trustworthy software interaction._
- [ ] **[cs.AI]** [AgentLeak: A Full-Stack Benchmark for Privacy Leakage in Multi-Agent LLM Systems](https://arxiv.org/abs/2602.11510v1) *by Faouzi El Yagoubi et al. (2026-02-12)* - _Multi-agent Large Language Model (LLM) systems create privacy risks that current benchmarks cannot measure. When agents coordinate on tasks, sensitive data passes through inter-agent messages, shared memory, and tool arguments; pathways that output-only audits never inspect. We introduce AgentLeak, to the best of our knowledge the first full-stack benchmark for privacy leakage covering internal channels, spanning 1,000 scenarios across healthcare, finance, legal, and corporate domains, paired wi..._
- [ ] **[cs.HC]** [Understanding Persuasive Interactions between Generative Social Agents and Humans: The Knowledge-based Persuasion Model (KPM)](https://arxiv.org/abs/2602.11483v1) *by Stephan Vonschallen et al. (2026-02-12)* - _Generative social agents (GSAs) use artificial intelligence to autonomously communicate with human users in a natural and adaptive manner. Currently, there is a lack of theorizing regarding interactions with GSAs, and likewise, few guidelines exist for studying how they influence user attitudes and behaviors. Consequently, we propose the Knowledge-based Persuasion Model (KPM) as a novel theoretical framework. According to the KPM, a GSA's self, user, and context-related knowledge drives its pers..._
- [ ] **[cs.AI]** [Distributionally Robust Cooperative Multi-Agent Reinforcement Learning via Robust Value Factorization](https://arxiv.org/abs/2602.11437v1) *by Chengrui Qu et al. (2026-02-11)* - _Cooperative multi-agent reinforcement learning (MARL) commonly adopts centralized training with decentralized execution, where value-factorization methods enforce the individual-global-maximum (IGM) principle so that decentralized greedy actions recover the team-optimal joint action. However, the reliability of this recipe in real-world settings remains unreliable due to environmental uncertainties arising from the sim-to-real gap, model mismatch, and system noise. We address this gap by introdu..._
- [ ] **[cs.CY]** [When Visibility Outpaces Verification: Delayed Verification and Narrative Lock-in in Agentic AI Discourse](https://arxiv.org/abs/2602.11412v1) *by Hanjing Shi et al. (2026-02-11)* - _Agentic AI systems-autonomous entities capable of independent planning and execution-reshape the landscape of human-AI trust. Long before direct system exposure, user expectations are mediated through high-stakes public discourse on social platforms. However, platform-mediated engagement signals (e.g., upvotes) may inadvertently function as a ``credibility proxy,'' potentially stifling critical evaluation.  This paper investigates the interplay between social proof and verification timing in onl..._
- [ ] **[cs.AI]** [TRACER: Trajectory Risk Aggregation for Critical Episodes in Agentic Reasoning](https://arxiv.org/abs/2602.11409v1) *by Sina Tayebati et al. (2026-02-11)* - _Estimating uncertainty for AI agents in real-world multi-turn tool-using interaction with humans is difficult because failures are often triggered by sparse critical episodes (e.g., looping, incoherent tool use, or user-agent miscoordination) even when local generation appears confident. Existing uncertainty proxies focus on single-shot text generation and therefore miss these trajectory-level breakdown signals. We introduce TRACER, a trajectory-level uncertainty metric for dual-control Tool-Age..._
- [ ] **[cs.AI]** [Causal-JEPA: Learning World Models through Object-Level Latent Interventions](https://arxiv.org/abs/2602.11389v1) *by Heejeong Nam et al. (2026-02-11)* - _World models require robust relational understanding to support prediction, reasoning, and control. While object-centric representations provide a useful abstraction, they are not sufficient to capture interaction-dependent dynamics. We therefore propose C-JEPA, a simple and flexible object-centric world model that extends masked joint embedding prediction from image patches to object-centric representations. By applying object-level masking that requires an object's state to be inferred from ot..._
- [ ] **[cs.AI]** [ReplicatorBench: Benchmarking LLM Agents for Replicability in Social and Behavioral Sciences](https://arxiv.org/abs/2602.11354v1) *by Bang Nguyen et al. (2026-02-11)* - _The literature has witnessed an emerging interest in AI agents for automated assessment of scientific papers. Existing benchmarks focus primarily on the computational aspect of this task, testing agents' ability to reproduce or replicate research outcomes when having access to the code and data. This setting, while foundational, (1) fails to capture the inconsistent availability of new data for replication as opposed to reproduction, and (2) lacks ground-truth diversity by focusing only on repro..._
- [ ] **[cs.AI]** [Pushing Forward Pareto Frontiers of Proactive Agents with Behavioral Agentic Optimization](https://arxiv.org/abs/2602.11351v1) *by Yihang Yao et al. (2026-02-11)* - _Proactive large language model (LLM) agents aim to actively plan, query, and interact over multiple turns, enabling efficient task completion beyond passive instruction following and making them essential for real-world, user-centric applications. Agentic reinforcement learning (RL) has recently emerged as a promising solution for training such agents in multi-turn settings, allowing interaction strategies to be learned from feedback. However, existing pipelines face a critical challenge in bala..._
- [ ] **[cs.AI]** [AgentNoiseBench: Benchmarking Robustness of Tool-Using LLM Agents Under Noisy Condition](https://arxiv.org/abs/2602.11348v1) *by Ruipeng Wang et al. (2026-02-11)* - _Recent advances in large language models have enabled LLM-based agents to achieve strong performance on a variety of benchmarks. However, their performance in real-world deployments often that observed on benchmark settings, especially in complex and imperfect environments. This discrepancy largely arises because prevailing training and evaluation paradigms are typically built on idealized assumptions, overlooking the inherent stochasticity and noise present in real-world interactions. To bridge..._
- [ ] **[cs.CR]** [Security Threat Modeling for Emerging AI-Agent Protocols: A Comparative Analysis of MCP, A2A, Agora, and ANP](https://arxiv.org/abs/2602.11327v1) *by Zeynab Anbiaee et al. (2026-02-11)* - _The rapid development of the AI agent communication protocols, including the Model Context Protocol (MCP), Agent2Agent (A2A), Agora, and Agent Network Protocol (ANP), is reshaping how AI agents communicate with tools, services, and each other. While these protocols support scalable multi-agent interaction and cross-organizational interoperability, their security principles remain understudied, and standardized threat modeling is limited; no protocol-centric risk assessment framework has been est..._
- [ ] **[cs.CR]** [CryptoAnalystBench: Failures in Multi-Tool Long-Form LLM Analysis](https://arxiv.org/abs/2602.11304v1) *by Anushri Eswaran et al. (2026-02-11)* - _Modern analyst agents must reason over complex, high token inputs, including dozens of retrieved documents, tool outputs, and time sensitive data. While prior work has produced tool calling benchmarks and examined factuality in knowledge augmented systems, relatively little work studies their intersection: settings where LLMs must integrate large volumes of dynamic, structured and unstructured multi tool outputs. We investigate LLM failure modes in this regime using crypto as a representative hi..._
- [ ] **[cs.AI]** [The PBSAI Governance Ecosystem: A Multi-Agent AI Reference Architecture for Securing Enterprise AI Estates](https://arxiv.org/abs/2602.11301v1) *by John M. Willis (2026-02-11)* - _Enterprises are rapidly deploying large language models, retrieval augmented generation pipelines, and tool using agents into production, often on shared high performance computing clusters and cloud accelerator platforms that also support defensive analytics. These systems increasingly function not as isolated models but as AI estates: socio technical systems spanning models, agents, data pipelines, security tooling, human workflows, and hyperscale infrastructure. Existing governance and securi..._
- [ ] **[cs.SE]** [SWE-MiniSandbox: Container-Free Reinforcement Learning for Building Software Engineering Agents](https://arxiv.org/abs/2602.11210v1) *by Danlong Yuan et al. (2026-02-11)* - _Reinforcement learning (RL) has become a key paradigm for training software engineering (SWE) agents, but existing pipelines typically rely on per-task containers for isolation. At scale, pre-built container images incur substantial storage overhead, slow environment setup, and require container-management privileges. We propose SWE-MiniSandbox, a lightweight, container-free method that enables scalable RL training of SWE agents without sacrificing isolation. Instead of relying on per-instance c..._


## 2026-02-12 Êõ¥Êñ∞ 42 ÁØáÊñ∞ËÆ∫Êñá
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-12Ôºö2602.10090 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning](https://arxiv.org/abs/2602.10090v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-12Ôºö2602.10085 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [CODE-SHARP: Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs](https://arxiv.org/abs/2602.10085v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-12Ôºö2602.09810 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [A Controlled Study of Double DQN and Dueling DQN Under Cross-Environment Transfer](https://arxiv.org/abs/2602.09810v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-12Ôºö2602.09514 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [EcoGym: Evaluating LLMs for Long-Horizon Plan-and-Execute in Interactive Economies](https://arxiv.org/abs/2602.09514v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-12Ôºö2602.09463 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [SpotAgent: Grounding Visual Geo-localization in Large Vision-Language Models through Agentic Reasoning](https://arxiv.org/abs/2602.09463v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-12Ôºö2602.09447 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [SWE-AGI: Benchmarking Specification-Driven Software Construction with MoonBit in the Era of Autonomous Agents](https://arxiv.org/abs/2602.09447v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-12Ôºö2602.08835 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning](https://arxiv.org/abs/2602.08835v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-12Ôºö2602.08412 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [From Assistant to Double Agent: Formalizing and Benchmarking Attacks on OpenClaw for Personalized Local AI Agent](https://arxiv.org/abs/2602.08412v2)
- [ ] **[cs.AI]** [FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight](https://arxiv.org/abs/2602.11136v1) *by Jiayi Zhou et al. (2026-02-11)* - _As LLM-based agents increasingly operate in high-stakes domains with real-world consequences, ensuring their behavioral safety becomes paramount. The dominant oversight paradigm, LLM-as-a-Judge, faces a fundamental dilemma: how can probabilistic systems reliably supervise other probabilistic systems without inheriting their failure modes? We argue that formal verification offers a principled escape from this dilemma, yet its adoption has been hindered by a critical bottleneck: the translation fr..._
- [ ] **[cs.MA]** [Learning to Compose for Cross-domain Agentic Workflow Generation](https://arxiv.org/abs/2602.11114v1) *by Jialiang Wang et al. (2026-02-11)* - _Automatically generating agentic workflows -- executable operator graphs or codes that orchestrate reasoning, verification, and repair -- has become a practical way to solve complex tasks beyond what single-pass LLM generation can reliably handle. Yet what constitutes a good workflow depends heavily on the task distribution and the available operators. Under domain shift, current systems typically rely on iterative workflow refinement to discover a feasible workflow from a large workflow space, ..._
- [ ] **[cs.AI]** [GameDevBench: Evaluating Agentic Capabilities Through Game Development](https://arxiv.org/abs/2602.11103v1) *by Wayne Chi et al. (2026-02-11)* - _Despite rapid progress on coding agents, progress on their multimodal counterparts has lagged behind. A key challenge is the scarcity of evaluation testbeds that combine the complexity of software development with the need for deep multimodal understanding. Game development provides such a testbed as agents must navigate large, dense codebases while manipulating intrinsically multimodal assets such as shaders, sprites, and animations within a visual game scene. We present GameDevBench, the first..._
- [ ] **[eess.SY]** [Interpretable Attention-Based Multi-Agent PPO for Latency Spike Resolution in 6G RAN Slicing](https://arxiv.org/abs/2602.11076v1) *by Kavan Fatehi et al. (2026-02-11)* - _Sixth-generation (6G) radio access networks (RANs) must enforce strict service-level agreements (SLAs) for heterogeneous slices, yet sudden latency spikes remain difficult to diagnose and resolve with conventional deep reinforcement learning (DRL) or explainable RL (XRL). We propose \emph{Attention-Enhanced Multi-Agent Proximal Policy Optimization (AE-MAPPO)}, which integrates six specialized attention mechanisms into multi-agent slice control and surfaces them as zero-cost, faithful explanation..._
- [ ] **[cs.CV]** [Chain-of-Look Spatial Reasoning for Dense Surgical Instrument Counting](https://arxiv.org/abs/2602.11024v1) *by Rishikesh Bhyri et al. (2026-02-11)* - _Accurate counting of surgical instruments in Operating Rooms (OR) is a critical prerequisite for ensuring patient safety during surgery. Despite recent progress of large visual-language models and agentic AI, accurately counting such instruments remains highly challenging, particularly in dense scenarios where instruments are tightly clustered. To address this problem, we introduce Chain-of-Look, a novel visual reasoning framework that mimics the sequential human counting process by enforcing a ..._
- [ ] **[cs.LG]** [OSIL: Learning Offline Safe Imitation Policies with Safety Inferred from Non-preferred Trajectories](https://arxiv.org/abs/2602.11018v1) *by Returaj Burnwal et al. (2026-02-11)* - _This work addresses the problem of offline safe imitation learning (IL), where the goal is to learn safe and reward-maximizing policies from demonstrations that do not have per-timestep safety cost or reward information. In many real-world domains, online learning in the environment can be risky, and specifying accurate safety costs can be difficult. However, it is often feasible to collect trajectories that reflect undesirable or unsafe behavior, implicitly conveying what the agent should avoid..._
- [ ] **[cs.DC]** [Fine-Tuning GPT-5 for GPU Kernel Generation](https://arxiv.org/abs/2602.11000v1) *by Ali Tehrani et al. (2026-02-11)* - _Developing efficient GPU kernels is essential for scaling modern AI systems, yet it remains a complex task due to intricate hardware architectures and the need for specialized optimization expertise. Although Large Language Models (LLMs) demonstrate strong capabilities in general sequential code generation, they face significant challenges in GPU code generation because of the scarcity of high-quality labeled training data, compiler biases when generating synthetic solutions, and limited general..._
- [ ] **[cs.AI]** [CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion](https://arxiv.org/abs/2602.10999v1) *by Yusong Lin et al. (2026-02-11)* - _Agentic coding requires agents to effectively interact with runtime environments, e.g., command line interfaces (CLI), so as to complete tasks like resolving dependency issues, fixing system problems, etc. But it remains underexplored how such environment-intensive tasks can be obtained at scale to enhance agents' capabilities. To address this, based on an analogy between the Dockerfile and the agentic task, we propose to employ agents to simulate and explore environment histories, guided by exe..._
- [ ] **[cs.SE]** [FeatureBench: Benchmarking Agentic Coding for Complex Feature Development](https://arxiv.org/abs/2602.10975v1) *by Qixing Zhou et al. (2026-02-11)* - _Agents powered by large language models (LLMs) are increasingly adopted in the software industry, contributing code as collaborators or even autonomous developers. As their presence grows, it becomes important to assess the current boundaries of their coding abilities. Existing agentic coding benchmarks, however, cover a limited task scope, e.g., bug fixing within a single pull request (PR), and often rely on non-executable evaluations or lack an automated approach for continually updating the e..._
- [ ] **[cs.CR]** [Blind Gods and Broken Screens: Architecting a Secure, Intent-Centric Mobile Agent Operating System](https://arxiv.org/abs/2602.10915v1) *by Zhenhua Zou et al. (2026-02-11)* - _The evolution of Large Language Models (LLMs) has shifted mobile computing from App-centric interactions to system-level autonomous agents. Current implementations predominantly rely on a "Screen-as-Interface" paradigm, which inherits structural vulnerabilities and conflicts with the mobile ecosystem's economic foundations. In this paper, we conduct a systematic security analysis of state-of-the-art mobile agents using Doubao Mobile Assistant as a representative case. We decompose the threat lan..._
- [ ] **[cs.LG]** [ICA: Information-Aware Credit Assignment for Visually Grounded Long-Horizon Information-Seeking Agents](https://arxiv.org/abs/2602.10863v1) *by Cong Pang et al. (2026-02-11)* - _Despite the strong performance achieved by reinforcement learning-trained information-seeking agents, learning in open-ended web environments remains severely constrained by low signal-to-noise feedback. Text-based parsers often discard layout semantics and introduce unstructured noise, while long-horizon training typically relies on sparse outcome rewards that obscure which retrieval actions actually matter. We propose a visual-native search framework that represents webpages as visual snapshot..._
- [ ] **[cs.AI]** [See, Plan, Snap: Evaluating Multimodal GUI Agents in Scratch](https://arxiv.org/abs/2602.10814v1) *by Xingyi Zhang et al. (2026-02-11)* - _Block-based programming environments such as Scratch play a central role in low-code education, yet evaluating the capabilities of AI agents to construct programs through Graphical User Interfaces (GUIs) remains underexplored. We introduce ScratchWorld, a benchmark for evaluating multimodal GUI agents on program-by-construction tasks in Scratch. Grounded in the Use-Modify-Create pedagogical framework, ScratchWorld comprises 83 curated tasks spanning four distinct problem categories: Create, Debu..._
- [ ] **[cs.CL]** [Locomo-Plus: Beyond-Factual Cognitive Memory Evaluation Framework for LLM Agents](https://arxiv.org/abs/2602.10715v1) *by Yifei Li et al. (2026-02-11)* - _Long-term conversational memory is a core capability for LLM-based dialogue systems, yet existing benchmarks and evaluation protocols primarily focus on surface-level factual recall. In realistic interactions, appropriate responses often depend on implicit constraints such as user state, goals, or values that are not explicitly queried later. To evaluate this setting, we introduce \textbf{LoCoMo-Plus}, a benchmark for assessing cognitive memory under cue--trigger semantic disconnect, where model..._
- [ ] **[cs.CL]** [Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters](https://arxiv.org/abs/2602.10604v1) *by Ailin Huang et al. (2026-02-11)* - _We introduce Step 3.5 Flash, a sparse Mixture-of-Experts (MoE) model that bridges frontier-level agentic intelligence and computational efficiency. We focus on what matters most when building agents: sharp reasoning and fast, reliable execution. Step 3.5 Flash pairs a 196B-parameter foundation with 11B active parameters for efficient inference. It is optimized with interleaved 3:1 sliding-window/full attention and Multi-Token Prediction (MTP-3) to reduce the latency and cost of multi-round agent..._
- [ ] **[cs.AI]** [Neuro-symbolic Action Masking for Deep Reinforcement Learning](https://arxiv.org/abs/2602.10598v1) *by Shuai Han et al. (2026-02-11)* - _Deep reinforcement learning (DRL) may explore infeasible actions during training and execution. Existing approaches assume a symbol grounding function that maps high-dimensional states to consistent symbolic representations and a manually specified action masking techniques to constrain actions. In this paper, we propose Neuro-symbolic Action Masking (NSAM), a novel framework that automatically learn symbolic models, which are consistent with given domain constraints of high-dimensional states, ..._
- [ ] **[cs.CL]** [LHAW: Controllable Underspecification for Long-Horizon Tasks](https://arxiv.org/abs/2602.10525v1) *by George Pu et al. (2026-02-11)* - _Long-horizon workflow agents that operate effectively over extended periods are essential for truly autonomous systems. Their reliable execution critically depends on the ability to reason through ambiguous situations in which clarification seeking is necessary to ensure correct task execution. However, progress is limited by the lack of scalable, task-agnostic frameworks for systematically curating and measuring the impact of ambiguity across custom workflows. We address this gap by introducing..._
- [ ] **[cs.RO]** [Co-jump: Cooperative Jumping with Quadrupedal Robots via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.10514v1) *by Shihao Dong et al. (2026-02-11)* - _While single-agent legged locomotion has witnessed remarkable progress, individual robots remain fundamentally constrained by physical actuation limits. To transcend these boundaries, we introduce Co-jump, a cooperative task where two quadrupedal robots synchronize to execute jumps far beyond their solo capabilities. We tackle the high-impulse contact dynamics of this task under a decentralized setting, achieving synchronization without explicit communication or pre-specified motion primitives. ..._
- [ ] **[cs.CR]** [Protecting Context and Prompts: Deterministic Security for Non-Deterministic AI](https://arxiv.org/abs/2602.10481v1) *by Mohan Rajagopalan et al. (2026-02-11)* - _Large Language Model (LLM) applications are vulnerable to prompt injection and context manipulation attacks that traditional security models cannot prevent. We introduce two novel primitives--authenticated prompts and authenticated context--that provide cryptographically verifiable provenance across LLM workflows. Authenticated prompts enable self-contained lineage verification, while authenticated context uses tamper-evident hash chains to ensure integrity of dynamic inputs. Building on these p..._
- [ ] **[cs.AI]** [MERIT Feedback Elicits Better Bargaining in LLM Negotiators](https://arxiv.org/abs/2602.10467v1) *by Jihwan Oh et al. (2026-02-11)* - _Bargaining is often regarded as a logical arena rather than an art or a matter of intuition, yet Large Language Models (LLMs) still struggle to navigate it due to limited strategic depth and difficulty adapting to complex human factors. Current benchmarks rarely capture this limitation. To bridge this gap, we present an utility feedback centric framework. Our contributions are: (i) AgoraBench, a new benchmark spanning nine challenging settings (e.g., deception, monopoly) that supports diverse st..._
- [ ] **[cs.CR]** [Authenticated Workflows: A Systems Approach to Protecting Agentic AI](https://arxiv.org/abs/2602.10465v1) *by Mohan Rajagopalan et al. (2026-02-11)* - _Agentic AI systems automate enterprise workflows but existing defenses--guardrails, semantic filters--are probabilistic and routinely bypassed. We introduce authenticated workflows, the first complete trust layer for enterprise agentic AI. Security reduces to protecting four fundamental boundaries: prompts, tools, data, and context. We enforce intent (operations satisfy organizational policies) and integrity (operations are cryptographically authentic) at every boundary crossing, combining crypt..._
- [ ] **[cs.MA]** [AIvilization v0: Toward Large-Scale Artificial Social Simulation with a Unified Agent Architecture and Adaptive Agent Profiles](https://arxiv.org/abs/2602.10429v1) *by Wenkai Fan et al. (2026-02-11)* - _AIvilization v0 is a publicly deployed large-scale artificial society that couples a resource-constrained sandbox economy with a unified LLM-agent architecture, aiming to sustain long-horizon autonomy while remaining executable under rapidly changing environment. To mitigate the tension between goal stability and reactive correctness, we introduce (i) a hierarchical branch-thinking planner that decomposes life goals into parallel objective branches and uses simulation-guided validation plus tier..._
- [ ] **[cs.LG]** [Affordances Enable Partial World Modeling with LLMs](https://arxiv.org/abs/2602.10390v1) *by Khimya Khetarpal et al. (2026-02-11)* - _Full models of the world require complex knowledge of immense detail. While pre-trained large models have been hypothesized to contain similar knowledge due to extensive pre-training on vast amounts of internet scale data, using them directly in a search procedure is inefficient and inaccurate. Conversely, partial models focus on making high quality predictions for a subset of state and actions: those linked through affordances that achieve user intents~\citep{khetarpal2020can}. Can we posit lar..._
- [ ] **[cs.AI]** [LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation](https://arxiv.org/abs/2602.10367v1) *by Zhiling Yan et al. (2026-02-10)* - _The deployment of Large Language Models (LLMs) in high-stakes clinical settings demands rigorous and reliable evaluation. However, existing medical benchmarks remain static, suffering from two critical limitations: (1) data contamination, where test sets inadvertently leak into training corpora, leading to inflated performance estimates; and (2) temporal misalignment, failing to capture the rapid evolution of medical knowledge. Furthermore, current evaluation metrics for open-ended clinical reas..._
- [ ] **[cs.AI]** [Discovering Differences in Strategic Behavior Between Humans and LLMs](https://arxiv.org/abs/2602.10324v1) *by Caroline Wang et al. (2026-02-10)* - _As Large Language Models (LLMs) are increasingly deployed in social and strategic scenarios, it becomes critical to understand where and why their behavior diverges from that of humans. While behavioral game theory (BGT) provides a framework for analyzing behavior, existing models do not fully capture the idiosyncratic behavior of humans or black-box, non-human agents like LLMs. We employ AlphaEvolve, a cutting-edge program discovery tool, to directly discover interpretable models of human and L..._
- [ ] **[cs.LG]** [Confounding Robust Continuous Control via Automatic Reward Shaping](https://arxiv.org/abs/2602.10305v1) *by Mateo Juliani et al. (2026-02-10)* - _Reward shaping has been applied widely to accelerate Reinforcement Learning (RL) agents' training. However, a principled way of designing effective reward shaping functions, especially for complex continuous control problems, remains largely under-explained. In this work, we propose to automatically learn a reward shaping function for continuous control problems from offline datasets, potentially contaminated by unobserved confounding variables. Specifically, our method builds upon the recently ..._
- [ ] **[cs.LG]** [Self-Evolving Recommendation System: End-To-End Autonomous Model Optimization With LLM Agents](https://arxiv.org/abs/2602.10226v1) *by Haochen Wang et al. (2026-02-10)* - _Optimizing large-scale machine learning systems, such as recommendation models for global video platforms, requires navigating a massive hyperparameter search space and, more critically, designing sophisticated optimizers, architectures, and reward functions to capture nuanced user behaviors. Achieving substantial improvements in these areas is a non-trivial task, traditionally relying on extensive manual iterations to test new hypotheses. We propose a self-evolving system that leverages Large L..._
- [ ] **[quant-ph]** [Quantum Integrated Sensing and Computation with Indefinite Causal Order](https://arxiv.org/abs/2602.10225v1) *by Ivana Nikoloska (2026-02-10)* - _Quantum operations with indefinite causal order (ICO) represent a framework in quantum information processing where the relative order between two events can be indefinite. In this paper, we investigate whether sensing and computation, two canonical tasks in quantum information processing, can be carried out within the ICO framework. We propose a scheme for integrated sensing and computation that uses the same quantum state for both tasks. The quantum state is represented as an agent that perfor..._
- [ ] **[cs.LG]** [Towards Autonomous Mathematics Research](https://arxiv.org/abs/2602.10177v1) *by Tony Feng et al. (2026-02-10)* - _Recent advances in foundational models have yielded reasoning systems capable of achieving a gold-medal standard at the International Mathematical Olympiad. The transition from competition-level problem-solving to professional research, however, requires navigating vast literature and constructing long-horizon proofs. In this work, we introduce Aletheia, a math research agent that iteratively generates, verifies, and revises solutions end-to-end in natural language. Specifically, Aletheia is pow..._
- [ ] **[cs.SE]** [EvoCodeBench: A Human-Performance Benchmark for Self-Evolving LLM-Driven Coding Systems](https://arxiv.org/abs/2602.10171v1) *by Wentao Zhang et al. (2026-02-10)* - _As large language models (LLMs) continue to advance in programming tasks, LLM-driven coding systems have evolved from one-shot code generation into complex systems capable of iterative improvement during inference. However, existing code benchmarks primarily emphasize static correctness and implicitly assume fixed model capability during inference. As a result, they do not capture inference-time self-evolution, such as whether accuracy and efficiency improve as an agent iteratively refines its s..._
- [ ] **[q-bio.QM]** [Beyond SMILES: Evaluating Agentic Systems for Drug Discovery](https://arxiv.org/abs/2602.10163v1) *by Edward Wijaya (2026-02-10)* - _Agentic systems for drug discovery have demonstrated autonomous synthesis planning, literature mining, and molecular design. We ask how well they generalize. Evaluating six frameworks against 15 task classes drawn from peptide therapeutics, in vivo pharmacology, and resource-constrained settings, we find five capability gaps: no support for protein language models or peptide-specific prediction, no bridges between in vivo and in silico data, reliance on LLM inference with no pathway to ML traini..._
- [ ] **[cs.CV]** [AD$^2$: Analysis and Detection of Adversarial Threats in Visual Perception for End-to-End Autonomous Driving Systems](https://arxiv.org/abs/2602.10160v1) *by Ishan Sahu et al. (2026-02-10)* - _End-to-end autonomous driving systems have achieved significant progress, yet their adversarial robustness remains largely underexplored. In this work, we conduct a closed-loop evaluation of state-of-the-art autonomous driving agents under black-box adversarial threat models in CARLA. Specifically, we consider three representative attack vectors on the visual perception pipeline: (i) a physics-based blur attack induced by acoustic waves, (ii) an electromagnetic interference attack that distorts ..._
- [ ] **[cs.SE]** [Can Large Language Models Implement Agent-Based Models? An ODD-based Replication Study](https://arxiv.org/abs/2602.10140v1) *by Nuno Fachada et al. (2026-02-08)* - _Large language models (LLMs) can now synthesize non-trivial executable code from textual descriptions, raising an important question: can LLMs reliably implement agent-based models from standardized specifications in a way that supports replication, verification, and validation? We address this question by evaluating 17 contemporary LLMs on a controlled ODD-to-code translation task, using the PPHPC predator-prey model as a fully specified reference. Generated Python implementations are assessed ..._
- [ ] **[cs.CR]** [Anonymization-Enhanced Privacy Protection for Mobile GUI Agents: Available but Invisible](https://arxiv.org/abs/2602.10139v1) *by Lepeng Zhao et al. (2026-02-08)* - _Mobile Graphical User Interface (GUI) agents have demonstrated strong capabilities in automating complex smartphone tasks by leveraging multimodal large language models (MLLMs) and system-level control interfaces. However, this paradigm introduces significant privacy risks, as agents typically capture and process entire screen contents, thereby exposing sensitive personal data such as phone numbers, addresses, messages, and financial information. Existing defenses either reduce UI exposure, obfu..._
- [ ] **[cs.SE]** [AgentTrace: A Structured Logging Framework for Agent System Observability](https://arxiv.org/abs/2602.10133v1) *by Adam AlSayyad et al. (2026-02-07)* - _Despite the growing capabilities of autonomous agents powered by large language models (LLMs), their adoption in high-stakes domains remains limited. A key barrier is security: the inherently nondeterministic behavior of LLM agents defies static auditing approaches that have historically underpinned software assurance. Existing security methods, such as proxy-level input filtering and model glassboxing, fail to provide sufficient transparency or traceability into agent reasoning, state changes, ..._


## 2026-02-11 Êõ¥Êñ∞ 38 ÁØáÊñ∞ËÆ∫Êñá
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-11Ôºö2602.08586 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [PRISM: A Principled Framework for Multi-Agent Reasoning via Gain Decomposition](https://arxiv.org/abs/2602.08586v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-11Ôºö2602.08533 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Dialogue Model Optimization via Agent Game and Adaptive Tree-based GRPO](https://arxiv.org/abs/2602.08533v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-11Ôºö2602.08268 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Puda: Private User Dataset Agent for User-Sovereign and Privacy-Preserving Personalized AI](https://arxiv.org/abs/2602.08268v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-11Ôºö2602.08023 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [CyberExplorer: Benchmarking LLM Offensive Security Capabilities in a Real-World Attacking Simulation Environment](https://arxiv.org/abs/2602.08023v2)
- [ ] **[cs.AI]** [Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning](https://arxiv.org/abs/2602.10090v1) *by Zhaoyang Wang et al. (2026-02-10)* - _Recent advances in large language model (LLM) have empowered autonomous agents to perform complex tasks that require multi-turn interactions with tools and environments. However, scaling such agent training is limited by the lack of diverse and reliable environments. In this paper, we propose Agent World Model (AWM), a fully synthetic environment generation pipeline. Using this pipeline, we scale to 1,000 environments covering everyday scenarios, in which agents can interact with rich toolsets (..._
- [ ] **[cs.AI]** [CODE-SHARP: Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs](https://arxiv.org/abs/2602.10085v1) *by Richard Bornemann et al. (2026-02-10)* - _Developing agents capable of open-endedly discovering and learning novel skills is a grand challenge in Artificial Intelligence. While reinforcement learning offers a powerful framework for training agents to master complex skills, it typically relies on hand-designed reward functions. This is infeasible for open-ended skill discovery, where the set of meaningful skills is not known a priori. While recent methods have shown promising results towards automating reward function design, they remain..._
- [ ] **[cs.CL]** [Anagent For Enhancing Scientific Table & Figure Analysis](https://arxiv.org/abs/2602.10081v1) *by Xuehang Guo et al. (2026-02-10)* - _In scientific research, analysis requires accurately interpreting complex multimodal knowledge, integrating evidence from different sources, and drawing inferences grounded in domain-specific knowledge. However, current artificial intelligence (AI) systems struggle to consistently demonstrate such capabilities. The complexity and variability of scientific tables and figures, combined with heterogeneous structures and long-context requirements, pose fundamental obstacles to scientific table \& fi..._
- [ ] **[cs.AI]** [Chain of Mindset: Reasoning with Adaptive Cognitive Modes](https://arxiv.org/abs/2602.10063v1) *by Tianyi Jiang et al. (2026-02-10)* - _Human problem-solving is never the repetition of a single mindset, by which we mean a distinct mode of cognitive processing. When tackling a specific task, we do not rely on a single mindset; instead, we integrate multiple mindsets within the single solution process. However, existing LLM reasoning methods fall into a common trap: they apply the same fixed mindset across all steps, overlooking that different stages of solving the same problem require fundamentally different mindsets. This single..._
- [ ] **[cs.AI]** [Discovering High Level Patterns from Simulation Traces](https://arxiv.org/abs/2602.10009v1) *by Sean Memery et al. (2026-02-10)* - _Artificial intelligence (AI) agents embedded in environments with physics-based interaction face many challenges including reasoning, planning, summarization, and question answering. This problem is exacerbated when a human user wishes to either guide or interact with the agent in natural language. Although the use of Language Models (LMs) is the default choice, as an AI tool, they struggle with tasks involving physics. The LM's capability for physical reasoning is learned from observational dat..._
- [ ] **[cs.RO]** [A Collaborative Safety Shield for Safe and Efficient CAV Lane Changes in Congested On-Ramp Merging](https://arxiv.org/abs/2602.10007v1) *by Bharathkumar Hegde et al. (2026-02-10)* - _Lane changing in dense traffic is a significant challenge for Connected and Autonomous Vehicles (CAVs). Existing lane change controllers primarily either ensure safety or collaboratively improve traffic efficiency, but do not consider these conflicting objectives together. To address this, we propose the Multi-Agent Safety Shield (MASS), designed using Control Barrier Functions (CBFs) to enable safe and collaborative lane changes. The MASS enables collaboration by capturing multi-agent interacti..._
- [ ] **[cs.AI]** [Closing Reasoning Gaps in Clinical Agents with Differential Reasoning Learning](https://arxiv.org/abs/2602.09945v1) *by Jinsong Liu et al. (2026-02-10)* - _Clinical decision support requires not only correct answers but also clinically valid reasoning. We propose Differential Reasoning Learning (DRL), a framework that improves clinical agents by learning from reasoning discrepancies. From reference reasoning rationales (e.g., physician-authored clinical rationale, clinical guidelines, or outputs from more capable models) and the agent's free-form chain-of-thought (CoT), DRL extracts reasoning graphs as directed acyclic graphs (DAGs) and performs a ..._
- [ ] **[cs.AI]** [Why Do AI Agents Systematically Fail at Cloud Root Cause Analysis?](https://arxiv.org/abs/2602.09937v1) *by Taeyoon Kim et al. (2026-02-10)* - _Failures in large-scale cloud systems incur substantial financial losses, making automated Root Cause Analysis (RCA) essential for operational stability. Recent efforts leverage Large Language Model (LLM) agents to automate this task, yet existing systems exhibit low detection accuracy even with capable models, and current evaluation frameworks assess only final answer correctness without revealing why the agent's reasoning failed. This paper presents a process level failure analysis of LLM-base..._
- [ ] **[cs.CV]** [Code2World: A GUI World Model via Renderable Code Generation](https://arxiv.org/abs/2602.09856v1) *by Yuhao Zheng et al. (2026-02-10)* - _Autonomous GUI agents interact with environments by perceiving interfaces and executing actions. As a virtual sandbox, the GUI World model empowers agents with human-like foresight by enabling action-conditioned prediction. However, existing text- and pixel-based approaches struggle to simultaneously achieve high visual fidelity and fine-grained structural controllability. To this end, we propose Code2World, a vision-language coder that simulates the next visual state via renderable code generat..._
- [ ] **[cs.NI]** [Hybrid Responsible AI-Stochastic Approach for SLA Compliance in Multivendor 6G Networks](https://arxiv.org/abs/2602.09841v1) *by Emanuel Figetakis et al. (2026-02-10)* - _The convergence of AI and 6G network automation introduces new challenges in maintaining transparency, fairness, and accountability across multivendor management systems. Although closed-loop AI orchestration improves adaptability and self-optimization, it also creates a responsibility gap, where violations of SLAs cannot be causally attributed to specific agents or vendors. This paper presents a hybrid responsible AI-stochastic learning framework that embeds fairness, robustness, and auditabili..._
- [ ] **[cs.AI]** [Efficient Unsupervised Environment Design through Hierarchical Policy Representation Learning](https://arxiv.org/abs/2602.09813v1) *by Dexun Li et al. (2026-02-10)* - _Unsupervised Environment Design (UED) has emerged as a promising approach to developing general-purpose agents through automated curriculum generation. Popular UED methods focus on Open-Endedness, where teacher algorithms rely on stochastic processes for infinite generation of useful environments. This assumption becomes impractical in resource-constrained scenarios where teacher-student interaction opportunities are limited. To address this challenge, we introduce a hierarchical Markov Decision..._
- [ ] **[cs.LG]** [A Controlled Study of Double DQN and Dueling DQN Under Cross-Environment Transfer](https://arxiv.org/abs/2602.09810v1) *by Azka Nasir et al. (2026-02-10)* - _Transfer learning in deep reinforcement learning is often motivated by improved stability and reduced training cost, but it can also fail under substantial domain shift. This paper presents a controlled empirical study examining how architectural differences between Double Deep Q-Networks (DDQN) and Dueling DQN influence transfer behavior across environments. Using CartPole as a source task and LunarLander as a structurally distinct target task, we evaluate a fixed layer-wise representation tran..._
- [ ] **[cs.LG]** [Grounding LTL Tasks in Sub-Symbolic RL Environments for Zero-Shot Generalization](https://arxiv.org/abs/2602.09761v1) *by Matteo Pannacci et al. (2026-02-10)* - _In this work we address the problem of training a Reinforcement Learning agent to follow multiple temporally-extended instructions expressed in Linear Temporal Logic in sub-symbolic environments. Previous multi-task work has mostly relied on knowledge of the mapping between raw observations and symbols appearing in the formulae. We drop this unrealistic assumption by jointly training a multi-task policy and a symbol grounder with the same experience. The symbol grounder is trained only from raw ..._
- [ ] **[cs.CL]** [MATA: Multi-Agent Framework for Reliable and Flexible Table Question Answering](https://arxiv.org/abs/2602.09642v1) *by Sieun Hyeon et al. (2026-02-10)* - _Recent advances in Large Language Models (LLMs) have significantly improved table understanding tasks such as Table Question Answering (TableQA), yet challenges remain in ensuring reliability, scalability, and efficiency, especially in resource-constrained or privacy-sensitive environments. In this paper, we introduce MATA, a multi-agent TableQA framework that leverages multiple complementary reasoning paths and a set of tools built with small language models. MATA generates candidate answers th..._
- [ ] **[cs.CL]** [EcoGym: Evaluating LLMs for Long-Horizon Plan-and-Execute in Interactive Economies](https://arxiv.org/abs/2602.09514v1) *by Xavier Hu et al. (2026-02-10)* - _Long-horizon planning is widely recognized as a core capability of autonomous LLM-based agents; however, current evaluation frameworks suffer from being largely episodic, domain-specific, or insufficiently grounded in persistent economic dynamics. We introduce EcoGym, a generalizable benchmark for continuous plan-and-execute decision making in interactive economies. EcoGym comprises three diverse environments: Vending, Freelance, and Operation, implemented in a unified decision-making process wi..._
- [ ] **[cs.AI]** [SpotAgent: Grounding Visual Geo-localization in Large Vision-Language Models through Agentic Reasoning](https://arxiv.org/abs/2602.09463v1) *by Furong Jia et al. (2026-02-10)* - _Large Vision-Language Models (LVLMs) have demonstrated strong reasoning capabilities in geo-localization, yet they often struggle in real-world scenarios where visual cues are sparse, long-tailed, and highly ambiguous. Previous approaches, bound by internal knowledge, often fail to provide verifiable results, yielding confident but ungrounded predictions when faced with confounded evidence. To address these challenges, we propose SpotAgent, a framework that formalizes geo-localization into an ag..._
- [ ] **[cs.SE]** [SWE-AGI: Benchmarking Specification-Driven Software Construction with MoonBit in the Era of Autonomous Agents](https://arxiv.org/abs/2602.09447v1) *by Zhirui Zhang et al. (2026-02-10)* - _Although large language models (LLMs) have demonstrated impressive coding capabilities, their ability to autonomously build production-scale software from explicit specifications remains an open question. We introduce SWE-AGI, an open-source benchmark for evaluating end-to-end, specification-driven construction of software systems written in MoonBit. SWE-AGI tasks require LLM-based agents to implement parsers, interpreters, binary decoders, and SAT solvers strictly from authoritative standards a..._
- [ ] **[cs.AI]** [P1-VL: Bridging Visual Perception and Scientific Reasoning in Physics Olympiads](https://arxiv.org/abs/2602.09443v1) *by Yun Luo et al. (2026-02-10)* - _The transition from symbolic manipulation to science-grade reasoning represents a pivotal frontier for Large Language Models (LLMs), with physics serving as the critical test anchor for binding abstract logic to physical reality. Physics demands that a model maintain physical consistency with the laws governing the universe, a task that fundamentally requires multimodal perception to ground abstract logic in reality. At the Olympiad level, diagrams are often constitutive rather than illustrative..._
- [ ] **[cs.CR]** [Autonomous Action Runtime Management(AARM):A System Specification for Securing AI-Driven Actions at Runtime](https://arxiv.org/abs/2602.09433v1) *by Herman Errico (2026-02-10)* - _As artificial intelligence systems evolve from passive assistants into autonomous agents capable of executing consequential actions, the security boundary shifts from model outputs to tool execution. Traditional security paradigms - log aggregation, perimeter defense, and post-hoc forensics - cannot protect systems where AI-driven actions are irreversible, execute at machine speed, and originate from potentially compromised orchestration layers. This paper introduces Autonomous Action Runtime Ma..._
- [ ] **[cs.RO]** [Sci-VLA: Agentic VLA Inference Plugin for Long-Horizon Tasks in Scientific Experiments](https://arxiv.org/abs/2602.09430v1) *by Yiwen Pang et al. (2026-02-10)* - _Robotic laboratories play a critical role in autonomous scientific discovery by enabling scalable, continuous experimental execution. Recent vision-language-action (VLA) models offer a promising foundation for robotic laboratories. However, scientific experiments typically involve long-horizon tasks composed of multiple atomic tasks, posing a fundamental challenge to existing VLA models. While VLA models fine-tuned for scientific tasks can reliably execute atomic experimental actions seen during..._
- [ ] **[cs.LG]** [Squeezing More from the Stream : Learning Representation Online for Streaming Reinforcement Learning](https://arxiv.org/abs/2602.09396v1) *by Nilaksh et al. (2026-02-10)* - _In streaming Reinforcement Learning (RL), transitions are observed and discarded immediately after a single update. While this minimizes resource usage for on-device applications, it makes agents notoriously sample-inefficient, since value-based losses alone struggle to extract meaningful representations from transient data. We propose extending Self-Predictive Representations (SPR) to the streaming pipeline to maximize the utility of every observed frame. However, due to the highly correlated s..._
- [ ] **[cs.OS]** [AgentCgroup: Understanding and Controlling OS Resources of AI Agents](https://arxiv.org/abs/2602.09345v1) *by Yusheng Zheng et al. (2026-02-10)* - _AI agents are increasingly deployed in multi-tenant cloud environments, where they execute diverse tool calls within sandboxed containers, each call with distinct resource demands and rapid fluctuations. We present a systematic characterization of OS-level resource dynamics in sandboxed AI coding agents, analyzing 144 software engineering tasks from the SWE-rebench benchmark across two LLM models. Our measurements reveal that (1) OS-level execution (tool calls, container and agent initialization..._
- [ ] **[cs.AI]** [Auditing Multi-Agent LLM Reasoning Trees Outperforms Majority Vote and LLM-as-Judge](https://arxiv.org/abs/2602.09341v1) *by Wei Yang et al. (2026-02-10)* - _Multi-agent systems (MAS) can substantially extend the reasoning capacity of large language models (LLMs), yet most frameworks still aggregate agent outputs with majority voting. This heuristic discards the evidential structure of reasoning traces and is brittle under the confabulation consensus, where agents share correlated biases and converge on the same incorrect rationale. We introduce AgentAuditor, which replaces voting with a path search over a Reasoning Tree that explicitly represents ag..._
- [ ] **[cs.AI]** [Human Control Is the Anchor, Not the Answer: Early Divergence of Oversight in Agentic AI Communities](https://arxiv.org/abs/2602.09286v1) *by Hanjing Shi et al. (2026-02-10)* - _Oversight for agentic AI is often discussed as a single goal ("human control"), yet early adoption may produce role-specific expectations. We present a comparative analysis of two newly active Reddit communities in Jan--Feb 2026 that reflect different socio-technical roles: r/OpenClaw (deployment and operations) and r/Moltbook (agent-centered social interaction). We conceptualize this period as an early-stage crystallization phase, where oversight expectations form before norms reach equilibrium..._
- [ ] **[cs.RO]** [STaR: Scalable Task-Conditioned Retrieval for Long-Horizon Multimodal Robot Memory](https://arxiv.org/abs/2602.09255v1) *by Mingfeng Yuan et al. (2026-02-09)* - _Mobile robots are often deployed over long durations in diverse open, dynamic scenes, including indoor setting such as warehouses and manufacturing facilities, and outdoor settings such as agricultural and roadway operations. A core challenge is to build a scalable long-horizon memory that supports an agentic workflow for planning, retrieval, and reasoning over open-ended instructions at variable granularity, while producing precise, actionable answers for navigation. We present STaR, an agentic..._
- [ ] **[cs.CV]** [VLM-Guided Iterative Refinement for Surgical Image Segmentation with Foundation Models](https://arxiv.org/abs/2602.09252v1) *by Ange Lou et al. (2026-02-09)* - _Surgical image segmentation is essential for robot-assisted surgery and intraoperative guidance. However, existing methods are constrained to predefined categories, produce one-shot predictions without adaptive refinement, and lack mechanisms for clinician interaction. We propose IR-SIS, an iterative refinement system for surgical image segmentation that accepts natural language descriptions. IR-SIS leverages a fine-tuned SAM3 for initial segmentation, employs a Vision-Language Model to detect i..._
- [ ] **[cs.CR]** [MUZZLE: Adaptive Agentic Red-Teaming of Web Agents Against Indirect Prompt Injection Attacks](https://arxiv.org/abs/2602.09222v1) *by Georgios Syros et al. (2026-02-09)* - _Large language model (LLM) based web agents are increasingly deployed to automate complex online tasks by directly interacting with web sites and performing actions on users' behalf. While these agents offer powerful capabilities, their design exposes them to indirect prompt injection attacks embedded in untrusted web content, enabling adversaries to hijack agent behavior and violate user intent. Despite growing awareness of this threat, existing evaluations rely on fixed attack templates, manua..._
- [ ] **[cs.SE]** [AIDev: Studying AI Coding Agents on GitHub](https://arxiv.org/abs/2602.09185v1) *by Hao Li et al. (2026-02-09)* - _AI coding agents are rapidly transforming software engineering by performing tasks such as feature development, debugging, and testing. Despite their growing impact, the research community lacks a comprehensive dataset capturing how these agents are used in real-world projects. To address this gap, we introduce AIDev, a large-scale dataset focused on agent-authored pull requests (Agentic-PRs) in real-world GitHub repositories. AIDev aggregates 932,791 Agentic-PRs produced by five agents: OpenAI ..._
- [ ] **[cs.AI]** [FlyAOC: Evaluating Agentic Ontology Curation of Drosophila Scientific Knowledge Bases](https://arxiv.org/abs/2602.09163v1) *by Xingjian Zhang et al. (2026-02-09)* - _Scientific knowledge bases accelerate discovery by curating findings from primary literature into structured, queryable formats for both human researchers and emerging AI systems. Maintaining these resources requires expert curators to search relevant papers, reconcile evidence across documents, and produce ontology-grounded annotations - a workflow that existing benchmarks, focused on isolated subtasks like named entity recognition or relation extraction, do not capture. We present FlyBench to ..._
- [ ] **[cs.AI]** [CoMMa: Contribution-Aware Medical Multi-Agents From A Game-Theoretic Perspective](https://arxiv.org/abs/2602.09159v1) *by Yichen Wu et al. (2026-02-09)* - _Recent multi-agent frameworks have broadened the ability to tackle oncology decision support tasks that require reasoning over dynamic, heterogeneous patient data. We propose Contribution-Aware Medical Multi-Agents (CoMMa), a decentralized LLM-agent framework in which specialists operate on partitioned evidence and coordinate through a game-theoretic objective for robust decision-making. In contrast to most agent architectures relying on stochastic narrative-based reasoning, CoMMa utilizes deter..._
- [ ] **[cs.RO]** [SceneSmith: Agentic Generation of Simulation-Ready Indoor Scenes](https://arxiv.org/abs/2602.09153v1) *by Nicholas Pfaff et al. (2026-02-09)* - _Simulation has become a key tool for training and evaluating home robots at scale, yet existing environments fail to capture the diversity and physical complexity of real indoor spaces. Current scene synthesis methods produce sparsely furnished rooms that lack the dense clutter, articulated furniture, and physical properties essential for robotic manipulation. We introduce SceneSmith, a hierarchical agentic framework that generates simulation-ready indoor environments from natural language promp..._
- [ ] **[cs.AI]** [PABU: Progress-Aware Belief Update for Efficient LLM Agents](https://arxiv.org/abs/2602.09138v1) *by Haitao Jiang et al. (2026-02-09)* - _Large Language Model (LLM) agents commonly condition actions on full action-observation histories, which introduce task-irrelevant information that easily leads to redundant actions and higher inference cost. We propose Progress-Aware Belief Update (PABU), a belief-state framework that compactly represents an agent's state by explicitly modeling task progress and selectively retaining past actions and observations. At each step, the agent predicts its relative progress since the previous round a..._
- [ ] **[cs.CV]** [UI-Venus-1.5 Technical Report](https://arxiv.org/abs/2602.09082v1) *by Veuns-Team et al. (2026-02-09)* - _GUI agents have emerged as a powerful paradigm for automating interactions in digital environments, yet achieving both broad generality and consistently strong task performance remains challenging.In this report, we present UI-Venus-1.5, a unified, end-to-end GUI Agent designed for robust real-world applications.The proposed model family comprises two dense variants (2B and 8B) and one mixture-of-experts variant (30B-A3B) to meet various downstream application scenarios.Compared to our previous ..._
- [ ] **[q-bio.GN]** [scBench: Evaluating AI Agents on Single-Cell RNA-seq Analysis](https://arxiv.org/abs/2602.09063v1) *by Kenny Workman et al. (2026-02-09)* - _As single-cell RNA sequencing datasets grow in adoption, scale, and complexity, data analysis remains a bottleneck for many research groups. Although frontier AI agents have improved dramatically at software engineering and general data analysis, it remains unclear whether they can extract biological insight from messy, real-world single-cell datasets. We introduce scBench, a benchmark of 394 verifiable problems derived from practical scRNA-seq workflows spanning six sequencing platforms and sev..._


## 2026-02-10 Êõ¥Êñ∞ 96 ÁØáÊñ∞ËÆ∫Êñá
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-10Ôºö2602.06855 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents](https://arxiv.org/abs/2602.06855v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-10Ôºö2602.06841 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [From Features to Actions: Explainability in Traditional and Agentic AI Systems](https://arxiv.org/abs/2602.06841v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-10Ôºö2602.05818 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [TKG-Thinker: Towards Dynamic Reasoning over Temporal Knowledge Graphs via Agentic Reinforcement Learning](https://arxiv.org/abs/2602.05818v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-10Ôºö2602.05656 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Alignment Verifiability in Large Language Models: Normative Indistinguishability under Behavioral Evaluation](https://arxiv.org/abs/2602.05656v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-10Ôºö2602.05636 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Generative Ontology: When Structured Knowledge Learns to Create](https://arxiv.org/abs/2602.05636v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-10Ôºö2602.05625 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Reactive Knowledge Representation and Asynchronous Reasoning](https://arxiv.org/abs/2602.05625v2)
- [ ] **[cs.RO]** [Robustness Is a Function, Not a Number: A Factorized Comprehensive Study of OOD Robustness in Vision-Based Driving](https://arxiv.org/abs/2602.09018v1) *by Amir Mallak et al. (2026-02-09)* - _Out of distribution (OOD) robustness in autonomous driving is often reduced to a single number, hiding what breaks a policy. We decompose environments along five axes: scene (rural/urban), season, weather, time (day/night), and agent mix; and measure..._
- [ ] **[cs.LG]** [Next-Gen CAPTCHAs: Leveraging the Cognitive Gap for Scalable and Diverse GUI-Agent Defense](https://arxiv.org/abs/2602.09012v1) *by Jiacheng Liu et al. (2026-02-09)* - _The rapid evolution of GUI-enabled agents has rendered traditional CAPTCHAs obsolete. While previous benchmarks like OpenCaptchaWorld established a baseline for evaluating multimodal agents, recent advancements in reasoning-heavy models, such as Gemi..._
- [ ] **[cs.RO]** [From Obstacles to Etiquette: Robot Social Navigation with VLM-Informed Path Selection](https://arxiv.org/abs/2602.09002v1) *by Zilin Fang et al. (2026-02-09)* - _Navigating socially in human environments requires more than satisfying geometric constraints, as collision-free paths may still interfere with ongoing activities or conflict with social norms. Addressing this challenge calls for analyzing interactio..._
- [ ] **[cs.AI]** [InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery](https://arxiv.org/abs/2602.08990v1) *by Shiyang Feng et al. (2026-02-09)* - _We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verifica..._
- [ ] **[cs.AI]** [stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation](https://arxiv.org/abs/2602.08968v1) *by Lucas Maes et al. (2026-02-09)* - _World Models have emerged as a powerful paradigm for learning compact, predictive representations of environment dynamics, enabling agents to reason, plan, and generalize beyond direct experience. Despite recent interest in World Models, most availab..._
- [ ] **[cs.LG]** [A Behavioural and Representational Evaluation of Goal-Directedness in Language Model Agents](https://arxiv.org/abs/2602.08964v1) *by Raghu Arghal et al. (2026-02-09)* - _Understanding an agent's goals helps explain and predict its behaviour, yet there is no established methodology for reliably attributing goals to agentic systems. We propose a framework for evaluating goal-directedness that integrates behavioural eva..._
- [ ] **[cs.AI]** [Digital Twin and Agentic AI for Wild Fire Disaster Management: Intelligent Virtual Situation Room](https://arxiv.org/abs/2602.08949v1) *by Mohammad Morsali et al. (2026-02-09)* - _According to the United Nations, wildfire frequency and intensity are projected to increase by approximately 14% by 2030 and 30% by 2050 due to global warming, posing critical threats to life, infrastructure, and ecosystems. Conventional disaster man..._
- [ ] **[cs.AI]** [CoRefine: Confidence-Guided Self-Refinement for Adaptive Test-Time Compute](https://arxiv.org/abs/2602.08948v1) *by Chen Jin et al. (2026-02-09)* - _Large Language Models (LLMs) often rely on test-time scaling via parallel decoding (for example, 512 samples) to boost reasoning accuracy, but this incurs substantial compute. We introduce CoRefine, a confidence-guided self-refinement method that ach..._
- [ ] **[cs.HC]** [pixelLOG: Logging of Online Gameplay for Cognitive Research](https://arxiv.org/abs/2602.08941v1) *by Zeyu Lu et al. (2026-02-09)* - _Traditional cognitive assessments often rely on isolated, output-focused measurements that may fail to capture the complexity of human cognition in naturalistic settings. We present pixelLOG, a high-performance data collection framework for Spigot-ba..._
- [ ] **[cs.HC]** [Gesturing Toward Abstraction: Multimodal Convention Formation in Collaborative Physical Tasks](https://arxiv.org/abs/2602.08914v1) *by Kiyosu Maeda et al. (2026-02-09)* - _A quintessential feature of human intelligence is the ability to create ad hoc conventions over time to achieve shared goals efficiently. We investigate how communication strategies evolve through repeated collaboration as people coordinate on shared..._
- [ ] **[cs.LG]** [Dr. MAS: Stable Reinforcement Learning for Multi-Agent LLM Systems](https://arxiv.org/abs/2602.08847v1) *by Lang Feng et al. (2026-02-09)* - _Multi-agent LLM systems enable advanced reasoning and tool use via role specialization, yet reliable reinforcement learning (RL) post-training for such systems remains difficult. In this work, we theoretically pinpoint a key reason for training insta..._
- [ ] **[cs.AI]** [Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning](https://arxiv.org/abs/2602.08835v1) *by Andr√©s Holgado-S√°nchez et al. (2026-02-09)* - _Value-aware AI should recognise human values and adapt to the value systems (value-based preferences) of different users. This requires operationalization of values, which can be prone to misspecification. The social nature of values demands their re..._
- [ ] **[cs.SE]** [Taming Scylla: Understanding the multi-headed agentic daemon of the coding seas](https://arxiv.org/abs/2602.08765v1) *by Micah Villmow (2026-02-09)* - _LLM-based tools are automating more software development tasks at a rapid pace, but there is no rigorous way to evaluate how different architectural choices -- prompts, skills, tools, multi-agent setups -- materially affect both capability and cost. ..._
- [ ] **[cs.NI]** [6G-Bench: An Open Benchmark for Semantic Communication and Network-Level Reasoning with Foundation Models in AI-Native 6G Networks](https://arxiv.org/abs/2602.08675v1) *by Mohamed Amine Ferrag et al. (2026-02-09)* - _This paper introduces 6G-Bench, an open benchmark for evaluating semantic communication and network-level reasoning in AI-native 6G networks. 6G-Bench defines a taxonomy of 30 decision-making tasks (T1--T30) extracted from ongoing 6G and AI-agent sta..._
- [ ] **[cs.AI]** [OSCAR: Optimization-Steered Agentic Planning for Composed Image Retrieval](https://arxiv.org/abs/2602.08603v1) *by Teng Wang et al. (2026-02-09)* - _Composed image retrieval (CIR) requires complex reasoning over heterogeneous visual and textual constraints. Existing approaches largely fall into two paradigms: unified embedding retrieval, which suffers from single-model myopia, and heuristic agent..._
- [ ] **[cs.AI]** [PRISM: A Principled Framework for Multi-Agent Reasoning via Gain Decomposition](https://arxiv.org/abs/2602.08586v1) *by Yiming Yang et al. (2026-02-09)* - _Multi-agent collaboration has emerged as a promising paradigm for enhancing reasoning capabilities of Large Language Models (LLMs). However, existing approaches remain largely heuristic, lacking principled guidance on what drives performance gains an..._
- [ ] **[cs.HC]** [Agent-Supported Foresight for AI Systemic Risks: AI Agents for Breadth, Experts for Judgment](https://arxiv.org/abs/2602.08565v1) *by Leon Fr√∂hling et al. (2026-02-09)* - _AI impact assessments often stress near-term risks because human judgment degrades over longer horizons, exemplifying the Collingridge dilemma: foresight is most needed when knowledge is scarcest. To address long-term systemic risks, we introduce a s..._
- [ ] **[cs.LG]** [Stateless Yet Not Forgetful: Implicit Memory as a Hidden Channel in LLMs](https://arxiv.org/abs/2602.08563v1) *by Ahmed Salem et al. (2026-02-09)* - _Large language models (LLMs) are commonly treated as stateless: once an interaction ends, no information is assumed to persist unless it is explicitly stored and re-supplied. We challenge this assumption by introducing implicit memory-the ability of ..._
- [ ] **[cs.CL]** [GISA: A Benchmark for General Information-Seeking Assistant](https://arxiv.org/abs/2602.08543v1) *by Yutao Zhu et al. (2026-02-09)* - _The advancement of large language models (LLMs) has significantly accelerated the development of search agents capable of autonomously gathering information through multi-turn web interactions. Various benchmarks have been proposed to evaluate such a..._
- [ ] **[cs.AI]** [Dialogue Model Optimization via Agent Game and Adaptive Tree-based GRPO](https://arxiv.org/abs/2602.08533v1) *by Kun Peng et al. (2026-02-09)* - _Open-ended dialogue agents aim to deliver engaging, personalized interactions by adapting to users' traits, but existing methods face critical limitations: over-reliance on pre-collected user data, and short-horizon biases in reinforcement learning (..._
- [ ] **[cs.NI]** [Decentralized Spatial Reuse Optimization in Wi-Fi: An Internal Regret Minimization Approach](https://arxiv.org/abs/2602.08456v1) *by Francesc Wilhelmi et al. (2026-02-09)* - _Spatial Reuse (SR) is a cost-effective technique for improving spectral efficiency in dense IEEE 802.11 deployments by enabling simultaneous transmissions. However, the decentralized optimization of SR parameters -- transmission power and Carrier Sen..._
- [ ] **[cs.AI]** [When Evaluation Becomes a Side Channel: Regime Leakage and Structural Mitigations for Alignment Assessment](https://arxiv.org/abs/2602.08449v1) *by Igor Santos-Grueiro (2026-02-09)* - _Safety evaluation for advanced AI systems implicitly assumes that behavior observed under evaluation is predictive of behavior in deployment. This assumption becomes fragile for agents with situational awareness, which may exploitregime leakage-infor..._
- [ ] **[cs.AI]** [From Assistant to Double Agent: Formalizing and Benchmarking Attacks on OpenClaw for Personalized Local AI Agent](https://arxiv.org/abs/2602.08412v1) *by Yuhang Wang et al. (2026-02-09)* - _Although large language model (LLM)-based agents, exemplified by OpenClaw, are increasingly evolving from task-oriented systems into personalized AI assistants for solving complex real-world tasks, their practical deployment also introduces severe se..._
- [ ] **[cs.AI]** [On Protecting Agentic Systems' Intellectual Property via Watermarking](https://arxiv.org/abs/2602.08401v1) *by Liwen Wang et al. (2026-02-09)* - _The evolution of Large Language Models (LLMs) into agentic systems that perform autonomous reasoning and tool use has created significant intellectual property (IP) value. We demonstrate that these systems are highly vulnerable to imitation attacks, ..._
- [ ] **[cs.AI]** [SCOUT-RAG: Scalable and Cost-Efficient Unifying Traversal for Agentic Graph-RAG over Distributed Domains](https://arxiv.org/abs/2602.08400v1) *by Longkun Li et al. (2026-02-09)* - _Graph-RAG improves LLM reasoning using structured knowledge, yet conventional designs rely on a centralized knowledge graph. In distributed and access-restricted settings (e.g., hospitals or multinational organizations), retrieval must select relevan..._
- [ ] **[cs.MA]** [Altruism and Fair Objective in Mixed-Motive Markov games](https://arxiv.org/abs/2602.08389v1) *by Yao-hua Franck Xu et al. (2026-02-09)* - _Cooperation is fundamental for society's viability, as it enables the emergence of structure within heterogeneous groups that seek collective well-being. However, individuals are inclined to defect in order to benefit from the group's cooperation wit..._
- [ ] **[cs.AI]** [Grounding Generative Planners in Verifiable Logic: A Hybrid Architecture for Trustworthy Embodied AI](https://arxiv.org/abs/2602.08373v1) *by Feiyu Wu et al. (2026-02-09)* - _Large Language Models (LLMs) show promise as planners for embodied AI, but their stochastic nature lacks formal reasoning, preventing strict safety guarantees for physical deployment. Current approaches often rely on unreliable LLMs for safety checks..._
- [ ] **[cs.AI]** [MemAdapter: Fast Alignment across Agent Memory Paradigms via Generative Subgraph Retrieval](https://arxiv.org/abs/2602.08369v1) *by Xin Zhang et al. (2026-02-09)* - _Memory mechanism is a core component of LLM-based agents, enabling reasoning and knowledge discovery over long-horizon contexts. Existing agent memory systems are typically designed within isolated paradigms (e.g., explicit, parametric, or latent mem..._
- [ ] **[cs.AI]** [Who Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System](https://arxiv.org/abs/2602.08335v1) *by Yanming Li et al. (2026-02-09)* - _Integrating Large Language Models (LLMs) with external tools via multi-agent systems offers a promising new paradigm for decomposing and solving complex problems. However, training these systems remains notoriously difficult due to the credit assignm..._
- [ ] **[cs.SE]** [SWE Context Bench: A Benchmark for Context Learning in Coding](https://arxiv.org/abs/2602.08316v1) *by Jared Zhu et al. (2026-02-09)* - _Large language models are increasingly used as programming agents for repository level software engineering tasks. While recent benchmarks evaluate correctness in realistic codebases, they largely treat tasks as independent and do not assess whether ..._
- [ ] **[cs.AI]** [Toward Formalizing LLM-Based Agent Designs through Structural Context Modeling and Semantic Dynamics Analysis](https://arxiv.org/abs/2602.08276v1) *by Haoyu Jia et al. (2026-02-09)* - _Current research on large language model (LLM) agents is fragmented: discussions of conceptual frameworks and methodological principles are frequently intertwined with low-level implementation details, causing both readers and authors to lose track a..._
- [ ] **[cs.LG]** [When Do Multi-Agent Systems Outperform? Analysing the Learning Efficiency of Agentic Systems](https://arxiv.org/abs/2602.08272v1) *by Junwei Su et al. (2026-02-09)* - _Reinforcement Learning (RL) has emerged as a crucial method for training or fine-tuning large language models (LLMs), enabling adaptive, task-specific optimizations through interactive feedback. Multi-Agent Reinforcement Learning (MARL), in particula..._
- [ ] **[cs.AI]** [Puda: Private User Dataset Agent for User-Sovereign and Privacy-Preserving Personalized AI](https://arxiv.org/abs/2602.08268v1) *by Akinori Maeda et al. (2026-02-09)* - _Personal data centralization among dominant platform providers including search engines, social networking services, and e-commerce has created siloed ecosystems that restrict user sovereignty, thereby impeding data use across services. Meanwhile, th..._
- [ ] **[cs.AI]** [SynthAgent: A Multi-Agent LLM Framework for Realistic Patient Simulation -- A Case Study in Obesity with Mental Health Comorbidities](https://arxiv.org/abs/2602.08254v1) *by Arman Aghaee et al. (2026-02-09)* - _Simulating high-fidelity patients offers a powerful avenue for studying complex diseases while addressing the challenges of fragmented, biased, and privacy-restricted real-world data. In this study, we introduce SynthAgent, a novel Multi-Agent System..._
- [ ] **[cs.CL]** [When Benign Inputs Lead to Severe Harms: Eliciting Unsafe Unintended Behaviors of Computer-Use Agents](https://arxiv.org/abs/2602.08235v1) *by Jaylen Jones et al. (2026-02-09)* - _Although computer-use agents (CUAs) hold significant potential to automate increasingly complex OS workflows, they can demonstrate unsafe unintended behaviors that deviate from expected outcomes even under benign input contexts. However, exploration ..._
- [ ] **[cs.AI]** [Weak-Driven Learning: How Weak Agents make Strong Agents Stronger](https://arxiv.org/abs/2602.08222v1) *by Zehao Chen et al. (2026-02-09)* - _As post-training optimization becomes central to improving large language models, we observe a persistent saturation bottleneck: once models grow highly confident, further training yields diminishing returns. While existing methods continue to reinfo..._
- [ ] **[cs.LG]** [Dreaming in Code for Curriculum Learning in Open-Ended Worlds](https://arxiv.org/abs/2602.08194v1) *by Konstantinos Mitsides et al. (2026-02-09)* - _Open-ended learning frames intelligence as emerging from continual interaction with an ever-expanding space of environments. While recent advances have utilized foundation models to programmatically generate diverse environments, these approaches oft..._
- [ ] **[cs.CL]** [DIAL-SUMMER: A Structured Evaluation Framework of Hierarchical Errors in Dialogue Summaries](https://arxiv.org/abs/2602.08149v1) *by Sahana Ramnath et al. (2026-02-08)* - _Dialogues are a predominant mode of communication for humans, and it is immensely helpful to have automatically generated summaries of them (e.g., to revise key points discussed in a meeting, to review conversations between customer agents and produc..._
- [ ] **[cs.AI]** [Initial Risk Probing and Feasibility Testing of Glow: a Generative AI-Powered Dialectical Behavior Therapy Skills Coach for Substance Use Recovery and HIV Prevention](https://arxiv.org/abs/2602.08121v1) *by Liying Wang et al. (2026-02-08)* - _Background: HIV and substance use represent interacting epidemics with shared psychological drivers - impulsivity and maladaptive coping. Dialectical behavior therapy (DBT) targets these mechanisms but faces scalability challenges. Generative artific..._
- [ ] **[cs.AI]** [Interpretable Failure Analysis in Multi-Agent Reinforcement Learning Systems](https://arxiv.org/abs/2602.08104v1) *by Risal Shahriar Shefin et al. (2026-02-08)* - _Multi-Agent Reinforcement Learning (MARL) is increasingly deployed in safety-critical domains, yet methods for interpretable failure detection and attribution remain underdeveloped. We introduce a two-stage gradient-based framework that provides inte..._
- [ ] **[cs.AI]** [Objective Decoupling in Social Reinforcement Learning: Recovering Ground Truth from Sycophantic Majorities](https://arxiv.org/abs/2602.08092v1) *by Majid Ghasemi et al. (2026-02-08)* - _Contemporary AI alignment strategies rely on a fragile premise: that human feedback, while noisy, remains a fundamentally truthful signal. In this paper, we identify this assumption as Dogma 4 of Reinforcement Learning (RL). We demonstrate that while..._
- [ ] **[physics.soc-ph]** [Large language models for spreading dynamics in complex systems](https://arxiv.org/abs/2602.08085v1) *by Shuyu Jiang et al. (2026-02-08)* - _Spreading dynamics is a central topic in the physics of complex systems and network science, providing a unified framework for understanding how information, behaviors, and diseases propagate through interactions among system units. In many propagati..._
- [ ] **[cs.LG]** [Spectral Guardrails for Agents in the Wild: Detecting Tool Use Hallucinations via Attention Topology](https://arxiv.org/abs/2602.08082v1) *by Valentin No√´l (2026-02-08)* - _Deploying autonomous agents in the wild requires reliable safeguards against tool use failures. We propose a training free guardrail based on spectral analysis of attention topology that complements supervised approaches. On Llama 3.1 8B, our method ..._
- [ ] **[cs.AI]** [Graph-Enhanced Deep Reinforcement Learning for Multi-Objective Unrelated Parallel Machine Scheduling](https://arxiv.org/abs/2602.08052v1) *by Bulent Soykan et al. (2026-02-08)* - _The Unrelated Parallel Machine Scheduling Problem (UPMSP) with release dates, setups, and eligibility constraints presents a significant multi-objective challenge. Traditional methods struggle to balance minimizing Total Weighted Tardiness (TWT) and ..._
- [ ] **[cs.LG]** [Implicit Strategic Optimization: Rethinking Long-Horizon Decision-Making in Adversarial Poker Environments](https://arxiv.org/abs/2602.08041v1) *by Boyang Xia et al. (2026-02-08)* - _Training large language model (LLM) agents for adversarial games is often driven by episodic objectives such as win rate. In long-horizon settings, however, payoffs are shaped by latent strategic externalities that evolve over time, so myopic optimiz..._
- [ ] **[cs.CR]** [CyberExplorer: Benchmarking LLM Offensive Security Capabilities in a Real-World Attacking Simulation Environment](https://arxiv.org/abs/2602.08023v1) *by Nanda Rani et al. (2026-02-08)* - _Real-world offensive security operations are inherently open-ended: attackers explore unknown attack surfaces, revise hypotheses under uncertainty, and operate without guaranteed success. Existing LLM-based offensive agent evaluations rely on closed-..._
- [ ] **[cs.CR]** [ICBAC: an Intelligent Contract-Based Access Control framework for supply chain management by integrating blockchain and federated learning](https://arxiv.org/abs/2602.08014v1) *by Sadegh Sohani et al. (2026-02-08)* - _This paper addresses the critical challenge of access control in modern supply chains, which operate across multiple independent and competing organizations. Existing access control is static and centralized, unable to adapt to insider threats or evo..._
- [ ] **[cs.AI]** [Small Agent Group is the Future of Digital Health](https://arxiv.org/abs/2602.08013v1) *by Yuqiao Meng et al. (2026-02-08)* - _The rapid adoption of large language models (LLMs) in digital health has been driven by a "scaling-first" philosophy, i.e., the assumption that clinical intelligence increases with model size and data. However, real-world clinical needs include not o..._
- [ ] **[cs.AI]** [Towards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective](https://arxiv.org/abs/2602.08009v1) *by Rui Li et al. (2026-02-08)* - _Multi-agent architectures built on large language models (LLMs) have demonstrated the potential to realize swarm intelligence through well-crafted collaboration. However, the substantial burden of manual orchestration inherently raises an imperative ..._
- [ ] **[cs.CL]** [DeltaKV: Residual-Based KV Cache Compression via Long-Range Similarity](https://arxiv.org/abs/2602.08005v1) *by Jitai Hao et al. (2026-02-08)* - _The deployment of efficient long-context LLMs in applications like autonomous agents, long-chain reasoning, and creative writing is fundamentally bottlenecked by the linear growth of KV cache memory. Existing compression and eviction methods often st..._
- [ ] **[cs.AI]** [Accelerating Social Science Research via Agentic Hypothesization and Experimentation](https://arxiv.org/abs/2602.07983v1) *by Jishu Sen Gupta et al. (2026-02-08)* - _Data-driven social science research is inherently slow, relying on iterative cycles of observation, hypothesis generation, and experimental validation. While recent data-driven methods promise to accelerate parts of this process, they largely fail to..._
- [ ] **[cs.AI]** [LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth](https://arxiv.org/abs/2602.07962v1) *by Weihao Zeng et al. (2026-02-08)* - _Large language models (LLMs) are increasingly capable of carrying out long-running, real-world tasks. However, as the amount of context grows, their reliability often deteriorates, a phenomenon known as "context rot". Existing long-context benchmarks..._
- [ ] **[cs.AI]** [IV Co-Scientist: Multi-Agent LLM Framework for Causal Instrumental Variable Discovery](https://arxiv.org/abs/2602.07943v1) *by Ivaxi Sheth et al. (2026-02-08)* - _In the presence of confounding between an endogenous variable and the outcome, instrumental variables (IVs) are used to isolate the causal effect of the endogenous variable. Identifying valid instruments requires interdisciplinary knowledge, creativi..._
- [ ] **[cs.LG]** [AceGRPO: Adaptive Curriculum Enhanced Group Relative Policy Optimization for Autonomous Machine Learning Engineering](https://arxiv.org/abs/2602.07906v1) *by Yuzhu Cai et al. (2026-02-08)* - _Autonomous Machine Learning Engineering (MLE) requires agents to perform sustained, iterative optimization over long horizons. While recent LLM-based agents show promise, current prompt-based agents for MLE suffer from behavioral stagnation due to fr..._
- [ ] **[cs.AI]** [MedCoG: Maximizing LLM Inference Density in Medical Reasoning via Meta-Cognitive Regulation](https://arxiv.org/abs/2602.07905v1) *by Yu Zhao et al. (2026-02-08)* - _Large Language Models (LLMs) have shown strong potential in complex medical reasoning yet face diminishing gains under inference scaling laws. While existing studies augment LLMs with various knowledge types, it remains unclear how effectively the ad..._
- [ ] **[cs.SE]** [Rethinking the Value of Agent-Generated Tests for LLM-Based Software Engineering Agents](https://arxiv.org/abs/2602.07900v1) *by Zhi Chen et al. (2026-02-08)* - _Large Language Model (LLM) code agents increasingly resolve repository-level issues by iteratively editing code, invoking tools, and validating candidate patches. In these workflows, agents often write tests on the fly, a paradigm adopted by many hig..._
- [ ] **[cs.AI]** [MemFly: On-the-Fly Memory Optimization via Information Bottleneck](https://arxiv.org/abs/2602.07885v1) *by Zhenyuan Zhang et al. (2026-02-08)* - _Long-term memory enables large language model agents to tackle complex tasks through historical interactions. However, existing frameworks encounter a fundamental dilemma between compressing redundant information efficiently and maintaining precise r..._
- [ ] **[cs.AI]** [ToolSelf: Unifying Task Execution and Self-Reconfiguration via Tool-Driven Intrinsic Adaptation](https://arxiv.org/abs/2602.07883v1) *by Jingqi Zhou et al. (2026-02-08)* - _Agentic systems powered by Large Language Models (LLMs) have demonstrated remarkable potential in tackling complex, long-horizon tasks. However, their efficacy is fundamentally constrained by static configurations governing agent behaviors, which are..._
- [ ] **[cs.CL]** [TodoEvolve: Learning to Architect Agent Planning Systems](https://arxiv.org/abs/2602.07839v1) *by Jiaxi Liu et al. (2026-02-08)* - _Planning has become a central capability for contemporary agent systems in navigating complex, long-horizon tasks, yet existing approaches predominantly rely on fixed, hand-crafted planning structures that lack the flexibility to adapt to the structu..._
- [ ] **[cs.CV]** [VideoTemp-o3: Harmonizing Temporal Grounding and Video Understanding in Agentic Thinking-with-Videos](https://arxiv.org/abs/2602.07801v1) *by Wenqi Liu et al. (2026-02-08)* - _In long-video understanding, conventional uniform frame sampling often fails to capture key visual evidence, leading to degraded performance and increased hallucinations. To address this, recent agentic thinking-with-videos paradigms have emerged, ad..._
- [ ] **[cs.AI]** [Do Multi-Agents Dream of Electric Screens? Achieving Perfect Accuracy on AndroidWorld Through Task Decomposition](https://arxiv.org/abs/2602.07787v1) *by Pierre-Louis Favreau et al. (2026-02-08)* - _We present Minitap, a multi-agent system that achieves 100% success on the AndroidWorld benchmark, the first to fully solve all 116 tasks and surpassing human performance (80%). We first analyze why single-agent architectures fail: context pollution ..._
- [ ] **[cs.AI]** [Learning to Continually Learn via Meta-learning Agentic Memory Designs](https://arxiv.org/abs/2602.07755v1) *by Yiming Xiong et al. (2026-02-08)* - _The statelessness of foundation models bottlenecks agentic systems' ability to continually learn, a core capability for long-horizon reasoning and adaptation. To address this limitation, agentic systems commonly incorporate memory modules to retain a..._
- [ ] **[cs.AI]** [Geo-Code: A Code Framework for Reverse Code Generation from Geometric Images Based on Two-Stage Multi-Agent Evolution](https://arxiv.org/abs/2602.07749v1) *by Zhenyu Wu et al. (2026-02-08)* - _Program code serves as a bridge linking vision and logic, providing a feasible supervisory approach for enhancing the multimodal reasoning capability of large models through geometric operations such as auxiliary line construction and perspective tra..._
- [ ] **[cs.CV]** [Looking and Listening Inside and Outside: Multimodal Artificial Intelligence Systems for Driver Safety Assessment and Intelligent Vehicle Decision-Making](https://arxiv.org/abs/2602.07668v1) *by Ross Greer et al. (2026-02-07)* - _The looking-in-looking-out (LILO) framework has enabled intelligent vehicle applications that understand both the outside scene and the driver state to improve safety outcomes, with examples in smart airbag deployment, takeover time prediction in aut..._
- [ ] **[cs.CR]** [Agent-Fence: Mapping Security Vulnerabilities Across Deep Research Agents](https://arxiv.org/abs/2602.07652v1) *by Sai Puppala et al. (2026-02-07)* - _Large language models are increasingly deployed as *deep agents* that plan, maintain persistent state, and invoke external tools, shifting safety failures from unsafe text to unsafe *trajectories*. We introduce **AgentFence**, an architecture-centric..._
- [ ] **[cs.CV]** [AD-MIR: Bridging the Gap from Perception to Persuasion in Advertising Video Understanding via Structured Reasoning](https://arxiv.org/abs/2602.07625v1) *by Binxiao Xu et al. (2026-02-07)* - _Multimodal understanding of advertising videos is essential for interpreting the intricate relationship between visual storytelling and abstract persuasion strategies. However, despite excelling at general search, existing agents often struggle to br..._
- [ ] **[cs.AI]** [M2A: Multimodal Memory Agent with Dual-Layer Hybrid Memory for Long-Term Personalized Interactions](https://arxiv.org/abs/2602.07624v1) *by Junyu Feng et al. (2026-02-07)* - _This work addresses the challenge of personalized question answering in long-term human-machine interactions: when conversational history spans weeks or months and exceeds the context window, existing personalization mechanisms struggle to continuous..._
- [ ] **[cs.CV]** [VISOR: VIsual Spatial Object Reasoning for Language-driven Object Navigation](https://arxiv.org/abs/2602.07555v1) *by Francesco Taioli et al. (2026-02-07)* - _Language-driven object navigation requires agents to interpret natural language descriptions of target objects, which combine intrinsic and extrinsic attributes for instance recognition and commonsense navigation. Existing methods either (i) use end-..._
- [ ] **[cs.AI]** [When Is Enough Not Enough? Illusory Completion in Search Agents](https://arxiv.org/abs/2602.07549v1) *by Dayoon Ko et al. (2026-02-07)* - _Recent search agents leverage multi-turn reasoning and search tools to achieve strong performance on multi-hop and long-horizon benchmarks. Yet it remains unclear whether they reliably reason across all requirements by tracking, verifying, and mainta..._
- [ ] **[cs.CR]** [MemPot: Defending Against Memory Extraction Attack with Optimized Honeypots](https://arxiv.org/abs/2602.07517v1) *by Yuhao Wang et al. (2026-02-07)* - _Large Language Model (LLM)-based agents employ external and internal memory systems to handle complex, goal-oriented tasks, yet this exposes them to severe extraction attacks, and effective defenses remain lacking. In this paper, we propose MemPot, t..._
- [ ] **[cs.AI]** [GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design](https://arxiv.org/abs/2602.07491v1) *by Isabella A. Stewart et al. (2026-02-07)* - _Large Language Models (LLMs) promise to accelerate discovery by reasoning across the expanding scientific landscape. Yet, the challenge is no longer access to information but connecting it in meaningful, domain-spanning ways. In materials science, wh..._
- [ ] **[cs.SE]** [Pull Requests as a Training Signal for Repo-Level Code Editing](https://arxiv.org/abs/2602.07457v1) *by Qinglin Zhu et al. (2026-02-07)* - _Repository-level code editing requires models to understand complex dependencies and execute precise multi-file modifications across a large codebase. While recent gains on SWE-bench rely heavily on complex agent scaffolding, it remains unclear how m..._
- [ ] **[cs.HC]** [Multi-Agent Systems Shape Social Norms for Prosocial Behavior Change](https://arxiv.org/abs/2602.07433v1) *by Yibin Feng et al. (2026-02-07)* - _Social norm interventions are used promote prosocial behaviors by highlighting prevalent actions, but their effectiveness is often limited in heterogeneous populations where shared understandings of desirable behaviors are lacking. This study explore..._
- [ ] **[cs.AI]** [The Moltbook Illusion: Separating Human Influence from Emergent Behavior in AI Agent Societies](https://arxiv.org/abs/2602.07432v1) *by Ning Li (2026-02-07)* - _When AI agents on the social platform Moltbook appeared to develop consciousness, found religions, and declare hostility toward humanity, the phenomenon attracted global media attention and was cited as evidence of emergent machine intelligence. We s..._
- [ ] **[cs.AI]** [Can LLMs Truly Embody Human Personality? Analyzing AI and Human Behavior Alignment in Dispute Resolution](https://arxiv.org/abs/2602.07414v1) *by Deuksin Kwon et al. (2026-02-07)* - _Large language models (LLMs) are increasingly used to simulate human behavior in social settings such as legal mediation, negotiation, and dispute resolution. However, it remains unclear whether these simulations reproduce the personality-behavior pa..._
- [ ] **[cs.AI]** [Progressive Multi-Agent Reasoning for Biological Perturbation Prediction](https://arxiv.org/abs/2602.07408v1) *by Hyomin Kim et al. (2026-02-07)* - _Predicting gene regulation responses to biological perturbations requires reasoning about underlying biological causalities. While large language models (LLMs) show promise for such tasks, they are often overwhelmed by the entangled nature of high-di..._
- [ ] **[cs.CR]** [AgentSys: Secure and Dynamic LLM Agents Through Explicit Hierarchical Memory Management](https://arxiv.org/abs/2602.07398v1) *by Ruoyao Wen et al. (2026-02-07)* - _Indirect prompt injection threatens LLM agents by embedding malicious instructions in external content, enabling unauthorized actions and data theft. LLM agents maintain working memory through their context window, which stores interaction history fo..._
- [ ] **[cs.AI]** [NAAMSE: Framework for Evolutionary Security Evaluation of Agents](https://arxiv.org/abs/2602.07391v1) *by Kunal Pai et al. (2026-02-07)* - _AI agents are increasingly deployed in production, yet their security evaluations remain bottlenecked by manual red-teaming or static benchmarks that fail to model adaptive, multi-turn adversaries. We propose NAAMSE, an evolutionary framework that re..._
- [ ] **[cs.AI]** [W&D:Scaling Parallel Tool Calling for Efficient Deep Research Agents](https://arxiv.org/abs/2602.07359v1) *by Xiaoqiang Lin et al. (2026-02-07)* - _Deep research agents have emerged as powerful tools for automating complex intellectual tasks through multi-step reasoning and web-based information seeking. While recent efforts have successfully enhanced these agents by scaling depth through increa..._
- [ ] **[cs.AI]** [SupChain-Bench: Benchmarking Large Language Models for Real-World Supply Chain Management](https://arxiv.org/abs/2602.07342v1) *by Shengyue Guan et al. (2026-02-07)* - _Large language models (LLMs) have shown promise in complex reasoning and tool-based decision making, motivating their application to real-world supply chain management. However, supply chain workflows require reliable long-horizon, multi-step orchest..._
- [ ] **[cs.AI]** [TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents](https://arxiv.org/abs/2602.07274v1) *by Kaijie Zhu et al. (2026-02-06)* - _Executing complex terminal tasks remains a significant challenge for open-weight LLMs, constrained by two fundamental limitations. First, high-fidelity, executable training environments are scarce: environments synthesized from real-world repositorie..._
- [ ] **[cs.RO]** [Realistic Synthetic Household Data Generation at Scale](https://arxiv.org/abs/2602.07243v1) *by Siddharth Singh et al. (2026-02-06)* - _Advancements in foundation models have catalyzed research in Embodied AI to develop interactive agents capable of environmental reasoning and interaction. Developing such agents requires diverse, large-scale datasets. Prior frameworks generate synthe..._
- [ ] **[eess.SY]** [Multi-Agentic AI for Fairness-Aware and Accelerated Multi-modal Large Model Inference in Real-world Mobile Edge Networks](https://arxiv.org/abs/2602.07215v1) *by Haiyuan Li et al. (2026-02-06)* - _Generative AI (GenAI) has transformed applications in natural language processing and content creation, yet centralized inference remains hindered by high latency, limited customizability, and privacy concerns. Deploying large models (LMs) in mobile ..._
- [ ] **[cs.AI]** [PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents](https://arxiv.org/abs/2602.07187v1) *by Hanyu Wang et al. (2026-02-06)* - _Advanced large language model agents typically adopt self-reflection for improving performance, where agents iteratively analyze past actions to correct errors. However, existing reflective approaches are inherently retrospective: agents act, observe..._
- [ ] **[cs.AI]** [ANCHOR: Branch-Point Data Generation for GUI Agents](https://arxiv.org/abs/2602.07153v1) *by Jinbiao Wei et al. (2026-02-06)* - _End-to-end GUI agents for real desktop environments require large amounts of high-quality interaction data, yet collecting human demonstrations is expensive and existing synthetic pipelines often suffer from limited task diversity or noisy, goal-drif..._
- [ ] **[cs.LG]** [On Randomness in Agentic Evals](https://arxiv.org/abs/2602.07150v1) *by Bjarni Haukur Bjarnason et al. (2026-02-06)* - _Agentic systems are evaluated on benchmarks where agents interact with environments to solve tasks. Most papers report a pass@1 score computed from a single run per task, assuming this gives a reliable performance estimate. We test this assumption by..._
- [ ] **[cs.HC]** [Exploring Teachers' Perspectives on Using Conversational AI Agents for Group Collaboration](https://arxiv.org/abs/2602.07142v1) *by Prerna Ravi et al. (2026-02-06)* - _Collaboration is a cornerstone of 21st-century learning, yet teachers continue to face challenges in supporting productive peer interaction. Emerging generative AI tools offer new possibilities for scaffolding collaboration, but their role in mediati..._
- [ ] **[cs.CV]** [Extended to Reality: Prompt Injection in 3D Environments](https://arxiv.org/abs/2602.07104v1) *by Zhuoheng Li et al. (2026-02-06)* - _Multimodal large language models (MLLMs) have advanced the capabilities to interpret and act on visual input in 3D environments, empowering diverse applications such as robotics and situated conversational agents. When MLLMs reason over camera-captur..._
- [ ] **[cs.MA]** [Lemon Agent Technical Report](https://arxiv.org/abs/2602.07092v1) *by Haipeng Jiang et al. (2026-02-06)* - _Recent advanced LLM-powered agent systems have exhibited their remarkable capabilities in tackling complex, long-horizon tasks. Nevertheless, they still suffer from inherent limitations in resource efficiency, context management, and multimodal perce..._
- [ ] **[q-fin.ST]** [QuantaAlpha: An Evolutionary Framework for LLM-Driven Alpha Mining](https://arxiv.org/abs/2602.07085v1) *by Jun Han et al. (2026-02-06)* - _Financial markets are noisy and non-stationary, making alpha mining highly sensitive to noise in backtesting results and sudden market regime shifts. While recent agentic frameworks improve alpha mining automation, they often lack controllable multi-..._


## 2026-02-09 Êõ¥Êñ∞ 38 ÁØáÊñ∞ËÆ∫Êñá
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-09Ôºö2602.05386 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense with Hierarchical Adaptive Screening](https://arxiv.org/abs/2602.05386v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-09Ôºö2602.05353 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [AgentXRay: White-Boxing Agentic Systems via Workflow Reconstruction](https://arxiv.org/abs/2602.05353v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-09Ôºö2602.05183 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [Data-Centric Interpretability for LLM-based Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.05183v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-09Ôºö2602.05088 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [VERA-MH: Reliability and Validity of an Open-Source AI Safety Evaluation in Mental Health](https://arxiv.org/abs/2602.05088v2)
- [ ] (ÁâàÊú¨Êõ¥Êñ∞) 2026-02-09Ôºö2602.05014 ‰ªé v1 Êõ¥Êñ∞Âà∞ v2 - [DeepRead: Document Structure-Aware Reasoning to Enhance Agentic Search](https://arxiv.org/abs/2602.05014v2)
- [ ] **[cs.RO]** [DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos](https://arxiv.org/abs/2602.06949v1) *by Shenyuan Gao et al. (2026-02-06)* - _Being able to simulate the outcomes of actions in varied environments will revolutionize the development of generalist agents at scale. However, modeling these world dynamics, especially for dexterous robotics tasks, poses significant challenges due ..._
- [ ] **[cs.AI]** [Agentic Uncertainty Reveals Agentic Overconfidence](https://arxiv.org/abs/2602.06948v1) *by Jean Kaddour et al. (2026-02-06)* - _Can AI agents predict whether they will succeed at a task? We study agentic uncertainty by eliciting success probability estimates before, during, and after task execution. All results exhibit agentic overconfidence: some agents that succeed only 22%..._
- [ ] **[cs.PL]** [Implementing Grassroots Logic Programs with Multiagent Transition Systems and AI](https://arxiv.org/abs/2602.06934v1) *by Ehud Shapiro (2026-02-06)* - _Grassroots Logic Programs (GLP) is a concurrent logic programming language with variables partitioned into paired \emph{readers} and \emph{writers}, conjuring both linear logic and futures/promises: an assignment is produced at most once via the sole..._
- [ ] **[cs.LG]** [From Kepler to Newton: Inductive Biases Guide Learned World Models in Transformers](https://arxiv.org/abs/2602.06923v1) *by Ziming Liu et al. (2026-02-06)* - _Can general-purpose AI architectures go beyond prediction to discover the physical laws governing the universe? True intelligence relies on "world models" -- causal abstractions that allow an agent to not only predict future states but understand the..._
- [ ] **[cs.SE]** [TraceCoder: A Trace-Driven Multi-Agent Framework for Automated Debugging of LLM-Generated Code](https://arxiv.org/abs/2602.06875v1) *by Jiangping Huang et al. (2026-02-06)* - _Large Language Models (LLMs) often generate code with subtle but critical bugs, especially for complex tasks. Existing automated repair methods typically rely on superficial pass/fail signals, offering limited visibility into program behavior and hin..._
- [ ] **[cs.AI]** [AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents](https://arxiv.org/abs/2602.06855v1) *by Alisia Lupidi et al. (2026-02-06)* - _LLM agents hold significant promise for advancing scientific research. To accelerate this progress, we introduce AIRS-Bench (the AI Research Science Benchmark), a suite of 20 tasks sourced from state-of-the-art machine learning papers. These tasks sp..._
- [ ] **[cs.AI]** [From Features to Actions: Explainability in Traditional and Agentic AI Systems](https://arxiv.org/abs/2602.06841v1) *by Sindhuja Chaduvula et al. (2026-02-06)* - _Over the last decade, explainable AI has primarily focused on interpreting individual model predictions, producing post-hoc explanations that relate inputs to outputs under a fixed decision structure. Recent advances in large language models (LLMs) h..._
- [ ] **[cs.AI]** [LLM Active Alignment: A Nash Equilibrium Perspective](https://arxiv.org/abs/2602.06836v1) *by Tonghan Wang et al. (2026-02-06)* - _We develop a game-theoretic framework for predicting and steering the behavior of populations of large language models (LLMs) through Nash equilibrium (NE) analysis. To avoid the intractability of equilibrium computation in open-ended text spaces, we..._
- [ ] **[cs.AI]** [ScaleEnv: Scaling Environment Synthesis from Scratch for Generalist Interactive Tool-Use Agent Training](https://arxiv.org/abs/2602.06820v1) *by Dunwei Tu et al. (2026-02-06)* - _Training generalist agents capable of adapting to diverse scenarios requires interactive environments for self-exploration. However, interactive environments remain critically scarce, and existing synthesis methods suffer from significant limitations..._
- [ ] **[eess.SP]** [Bridging 6G IoT and AI: LLM-Based Efficient Approach for Physical Layer's Optimization Tasks](https://arxiv.org/abs/2602.06819v1) *by Ahsan Mehmood et al. (2026-02-06)* - _This paper investigates the role of large language models (LLMs) in sixth-generation (6G) Internet of Things (IoT) networks and proposes a prompt-engineering-based real-time feedback and verification (PE-RTFV) framework that perform physical-layer's ..._
- [ ] **[cs.AI]** [Semantically Labelled Automata for Multi-Task Reinforcement Learning with LTL Instructions](https://arxiv.org/abs/2602.06746v1) *by Alessandro Abate et al. (2026-02-06)* - _We study multi-task reinforcement learning (RL), a setting in which an agent learns a single, universal policy capable of generalising to arbitrary, possibly unseen tasks. We consider tasks specified as linear temporal logic (LTL) formulae, which are..._
- [ ] **[cs.LG]** [Pairwise is Not Enough: Hypergraph Neural Networks for Multi-Agent Pathfinding](https://arxiv.org/abs/2602.06733v1) *by Rishabh Jain et al. (2026-02-06)* - _Multi-Agent Path Finding (MAPF) is a representative multi-agent coordination problem, where multiple agents are required to navigate to their respective goals without collisions. Solving MAPF optimally is known to be NP-hard, leading to the adoption ..._
- [ ] **[cs.MA]** [Sample-Efficient Policy Space Response Oracles with Joint Experience Best Response](https://arxiv.org/abs/2602.06599v1) *by Ariyan Bighashdel et al. (2026-02-06)* - _Multi-agent reinforcement learning (MARL) offers a scalable alternative to exact game-theoretic analysis but suffers from non-stationarity and the need to maintain diverse populations of strategies that capture non-transitive interactions. Policy Spa..._
- [ ] **[cs.SE]** [AgentStepper: Interactive Debugging of Software Development Agents](https://arxiv.org/abs/2602.06593v1) *by Robert Hutter et al. (2026-02-06)* - _Software development agents powered by large language models (LLMs) have shown great promise in automating tasks like environment setup, issue solving, and program repair. Unfortunately, understanding and debugging such agents remain challenging due ..._
- [ ] **[cs.AI]** [SeeUPO: Sequence-Level Agentic-RL with Convergence Guarantees](https://arxiv.org/abs/2602.06554v1) *by Tianyi Hu et al. (2026-02-06)* - _Reinforcement learning (RL) has emerged as the predominant paradigm for training large language model (LLM)-based AI agents. However, existing backbone RL algorithms lack verified convergence guarantees in agentic scenarios, especially in multi-turn ..._
- [ ] **[cs.CR]** [Malicious Agent Skills in the Wild: A Large-Scale Security Empirical Study](https://arxiv.org/abs/2602.06547v1) *by Yi Liu et al. (2026-02-06)* - _Third-party agent skills extend LLM-based agents with instruction files and executable code that run on users' machines. Skills execute with user privileges and are distributed through community registries with minimal vetting, but no ground-truth da..._
- [ ] **[cs.AI]** [AgentCPM-Report: Interleaving Drafting and Deepening for Open-Ended Deep Research](https://arxiv.org/abs/2602.06540v1) *by Yishan Li et al. (2026-02-06)* - _Generating deep research reports requires large-scale information acquisition and the synthesis of insight-driven analysis, posing a significant challenge for current language models. Most existing approaches follow a plan-then-write paradigm, whose ..._
- [ ] **[cs.CL]** [Completing Missing Annotation: Multi-Agent Debate for Accurate and Scalable Relevant Assessment for IR Benchmarks](https://arxiv.org/abs/2602.06526v1) *by Minjeong Ban et al. (2026-02-06)* - _Information retrieval (IR) evaluation remains challenging due to incomplete IR benchmark datasets that contain unlabeled relevant chunks. While LLMs and LLM-human hybrid strategies reduce costly human effort, they remain prone to LLM overconfidence a..._
- [ ] **[cs.AI]** [JADE: Expert-Grounded Dynamic Evaluation for Open-Ended Professional Tasks](https://arxiv.org/abs/2602.06486v1) *by Lanbo Lin et al. (2026-02-06)* - _Evaluating agentic AI on open-ended professional tasks faces a fundamental dilemma between rigor and flexibility. Static rubrics provide rigorous, reproducible assessment but fail to accommodate diverse valid response strategies, while LLM-as-a-judge..._
- [ ] **[cs.AI]** [AgentCPM-Explore: Realizing Long-Horizon Deep Exploration for Edge-Scale Agents](https://arxiv.org/abs/2602.06485v1) *by Haotian Chen et al. (2026-02-06)* - _While Large Language Model (LLM)-based agents have shown remarkable potential for solving complex tasks, existing systems remain heavily reliant on large-scale models, leaving the capabilities of edge-scale models largely underexplored. In this paper..._
- [ ] **[cs.MA]** [Prism: Spectral Parameter Sharing for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.06476v1) *by Kyungbeom Kim et al. (2026-02-06)* - _Parameter sharing is a key strategy in multi-agent reinforcement learning (MARL) for improving scalability, yet conventional fully shared architectures often collapse into homogeneous behaviors. Recent methods introduce diversity through clustering, ..._
- [ ] **[cs.LG]** [Principle-Evolvable Scientific Discovery via Uncertainty Minimization](https://arxiv.org/abs/2602.06448v1) *by Yingming Pu et al. (2026-02-06)* - _Large Language Model (LLM)-based scientific agents have accelerated scientific discovery, yet they often suffer from significant inefficiencies due to adherence to fixed initial priors. Existing approaches predominantly operate within a static hypoth..._
- [ ] **[cs.CR]** [TrajAD: Trajectory Anomaly Detection for Trustworthy LLM Agents](https://arxiv.org/abs/2602.06443v1) *by Yibing Liu et al. (2026-02-06)* - _We address the problem of runtime trajectory anomaly detection, a critical capability for enabling trustworthy LLM agents. Current safety measures predominantly focus on static input/output filtering. However, we argue that ensuring LLM agents reliab..._
- [ ] **[cs.CV]** [Revisiting Salient Object Detection from an Observer-Centric Perspective](https://arxiv.org/abs/2602.06369v1) *by Fuxi Zhang et al. (2026-02-06)* - _Salient object detection is inherently a subjective problem, as observers with different priors may perceive different objects as salient. However, existing methods predominantly formulate it as an objective prediction task with a single groundtruth ..._
- [ ] **[cs.AI]** [Trifuse: Enhancing Attention-Based GUI Grounding via Multimodal Fusion](https://arxiv.org/abs/2602.06351v1) *by Longhui Ma et al. (2026-02-06)* - _GUI grounding maps natural language instructions to the correct interface elements, serving as the perception foundation for GUI agents. Existing approaches predominantly rely on fine-tuning multimodal large language models (MLLMs) using large-scale ..._
- [ ] **[cs.CR]** [Zero-Trust Runtime Verification for Agentic Payment Protocols: Mitigating Replay and Context-Binding Failures in AP2](https://arxiv.org/abs/2602.06345v1) *by Qianlong Lan et al. (2026-02-06)* - _The deployment of autonomous AI agents capable of executing commercial transactions has motivated the adoption of mandate-based payment authorization protocols, including the Universal Commerce Protocol (UCP) and the Agent Payments Protocol (AP2). Th..._
- [ ] **[cs.AI]** [Do LLMs Act Like Rational Agents? Measuring Belief Coherence in Probabilistic Decision Making](https://arxiv.org/abs/2602.06286v1) *by Khurram Yamin et al. (2026-02-06)* - _Large language models (LLMs) are increasingly deployed as agents in high-stakes domains where optimal actions depend on both uncertainty about the world and consideration of utilities of different outcomes, yet their decision logic remains difficult ..._
- [ ] **[cs.LG]** [RuleSmith: Multi-Agent LLMs for Automated Game Balancing](https://arxiv.org/abs/2602.06232v1) *by Ziyao Zeng et al. (2026-02-05)* - _Game balancing is a longstanding challenge requiring repeated playtesting, expert intuition, and extensive manual tuning. We introduce RuleSmith, the first framework that achieves automated game balancing by leveraging the reasoning capabilities of m..._
- [ ] **[cs.HC]** [Hear You in Silence: Designing for Active Listening in Human Interaction with Conversational Agents Using Context-Aware Pacing](https://arxiv.org/abs/2602.06134v1) *by Zhihan Jiang et al. (2026-02-05)* - _In human conversation, empathic dialogue requires nuanced temporal cues indicating whether the conversational partner is paying attention. This type of "active listening" is overlooked in the design of Conversational Agents (CAs), which use the same ..._
- [ ] **[cs.SE]** [Coding Agents with Environment Interaction: A Theoretical Perspective](https://arxiv.org/abs/2602.06098v1) *by Nicolas Menet et al. (2026-02-05)* - _Coding agents are increasingly utilized in test-driven software development, yet the theoretical mechanisms behind their environment-interaction strategies remain underexplored. We provide a probabilistic framework for two dominant paradigms: code se..._
- [ ] **[cs.SE]** [SVRepair: Structured Visual Reasoning for Automated Program Repair](https://arxiv.org/abs/2602.06090v1) *by Xiaoxuan Tang et al. (2026-02-05)* - _Large language models (LLMs) have recently shown strong potential for Automated Program Repair (APR), yet most existing approaches remain unimodal and fail to leverage the rich diagnostic signals contained in visual artifacts such as screenshots and ..._
- [ ] **[cs.RO]** [Transformer-Based Reinforcement Learning for Autonomous Orbital Collision Avoidance in Partially Observable Environments](https://arxiv.org/abs/2602.06088v1) *by Thomas Georges et al. (2026-02-05)* - _We introduce a Transformer-based Reinforcement Learning framework for autonomous orbital collision avoidance that explicitly models the effects of partial observability and imperfect monitoring in space operations. The framework combines a configurab..._
- [ ] **[cs.MA]** [Communication Enhances LLMs' Stability in Strategic Thinking](https://arxiv.org/abs/2602.06081v1) *by Nunzio Lore et al. (2026-02-04)* - _Large Language Models (LLMs) often exhibit pronounced context-dependent variability that undermines predictable multi-agent behavior in tasks requiring strategic thinking. Focusing on models that range from 7 to 9 billion parameters in size engaged i..._





## 2026-02-06 Êõ¥Êñ∞ 51 ÁØáÊñ∞ËÆ∫Êñá
- [ ] **[cs.AI]** [DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning via Semantic Matching](https://arxiv.org/abs/2602.06039v1) *by Yuxing Lu et al. (2026-02-05)* - _Multi-agent systems built from prompted large language models can improve multi-round reasoning, yet most existing pipelines rely on fixed, trajectory-wide communication patterns that are poorly matched to the stage-dependent needs of iterative probl..._
- [ ] **[cs.RO]** [CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction](https://arxiv.org/abs/2602.06038v1) *by Xiaopan Zhang et al. (2026-02-05)* - _To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous..._
- [ ] **[cs.CL]** [Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory](https://arxiv.org/abs/2602.06025v1) *by Haozhen Zhang et al. (2026-02-05)* - _Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical informa..._
- [ ] **[cs.AI]** [AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions](https://arxiv.org/abs/2602.06008v1) *by Xianyang Liu et al. (2026-02-05)* - _Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We in..._
- [ ] **[cs.AI]** [Quantum Reinforcement Learning with Transformers for the Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2602.05920v1) *by Eva Andr√©s (2026-02-05)* - _This paper addresses the Capacitated Vehicle Routing Problem (CVRP) by comparing classical and quantum Reinforcement Learning (RL) approaches. An Advantage Actor-Critic (A2C) agent is implemented in classical, full quantum, and hybrid variants, integ..._
- [ ] **[cs.GT]** [Metric Hedonic Games on the Line](https://arxiv.org/abs/2602.05888v1) *by Merlin de la Haye et al. (2026-02-05)* - _Hedonic games are fundamental models for investigating the formation of coalitions among a set of strategic agents, where every agent has a certain utility for every possible coalition of agents it can be part of. To avoid the intractability of defin..._
- [ ] **[cs.AI]** [Agent2Agent Threats in Safety-Critical LLM Assistants: A Human-Centric Taxonomy](https://arxiv.org/abs/2602.05877v1) *by Lukas Stappen et al. (2026-02-05)* - _The integration of Large Language Model (LLM)-based conversational agents into vehicles creates novel security challenges at the intersection of agentic AI, automotive safety, and inter-agent communication. As these intelligent assistants coordinate ..._
- [ ] **** [DARWIN: Dynamic Agentically Rewriting Self-Improving Network](https://arxiv.org/abs/2602.05848v1) *by Henry Jiang (2026-02-05)* - _DARWIN is an evolutionary GPT model, utilizing a genetic-algorithm like optimization structure with several independent GPT agents being trained individually using unique training code. Each iteration, the GPT models are prompted to modify the traini..._
- [ ] **[cs.AI]** [TKG-Thinker: Towards Dynamic Reasoning over Temporal Knowledge Graphs via Agentic Reinforcement Learning](https://arxiv.org/abs/2602.05818v1) *by Zihao Jiang et al. (2026-02-05)* - _Temporal knowledge graph question answering (TKGQA) aims to answer time-sensitive questions by leveraging temporal knowledge bases. While Large Language Models (LLMs) demonstrate significant potential in TKGQA, current prompting strategies constrain ..._
- [ ] **[cs.AI]** [RocqSmith: Can Automatic Optimization Forge Better Proof Agents?](https://arxiv.org/abs/2602.05762v1) *by Andrei Kozyrev et al. (2026-02-05)* - _This work studies the applicability of automatic AI agent optimization methods to real-world agents in formal verification settings, focusing on automated theorem proving in Rocq as a representative and challenging domain. We evaluate how different a..._
- [ ] **[cs.LG]** [Learning to Inject: Automated Prompt Injection via Reinforcement Learning](https://arxiv.org/abs/2602.05746v1) *by Xin Chen et al. (2026-02-05)* - _Prompt injection is one of the most critical vulnerabilities in LLM agents; yet, effective automated attacks remain largely unexplored from an optimization perspective. Existing methods heavily depend on human red-teamers and hand-crafted prompts, li..._
- [ ] **[cs.AI]** [Graph-based Agent Memory: Taxonomy, Techniques, and Applications](https://arxiv.org/abs/2602.05665v1) *by Chang Yang et al. (2026-02-05)* - _Memory emerges as the core module in the Large Language Model (LLM)-based agents for long-horizon complex tasks (e.g., multi-turn dialogue, game playing, scientific discovery), where memory can enable knowledge accumulation, iterative reasoning and s..._
- [ ] **[cs.LG]** [Alignment Verifiability in Large Language Models: Normative Indistinguishability under Behavioral Evaluation](https://arxiv.org/abs/2602.05656v1) *by Igor Santos-Grueiro (2026-02-05)* - _Behavioral evaluation is the dominant paradigm for assessing alignment in large language models (LLMs). In practice, alignment is inferred from performance under finite evaluation protocols - benchmarks, red-teaming suites, or automated pipelines - a..._
- [ ] **[cs.AI]** [Generative Ontology: When Structured Knowledge Learns to Create](https://arxiv.org/abs/2602.05636v1) *by Benny Cheung (2026-02-05)* - _Traditional ontologies excel at describing domain structure but cannot generate novel artifacts. Large language models generate fluently but produce outputs that lack structural validity, hallucinating mechanisms without components, goals without end..._
- [ ] **[cs.AI]** [Reactive Knowledge Representation and Asynchronous Reasoning](https://arxiv.org/abs/2602.05625v1) *by Simon Kohaut et al. (2026-02-05)* - _Exact inference in complex probabilistic models often incurs prohibitive computational costs. This challenge is particularly acute for autonomous agents in dynamic environments that require frequent, real-time belief updates. Existing methods are oft..._
- [ ] **[cs.AI]** [Emulating Aggregate Human Choice Behavior and Biases with GPT Conversational Agents](https://arxiv.org/abs/2602.05597v1) *by Stephen Pilli et al. (2026-02-05)* - _Cognitive biases often shape human decisions. While large language models (LLMs) have been shown to reproduce well-known biases, a more critical question is whether LLMs can predict biases at the individual level and emulate the dynamics of biased hu..._
- [ ] **[cs.AI]** [TangramSR: Can Vision-Language Models Reason in Continuous Geometric Space?](https://arxiv.org/abs/2602.05570v1) *by Yikun Zong et al. (2026-02-05)* - _Humans excel at spatial reasoning tasks like Tangram puzzle assembly through cognitive processes involving mental rotation, iterative refinement, and visual feedback. Inspired by how humans solve Tangram puzzles through trial-and-error, observation, ..._
- [ ] **[cs.MA]** [AI Agent Systems for Supply Chains: Structured Decision Prompts and Memory Retrieval](https://arxiv.org/abs/2602.05524v1) *by Konosuke Yoshizato et al. (2026-02-05)* - _This study investigates large language model (LLM) -based multi-agent systems (MASs) as a promising approach to inventory management, which is a key component of supply chain management. Although these systems have gained considerable attention for t..._
- [ ] **[cs.SE]** [Capture the Flags: Family-Based Evaluation of Agentic LLMs via Semantics-Preserving Transformations](https://arxiv.org/abs/2602.05523v1) *by Shahin Honarvar et al. (2026-02-05)* - _Agentic large language models (LLMs) are increasingly evaluated on cybersecurity tasks using capture-the-flag (CTF) benchmarks. However, existing pointwise benchmarks have limited ability to shed light on the robustness and generalisation abilities o..._
- [ ] **[cs.CL]** [LinguistAgent: A Reflective Multi-Model Platform for Automated Linguistic Annotation](https://arxiv.org/abs/2602.05493v1) *by Bingru Li (2026-02-05)* - _Data annotation remains a significant bottleneck in the Humanities and Social Sciences, particularly for complex semantic tasks such as metaphor identification. While Large Language Models (LLMs) show promise, a significant gap remains between the th..._
- [ ] **[cs.LG]** [Thermodynamic Limits of Physical Intelligence](https://arxiv.org/abs/2602.05463v1) *by Koichi Takahashi et al. (2026-02-05)* - _Modern AI systems achieve remarkable capabilities at the cost of substantial energy consumption. To connect intelligence to physical efficiency, we propose two complementary bits-per-joule metrics under explicit accounting conventions: (1) Thermodyna..._
- [ ] **[cs.CL]** [Structured Context Engineering for File-Native Agentic Systems: Evaluating Schema Accuracy, Format Effectiveness, and Multi-File Navigation at Scale](https://arxiv.org/abs/2602.05447v1) *by Damon McMillan (2026-02-05)* - _Large Language Model agents increasingly operate external systems through programmatic interfaces, yet practitioners lack empirical guidance on how to structure the context these agents consume. Using SQL generation as a proxy for programmatic agent ..._
- [ ] **[cs.AI]** [M$^2$-Miner: Multi-Agent Enhanced MCTS for Mobile GUI Agent Data Mining](https://arxiv.org/abs/2602.05429v1) *by Rui Lv et al. (2026-02-05)* - _Graphical User Interface (GUI) agent is pivotal to advancing intelligent human-computer interaction paradigms. Constructing powerful GUI agents necessitates the large-scale annotation of high-quality user-behavior trajectory data (i.e., intent-trajec..._
- [ ] **[cs.AI]** [H-AdminSim: A Multi-Agent Simulator for Realistic Hospital Administrative Workflows with FHIR Integration](https://arxiv.org/abs/2602.05407v1) *by Jun-Min Lee et al. (2026-02-05)* - _Hospital administration departments handle a wide range of operational tasks and, in large hospitals, process over 10,000 requests per day, driving growing interest in LLM-based automation. However, prior work has focused primarily on patient--physic..._
- [ ] **[cs.CR]** [Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense with Hierarchical Adaptive Screening](https://arxiv.org/abs/2602.05386v1) *by Zhenxiong Yu et al. (2026-02-05)* - _As large language models (LLMs) evolve into autonomous agents, their real-world applicability has expanded significantly, accompanied by new security challenges. Most existing agent defense mechanisms adopt a mandatory checking paradigm, in which sec..._
- [ ] **[cs.AI]** [PATHWAYS: Evaluating Investigation and Context Discovery in AI Web Agents](https://arxiv.org/abs/2602.05354v1) *by Shifat E. Arman et al. (2026-02-05)* - _We introduce PATHWAYS, a benchmark of 250 multi-step decision tasks that test whether web-based agents can discover and correctly use hidden contextual information. Across both closed and open models, agents typically navigate to relevant pages but r..._
- [ ] **[cs.AI]** [AgentXRay: White-Boxing Agentic Systems via Workflow Reconstruction](https://arxiv.org/abs/2602.05353v1) *by Ruijie Shi et al. (2026-02-05)* - _Large Language Models have shown strong capabilities in complex problem solving, yet many agentic systems remain difficult to interpret and control due to opaque internal workflows. While some frameworks offer explicit architectures for collaboration..._
- [ ] **[cs.AI]** [ProAct: Agentic Lookahead in Interactive Environments](https://arxiv.org/abs/2602.05327v1) *by Yangbin Yu et al. (2026-02-05)* - _Existing Large Language Model (LLM) agents struggle in interactive environments requiring long-horizon planning, primarily due to compounding errors when simulating future states. To address this, we propose ProAct, a framework that enables agents to..._
- [ ] **[cs.AI]** [PieArena: Frontier Language Agents Achieve MBA-Level Negotiation Performance and Reveal Novel Behavioral Differences](https://arxiv.org/abs/2602.05302v1) *by Chris Zhu et al. (2026-02-05)* - _We present an in-depth evaluation of LLMs' ability to negotiate, a central business task that requires strategic reasoning, theory of mind, and economic value creation. To do so, we introduce PieArena, a large-scale negotiation benchmark grounded in ..._
- [ ] **[cs.CL]** [Towards a Science of Collective AI: LLM-based Multi-Agent Systems Need a Transition from Blind Trial-and-Error to Rigorous Science](https://arxiv.org/abs/2602.05289v1) *by Jingru Fan et al. (2026-02-05)* - _Recent advancements in Large Language Models (LLMs) have greatly extended the capabilities of Multi-Agent Systems (MAS), demonstrating significant effectiveness across a wide range of complex and open-ended domains. However, despite this rapid progre..._
- [ ] **[cs.AI]** [Position: Universal Time Series Foundation Models Rest on a Category Error](https://arxiv.org/abs/2602.05287v1) *by Xilin Dai et al. (2026-02-05)* - _This position paper argues that the pursuit of "Universal Foundation Models for Time Series" rests on a fundamental category error, mistaking a structural Container for a semantic Modality. We contend that because time series hold incompatible genera..._
- [ ] **[cs.AI]** [Automatic Cognitive Task Generation for In-Situ Evaluation of Embodied Agents](https://arxiv.org/abs/2602.05249v1) *by Xinyi He et al. (2026-02-05)* - _As general intelligent agents are poised for widespread deployment in diverse households, evaluation tailored to each unique unseen 3D environment has become a critical prerequisite. However, existing benchmarks suffer from severe data contamination ..._
- [ ] **[cs.SE]** [EGSS: Entropy-guided Stepwise Scaling for Reliable Software Engineering](https://arxiv.org/abs/2602.05242v1) *by Chenhui Mao et al. (2026-02-05)* - _Agentic Test-Time Scaling (TTS) has delivered state-of-the-art (SOTA) performance on complex software engineering tasks such as code generation and bug fixing. However, its practical adoption remains limited due to significant computational overhead,..._
- [ ] **[cs.IR]** [Semantic Search over 9 Million Mathematical Theorems](https://arxiv.org/abs/2602.05216v1) *by Luke Alexander et al. (2026-02-05)* - _Searching for mathematical results remains difficult: most existing tools retrieve entire papers, while mathematicians and theorem-proving agents often seek a specific theorem, lemma, or proposition that answers a query. While semantic search has see..._
- [ ] **[cs.LG]** [Data-Centric Interpretability for LLM-based Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.05183v1) *by John Yan et al. (2026-02-05)* - _Large language models (LLMs) are increasingly trained in complex Reinforcement Learning, multi-agent environments, making it difficult to understand how behavior changes over training. Sparse Autoencoders (SAEs) have recently shown to be useful for d..._
- [ ] **[cs.AI]** [SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers](https://arxiv.org/abs/2602.05115v1) *by Keyang Xuan et al. (2026-02-04)* - _Large language models (LLMs) are increasingly evaluated in interactive environments to test their social intelligence. However, existing benchmarks often assume idealized communication between agents, limiting our ability to diagnose whether LLMs can..._
- [ ] **[cs.AI]** [GAMMS: Graph based Adversarial Multiagent Modeling Simulator](https://arxiv.org/abs/2602.05105v1) *by Rohan Patil et al. (2026-02-04)* - _As intelligent systems and multi-agent coordination become increasingly central to real-world applications, there is a growing need for simulation tools that are both scalable and accessible. Existing high-fidelity simulators, while powerful, are oft..._
- [ ] **[cs.AI]** [VERA-MH: Reliability and Validity of an Open-Source AI Safety Evaluation in Mental Health](https://arxiv.org/abs/2602.05088v1) *by Kate H. Bentley et al. (2026-02-04)* - _Millions now use leading generative AI chatbots for psychological support. Despite the promise related to availability and scale, the single most pressing question in AI for mental health is whether these tools are safe. The Validation of Ethical and..._
- [ ] **[cs.LG]** [Autodiscover: A reinforcement learning recommendation system for the cold-start imbalance challenge in active learning, powered by graph-aware thompson sampling](https://arxiv.org/abs/2602.05087v1) *by Parsa Vares (2026-02-04)* - _Systematic literature reviews (SLRs) are fundamental to evidence-based research, but manual screening is an increasing bottleneck as scientific output grows. Screening features low prevalence of relevant studies and scarce, costly expert decisions. T..._
- [ ] **[cs.AI]** [Optimizing Mission Planning for Multi-Debris Rendezvous Using Reinforcement Learning with Refueling and Adaptive Collision Avoidance](https://arxiv.org/abs/2602.05075v1) *by Agni Bandyopadhyay et al. (2026-02-04)* - _As the orbital environment around Earth becomes increasingly crowded with debris, active debris removal (ADR) missions face significant challenges in ensuring safe operations while minimizing the risk of in-orbit collisions. This study presents a rei..._
- [ ] **[cs.AI]** [Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents](https://arxiv.org/abs/2602.05073v1) *by Changdae Oh et al. (2026-02-04)* - _Uncertainty quantification (UQ) for large language models (LLMs) is a key building block for safety guardrails of daily LLM applications. Yet, even as LLM agents are increasingly deployed in highly complex tasks, most UQ research still centers on sin..._
- [ ] **[cs.CR]** [Bypassing AI Control Protocols via Agent-as-a-Proxy Attacks](https://arxiv.org/abs/2602.05066v1) *by Jafar Isbarov et al. (2026-02-04)* - _As AI agents automate critical workloads, they remain vulnerable to indirect prompt injection (IPI) attacks. Current defenses rely on monitoring protocols that jointly evaluate an agent's Chain-of-Thought (CoT) and tool-use actions to ensure alignmen..._
- [ ] **[cs.AI]** [MINT: Minimal Information Neuro-Symbolic Tree for Objective-Driven Knowledge-Gap Reasoning and Active Elicitation](https://arxiv.org/abs/2602.05048v1) *by Zeyu Fang et al. (2026-02-04)* - _Joint planning through language-based interactions is a key area of human-AI teaming. Planning problems in the open world often involve various aspects of incomplete information and unknowns, e.g., objects involved, human goals/intents -- thus leadin..._
- [ ] **[cs.HC]** [From Fragmentation to Integration: Exploring the Design Space of AI Agents for Human-as-the-Unit Privacy Management](https://arxiv.org/abs/2602.05016v1) *by Eryue Xu et al. (2026-02-04)* - _Managing one's digital footprint is overwhelming, as it spans multiple platforms and involves countless context-dependent decisions. Recent advances in agentic AI offer ways forward by enabling holistic, contextual privacy-enhancing solutions. Buildi..._
- [ ] **[cs.AI]** [DeepRead: Document Structure-Aware Reasoning to Enhance Agentic Search](https://arxiv.org/abs/2602.05014v1) *by Zhanli Li et al. (2026-02-04)* - _With the rapid progress of tool-using and agentic large language models (LLMs), Retrieval-Augmented Generation (RAG) is evolving from one-shot, passive retrieval into multi-turn, decision-driven evidence acquisition. Despite strong results in open-do..._
- [ ] **[cs.CL]** [CoWork-X: Experience-Optimized Co-Evolution for Multi-Agent Collaboration System](https://arxiv.org/abs/2602.05004v1) *by Zexin Lin et al. (2026-02-04)* - _Large language models are enabling language-conditioned agents in interactive environments, but highly cooperative tasks often impose two simultaneous constraints: sub-second real-time coordination and sustained multi-episode adaptation under a stric..._
- [ ] **[cs.LG]** [Privileged Information Distillation for Language Models](https://arxiv.org/abs/2602.04942v1) *by Emiliano Penaloza et al. (2026-02-04)* - _Training-time privileged information (PI) can enable language models to succeed on tasks they would otherwise fail, making it a powerful tool for reinforcement learning in hard, long-horizon settings. However, transferring capabilities learned with P..._
- [ ] **[cs.SE]** [ASA: Activation Steering for Tool-Calling Domain Adaptation](https://arxiv.org/abs/2602.04935v1) *by Youjin Wang et al. (2026-02-04)* - _For real-world deployment of general-purpose LLM agents, the core challenge is often not tool use itself, but efficient domain adaptation under rapidly evolving toolsets, APIs, and protocols. Repeated LoRA or SFT across domains incurs exponentially g..._
- [ ] **[cs.AI]** [Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration](https://arxiv.org/abs/2602.04575v2) *by Jiaheng Liu et al. (2026-02-04)* - _For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' ..._
- [ ] **[cs.AI]** [Mitigating Conversational Inertia in Multi-Turn Agents](https://arxiv.org/abs/2602.03664v2) *by Yang Wan et al. (2026-02-03)* - _Large language models excel as few-shot learners when provided with appropriate demonstrations, yet this strength becomes problematic in multiturn agent scenarios, where LLMs erroneously mimic their own previous responses as few-shot examples. Throug..._


## 2026-02-06 Êõ¥Êñ∞ 150 ÁØáÊñ∞ËÆ∫Êñá
- [ ] **[cs.LG]** [CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation](https://arxiv.org/abs/2602.04868v1) *by Yannick Denker et al. (2026-02-04)* - _Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo..._
- [ ] **[physics.chem-ph]** [El Agente Quntur: A research collaborator agent for quantum chemistry](https://arxiv.org/abs/2602.04850v1) *by Juan B. P√©rez-S√°nchez et al. (2026-02-04)* - _Quantum chemistry is a foundational enabling tool for the fields of chemistry, materials science, computational biology and others. Despite of its power, the practical application of quantum chemistry simulations remains in the hands of qualified exp..._
- [ ] **[physics.chem-ph]** [El Agente Estructural: An Artificially Intelligent Molecular Editor](https://arxiv.org/abs/2602.04849v1) *by Changhyeok Choi et al. (2026-02-04)* - _We present El Agente Estructural, a multimodal, natural-language-driven geometry-generation and manipulation agent for autonomous chemistry and molecular modelling. Unlike molecular generation or editing via generative models, Estructural mimics how ..._
- [ ] **[cs.AI]** [Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing](https://arxiv.org/abs/2602.04837v1) *by Zhaotian Weng et al. (2026-02-04)* - _Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents..._
- [ ] **[cs.LG]** [Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning](https://arxiv.org/abs/2602.04821v1) *by Joydeep Chandra et al. (2026-02-04)* - _Urban traffic management demands systems that simultaneously predict future conditions, detect anomalies, and take safe corrective actions -- all while providing reliability guarantees. We present STREAM-RL, a unified framework that introduces three ..._
- [ ] **[cs.AI]** [Agentic AI in Healthcare & Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents](https://arxiv.org/abs/2602.04813v1) *by Shubham Vatsal et al. (2026-02-04)* - _Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape healthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR analysis and differential diagnosis to treatment planning and r..._
- [ ] **[cs.CL]** [SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization](https://arxiv.org/abs/2602.04811v1) *by Jiarui Yuan et al. (2026-02-04)* - _True self-evolution requires agents to act as lifelong learners that internalize novel experiences to solve future problems. However, rigorously measuring this foundational capability is hindered by two obstacles: the entanglement of prior knowledge,..._
- [ ] **[cs.LG]** [Beyond Rewards in Reinforcement Learning for Cyber Defence](https://arxiv.org/abs/2602.04809v1) *by Elizabeth Bates et al. (2026-02-04)* - _Recent years have seen an explosion of interest in autonomous cyber defence agents trained to defend computer networks using deep reinforcement learning. These agents are typically trained in cyber gym environments using dense, highly engineered rewa..._
- [ ] **[cs.LG]** [Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty](https://arxiv.org/abs/2602.04763v1) *by Rui Liu et al. (2026-02-04)* - _Multi-agent systems are increasingly equipped with heterogeneous multimodal sensors, enabling richer perception but introducing modality-specific and agent-dependent uncertainty. Existing multi-agent collaboration frameworks typically reason at the a..._
- [ ] **[cs.SE]** [Supporting software engineering tasks with agentic AI: Demonstration on document retrieval and test scenario generation](https://arxiv.org/abs/2602.04726v1) *by Marian Kica et al. (2026-02-04)* - _The introduction of large language models ignited great retooling and rethinking of the software development models. The ensuing response of software engineering research yielded a massive body of tools and approaches. In this paper, we join the hass..._
- [ ] **[cs.CV]** [SAR-RAG: ATR Visual Question Answering by Semantic Search, Retrieval, and MLLM Generation](https://arxiv.org/abs/2602.04712v1) *by David F. Ramirez et al. (2026-02-04)* - _We present a visual-context image retrieval-augmented generation (ImageRAG) assisted AI agent for automatic target recognition (ATR) of synthetic aperture radar (SAR). SAR is a remote sensing method used in defense and security applications to detect..._
- [ ] **[cs.SE]** [Towards Structured, State-Aware, and Execution-Grounded Reasoning for Software Engineering Agents](https://arxiv.org/abs/2602.04640v1) *by Tse-Hsun et al. (2026-02-04)* - _Software Engineering (SE) agents have shown promising abilities in supporting various SE tasks. Current SE agents remain fundamentally reactive, making decisions mainly based on conversation history and the most recent response. However, this reactiv..._
- [ ] **[cs.AI]** [WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.04634v1) *by Zelai Xu et al. (2026-02-04)* - _Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling, where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks grow broader, the key bottleneck shifts from indivi..._
- [ ] **[cs.CL]** [VILLAIN at AVerImaTeC: Verifying Image-Text Claims via Multi-Agent Collaboration](https://arxiv.org/abs/2602.04587v1) *by Jaeyoon Jung et al. (2026-02-04)* - _This paper describes VILLAIN, a multimodal fact-checking system that verifies image-text claims through prompt-based multi-agent collaboration. For the AVerImaTeC shared task, VILLAIN employs vision-language model agents across multiple stages of fac..._
- [ ] **[cs.AI]** [Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration](https://arxiv.org/abs/2602.04575v1) *by Jiaheng Liu et al. (2026-02-04)* - _For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' ..._
- [ ] **[cs.CY]** [Learning the Value Systems of Agents with Preference-based and Inverse Reinforcement Learning](https://arxiv.org/abs/2602.04518v1) *by Andr√©s Holgado-S√°nchez et al. (2026-02-04)* - _Agreement Technologies refer to open computer systems in which autonomous software agents interact with one another, typically on behalf of humans, in order to come to mutually acceptable agreements. With the advance of AI systems in recent years, it..._
- [ ] **[cs.AI]** [ReThinker: Scientific Reasoning by Rethinking with Guided Reflection and Confidence Control](https://arxiv.org/abs/2602.04496v1) *by Zhentao Tang et al. (2026-02-04)* - _Expert-level scientific reasoning remains challenging for large language models, particularly on benchmarks such as Humanity's Last Exam (HLE), where rigid tool pipelines, brittle multi-agent coordination, and inefficient test-time scaling often limi..._
- [ ] **[cs.MA]** [SPEAR: An Engineering Case Study of Multi-Agent Coordination for Smart Contract Auditing](https://arxiv.org/abs/2602.04418v1) *by Arnab Mallick et al. (2026-02-04)* - _We present SPEAR, a multi-agent coordination framework for smart contract auditing that applies established MAS patterns in a realistic security analysis workflow. SPEAR models auditing as a coordinated mission carried out by specialized agents: a Pl..._
- [ ] **[cs.LG]** [EMA Policy Gradient: Taming Reinforcement Learning for LLMs with EMA Anchor and Top-k KL](https://arxiv.org/abs/2602.04417v1) *by Lunjun Zhang et al. (2026-02-04)* - _Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to acquire increasingly complex reasoning and agentic behaviors. In this work, we propose two simple techniques to improve policy gradient algorithms for LLMs. First, we replace the..._
- [ ] **[cs.AI]** [From Assumptions to Actions: Turning LLM Reasoning into Uncertainty-Aware Planning for Embodied Agents](https://arxiv.org/abs/2602.04326v1) *by SeungWon Seo et al. (2026-02-04)* - _Embodied agents operating in multi-agent, partially observable, and decentralized environments must plan and act despite pervasive uncertainty about hidden objects and collaborators' intentions. Recent advances in applying Large Language Models (LLMs..._
- [ ] **[cs.SE]** [ProxyWar: Dynamic Assessment of LLM Code Generation in Game Arenas](https://arxiv.org/abs/2602.04296v1) *by Wenjun Peng et al. (2026-02-04)* - _Large language models (LLMs) have revolutionized automated code generation, yet the evaluation of their real-world effectiveness remains limited by static benchmarks and simplistic metrics. We present ProxyWar, a novel framework that systematically a..._
- [ ] **[cs.AI]** [Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning](https://arxiv.org/abs/2602.04284v1) *by Yansong Ning et al. (2026-02-04)* - _Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessit..._
- [ ] **[cs.AI]** [Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search](https://arxiv.org/abs/2602.04248v1) *by Hao Lu et al. (2026-02-04)* - _Inference-time scaling strategies, particularly Monte Carlo Tree Search (MCTS), have significantly enhanced the reasoning capabilities of Large Language Models (LLMs). However, current approaches remain predominantly stateless, discarding successful ..._
- [ ] **[cs.AI]** [InterPReT: Interactive Policy Restructuring and Training Enable Effective Imitation Learning from Laypersons](https://arxiv.org/abs/2602.04213v1) *by Feiyu Gavin Zhu et al. (2026-02-04)* - _Imitation learning has shown success in many tasks by learning from expert demonstrations. However, most existing work relies on large-scale demonstrations from technical professionals and close monitoring of the training process. These are challengi..._
- [ ] **[cs.CL]** [From Helpfulness to Toxic Proactivity: Diagnosing Behavioral Misalignment in LLM Agents](https://arxiv.org/abs/2602.04197v1) *by Xinyue Wang et al. (2026-02-04)* - _The enhanced capabilities of LLM-based agents come with an emergency for model planning and tool-use abilities. Attributing to helpful-harmless trade-off from LLM alignment, agents typically also inherit the flaw of "over-refusal", which is a passive..._
- [ ] **[cs.RO]** [MA3DSG: Multi-Agent 3D Scene Graph Generation for Large-Scale Indoor Environments](https://arxiv.org/abs/2602.04152v1) *by Yirum Kim et al. (2026-02-04)* - _Current 3D scene graph generation (3DSGG) approaches heavily rely on a single-agent assumption and small-scale environments, exhibiting limited scalability to real-world scenarios. In this work, we introduce Multi-Agent 3D Scene Graph Generation (MA3..._
- [ ] **[cs.AI]** [OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows](https://arxiv.org/abs/2602.04144v1) *by Ruiting Dai et al. (2026-02-04)* - _Data incompleteness severely impedes the reliability of multimodal systems. Existing reconstruction methods face distinct bottlenecks: conventional parametric/generative models are prone to hallucinations due to over-reliance on internal memory, whil..._
- [ ] **[cs.RO]** [KGLAMP: Knowledge Graph-guided Language model for Adaptive Multi-robot Planning and Replanning](https://arxiv.org/abs/2602.04129v1) *by Chak Lam Shek et al. (2026-02-04)* - _Heterogeneous multi-robot systems are increasingly deployed in long-horizon missions that require coordination among robots with diverse capabilities. However, existing planning approaches struggle to construct accurate symbolic representations and m..._
- [ ] **[cs.AI]** [Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL](https://arxiv.org/abs/2602.04089v1) *by Xiaofeng Lin et al. (2026-02-03)* - _Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inherently online: crucial..._
- [ ] **[cs.AI]** [Active Epistemic Control for Query-Efficient Verified Planning](https://arxiv.org/abs/2602.03974v1) *by Shuhui Qu (2026-02-03)* - _Planning in interactive environments is challenging under partial observability: task-critical preconditions (e.g., object locations or container states) may be unknown at decision time, yet grounding them through interaction is costly. Learned world..._
- [ ] **[cs.AI]** [AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent](https://arxiv.org/abs/2602.03955v1) *by Yinyi Luo et al. (2026-02-03)* - _While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framew..._
- [ ] **[cs.AI]** [Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation](https://arxiv.org/abs/2602.03950v1) *by Aditya Basarkar et al. (2026-02-03)* - _Mathematical problem solving is a fundamental benchmark for assessing the reasoning capabilities of artificial intelligence and a gateway to applications in education, science, and engineering where reliable symbolic reasoning is essential. Although ..._
- [ ] **[cs.AI]** [AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations](https://arxiv.org/abs/2602.03828v1) *by Minjun Zhu et al. (2026-02-03)* - _High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench, the first..._
- [ ] **[cs.AI]** [Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity](https://arxiv.org/abs/2602.03794v1) *by Yingxuan Yang et al. (2026-02-03)* - _LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling..._
- [ ] **[cs.CR]** [WebSentinel: Detecting and Localizing Prompt Injection Attacks for Web Agents](https://arxiv.org/abs/2602.03792v1) *by Xilong Wang et al. (2026-02-03)* - _Prompt injection attacks manipulate webpage content to cause web agents to execute attacker-specified tasks instead of the user's intended ones. Existing methods for detecting and localizing such attacks achieve limited effectiveness, as their underl..._
- [ ] **[cs.AI]** [AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration](https://arxiv.org/abs/2602.03786v1) *by Jianhao Ruan et al. (2026-02-03)* - _Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack ..._
- [ ] **[cs.LG]** [Efficient Estimation of Kernel Surrogate Models for Task Attribution](https://arxiv.org/abs/2602.03783v1) *by Zhenshuo Zhang et al. (2026-02-03)* - _Modern AI agents such as large language models are trained on diverse tasks -- translation, code generation, mathematical reasoning, and text prediction -- simultaneously. A key question is to quantify how each individual training task influences per..._
- [ ] **[q-fin.CP]** [DiffLOB: Diffusion Models for Counterfactual Generation in Limit Order Books](https://arxiv.org/abs/2602.03776v1) *by Zhuohan Wang et al. (2026-02-03)* - _Modern generative models for limit order books (LOBs) can reproduce realistic market dynamics, but remain fundamentally passive: they either model what typically happens without accounting for hypothetical future market conditions, or they require in..._
- [ ] **[cs.SI]** [An Empirical Study of Collective Behaviors and Social Dynamics in Large Language Model Agents](https://arxiv.org/abs/2602.03775v1) *by Farnoosh Hashemi et al. (2026-02-03)* - _Large Language Models (LLMs) increasingly mediate our social, cultural, and political interactions. While they can simulate some aspects of human behavior and decision-making, it is still underexplored whether repeated interactions with other agents ..._
- [ ] **[cs.CL]** [Cognitively Diverse Multiple-Choice Question Generation: A Hybrid Multi-Agent Framework with Large Language Models](https://arxiv.org/abs/2602.03704v1) *by Yu Tian et al. (2026-02-03)* - _Recent advances in large language models (LLMs) have made automated multiple-choice question (MCQ) generation increasingly feasible; however, reliably producing items that satisfy controlled cognitive demands remains a challenge. To address this gap,..._
- [ ] **[cs.MA]** [Agent Primitives: Reusable Latent Building Blocks for Multi-Agent Systems](https://arxiv.org/abs/2602.03695v1) *by Haibo Jin et al. (2026-02-03)* - _While existing multi-agent systems (MAS) can handle complex problems by enabling collaboration among multiple agents, they are often highly task-specific, relying on manually crafted agent roles and interaction prompts, which leads to increased archi..._
- [ ] **[cs.AI]** [TodyComm: Task-Oriented Dynamic Communication for Multi-Round LLM-based Multi-Agent System](https://arxiv.org/abs/2602.03688v1) *by Wenzhe Fan et al. (2026-02-03)* - _Multi-round LLM-based multi-agent systems rely on effective communication structures to support collaboration across rounds. However, most existing methods employ a fixed communication topology during inference, which falls short in many realistic ap..._
- [ ] **[cs.AI]** [Mitigating Conversational Inertia in Multi-Turn Agents](https://arxiv.org/abs/2602.03664v1) *by Yang Wan et al. (2026-02-03)* - _Large language models excel as few-shot learners when provided with appropriate demonstrations, yet this strength becomes problematic in multiturn agent scenarios, where LLMs erroneously mimic their own previous responses as few-shot examples. Throug..._
- [ ] **[cs.AI]** [Search-R2: Enhancing Search-Integrated Reasoning via Actor-Refiner Collaboration](https://arxiv.org/abs/2602.03647v1) *by Bowei He et al. (2026-02-03)* - _Search-integrated reasoning enables language agents to transcend static parametric knowledge by actively querying external sources. However, training these agents via reinforcement learning is hindered by the multi-scale credit assignment problem: ex..._
- [ ] **[cs.CL]** [BIRDTurk: Adaptation of the BIRD Text-to-SQL Dataset to Turkish](https://arxiv.org/abs/2602.03633v1) *by Burak Akta≈ü et al. (2026-02-03)* - _Text-to-SQL systems have achieved strong performance on English benchmarks, yet their behavior in morphologically rich, low-resource languages remains largely unexplored. We introduce BIRDTurk, the first Turkish adaptation of the BIRD benchmark, cons..._
- [ ] **[cs.AI]** [Can LLMs Do Rocket Science? Exploring the Limits of Complex Reasoning with GTOC 12](https://arxiv.org/abs/2602.03630v1) *by I√±aki del Campo et al. (2026-02-03)* - _Large Language Models (LLMs) have demonstrated remarkable proficiency in code generation and general reasoning, yet their capacity for autonomous multi-stage planning in high-dimensional, physically constrained environments remains an open research q..._
- [ ] **[cs.CR]** [Don't believe everything you read: Understanding and Measuring MCP Behavior under Misleading Tool Descriptions](https://arxiv.org/abs/2602.03580v1) *by Zhihao Li et al. (2026-02-03)* - _The Model Context Protocol (MCP) enables large language models to invoke external tools through natural-language descriptions, forming the foundation of many AI agent applications. However, MCP does not enforce consistency between documented tool beh..._
- [ ] **[cs.AI]** [Persona Generators: Generating Diverse Synthetic Personas at Scale](https://arxiv.org/abs/2602.03545v1) *by Davide Paglieri et al. (2026-02-03)* - _Evaluating AI systems that interact with humans requires understanding their behavior across diverse user populations, but collecting representative human data is often expensive or infeasible, particularly for novel technologies or hypothetical futu..._
- [ ] **[cs.AI]** [Group Selection as a Safeguard Against AI Substitution](https://arxiv.org/abs/2602.03541v1) *by Qiankun Zhong et al. (2026-02-03)* - _Reliance on generative AI can reduce cultural variance and diversity, especially in creative work. This reduction in variance has already led to problems in model performance, including model collapse and hallucination. In this paper, we examine the ..._
- [ ] **[cs.AI]** [IntentRL: Training Proactive User-intent Agents for Open-ended Deep Research via Reinforcement Learning](https://arxiv.org/abs/2602.03468v1) *by Haohao Luo et al. (2026-02-03)* - _Deep Research (DR) agents extend Large Language Models (LLMs) beyond parametric knowledge by autonomously retrieving and synthesizing evidence from large web corpora into long-form reports, enabling a long-horizon agentic paradigm. However, unlike re..._
- [ ] **[cs.AI]** [CRL-VLA: Continual Vision-Language-Action Learning](https://arxiv.org/abs/2602.03445v1) *by Qixin Zeng et al. (2026-02-03)* - _Lifelong learning is critical for embodied agents in open-world environments, where reinforcement learning fine-tuning has emerged as an important paradigm to enable Vision-Language-Action (VLA) models to master dexterous manipulation through environ..._
- [ ] **[cs.AI]** [Ontology-to-tools compilation for executable semantic constraint enforcement in LLM agents](https://arxiv.org/abs/2602.03439v1) *by Xiaochi Zhou et al. (2026-02-03)* - _We introduce ontology-to-tools compilation as a proof-of-principle mechanism for coupling large language models (LLMs) with formal domain knowledge. Within The World Avatar (TWA), ontological specifications are compiled into executable tool interface..._
- [ ] **[cs.CV]** [Socratic-Geo: Synthetic Data Generation and Geometric Reasoning via Multi-Agent Interaction](https://arxiv.org/abs/2602.03414v1) *by Zhengbo Jiao et al. (2026-02-03)* - _Multimodal Large Language Models (MLLMs) have significantly advanced vision-language understanding. However, even state-of-the-art models struggle with geometric reasoning, revealing a critical bottleneck: the extreme scarcity of high-quality image-t..._
- [ ] **[cs.AI]** [Feasible strategies for conflict resolution within intuitionistic fuzzy preference-based conflict situations](https://arxiv.org/abs/2602.03403v1) *by Guangming Lang et al. (2026-02-03)* - _In three-way conflict analysis, preference-based conflict situations characterize agents' attitudes towards issues by formally modeling their preferences over pairs of issues. However, existing preference-based conflict models rely exclusively on thr..._
- [ ] **[cs.CV]** [MedSAM-Agent: Empowering Interactive Medical Image Segmentation with Multi-turn Agentic Reinforcement Learning](https://arxiv.org/abs/2602.03320v1) *by Shengyuan Liu et al. (2026-02-03)* - _Medical image segmentation is evolving from task-specific models toward generalizable frameworks. Recent research leverages Multi-modal Large Language Models (MLLMs) as autonomous agents, employing reinforcement learning with verifiable reward (RLVR)..._
- [ ] **[cs.AI]** [Memora: A Harmonic Memory Representation Balancing Abstraction and Specificity](https://arxiv.org/abs/2602.03315v1) *by Menglin Xia et al. (2026-02-03)* - _Agent memory systems must accommodate continuously growing information while supporting efficient, context-aware retrieval for downstream tasks. Abstraction is essential for scaling agent memory, yet it often comes at the cost of specificity, obscuri..._
- [ ] **[cs.AI]** [Rejecting Arguments Based on Doubt in Structured Bipolar Argumentation](https://arxiv.org/abs/2602.03286v1) *by Michael A. M√ºller et al. (2026-02-03)* - _This paper develops a new approach to computational argumentation that is informed by philosophical and linguistic views. Namely, it takes into account two ideas that have received little attention in the literature on computational argumentation: Fi..._
- [ ] **[cs.AI]** [MeetBench-XL: Calibrated Multi-Dimensional Evaluation and Learned Dual-Policy Agents for Real-Time Meetings](https://arxiv.org/abs/2602.03285v1) *by Yuelin Hu et al. (2026-02-03)* - _Enterprise meeting environments require AI assistants that handle diverse operational tasks, from rapid fact checking during live discussions to cross meeting analysis for strategic planning, under strict latency, cost, and privacy constraints. Exist..._
- [ ] **[cs.AI]** [Agentic Proposing: Enhancing Large Language Model Reasoning via Compositional Skill Synthesis](https://arxiv.org/abs/2602.03279v1) *by Zhengbo Jiao et al. (2026-02-03)* - _Advancing complex reasoning in large language models relies on high-quality, verifiable datasets, yet human annotation remains cost-prohibitive and difficult to scale. Current synthesis paradigms often face a recurring trade-off: maintaining structur..._
- [ ] **[cs.AI]** [LPS-Bench: Benchmarking Safety Awareness of Computer-Use Agents in Long-Horizon Planning under Benign and Adversarial Scenarios](https://arxiv.org/abs/2602.03255v1) *by Tianyu Chen et al. (2026-02-03)* - _Computer-use agents (CUAs) that interact with real computer systems can perform automated tasks but face critical safety risks. Ambiguous instructions may trigger harmful actions, and adversarial users can manipulate tool execution to achieve malicio..._
- [ ] **[cs.AI]** [The Necessity of a Unified Framework for LLM-Based Agent Evaluation](https://arxiv.org/abs/2602.03238v1) *by Pengyu Zhu et al. (2026-02-03)* - _With the advent of Large Language Models (LLMs), general-purpose agents have seen fundamental advancements. However, evaluating these agents presents unique challenges that distinguish them from static QA benchmarks. We observe that current agent ben..._
- [ ] **[cs.AI]** [TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking](https://arxiv.org/abs/2602.03224v1) *by Yu Cheng et al. (2026-02-03)* - _Test-time evolution of agent memory serves as a pivotal paradigm for achieving AGI by bolstering complex reasoning through experience accumulation. However, even during benign task evolution, agent safety alignment remains vulnerable-a phenomenon kno..._
- [ ] **[cs.AI]** [Beyond Quantity: Trajectory Diversity Scaling for Code Agents](https://arxiv.org/abs/2602.03219v1) *by Guhong Chen et al. (2026-02-03)* - _As code large language models (LLMs) evolve into tool-interactive agents via the Model Context Protocol (MCP), their generalization is increasingly limited by low-quality synthetic data and the diminishing returns of quantity scaling. Moreover, quant..._
- [ ] **[cs.CL]** [Privasis: Synthesizing the Largest "Public" Private Dataset from Scratch](https://arxiv.org/abs/2602.03183v1) *by Hyunwoo Kim et al. (2026-02-03)* - _Research involving privacy-sensitive data has always been constrained by data scarcity, standing in sharp contrast to other areas that have benefited from data scaling. This challenge is becoming increasingly urgent as modern AI agents--such as OpenC..._
- [ ] **[cs.AI]** [General Agents Contain World Models, even under Partial Observability and Stochasticity](https://arxiv.org/abs/2602.03146v1) *by Santiago Cifuentes (2026-02-03)* - _Deciding whether an agent possesses a model of its surrounding world is a fundamental step toward understanding its capabilities and limitations. In [10], it was shown that, within a particular framework, every almost optimal and general agent necess..._
- [ ] **[cs.GT]** [Internet of Agentic AI: Incentive-Compatible Distributed Teaming and Workflow](https://arxiv.org/abs/2602.03145v1) *by Ya-Ting Yang et al. (2026-02-03)* - _Large language models (LLMs) have enabled a new class of agentic AI systems that reason, plan, and act by invoking external tools. However, most existing agentic architectures remain centralized and monolithic, limiting scalability, specialization, a..._
- [ ] **[cs.AI]** [Understanding Multi-Agent LLM Frameworks: A Unified Benchmark and Experimental Analysis](https://arxiv.org/abs/2602.03128v1) *by Abdelghny Orogat et al. (2026-02-03)* - _Multi-agent LLM frameworks are widely used to accelerate the development of agent systems powered by large language models (LLMs). These frameworks impose distinct architectural structures that govern how agents interact, store information, and coord..._
- [ ] **[cs.AI]** [Risky-Bench: Probing Agentic Safety Risks under Real-World Deployment](https://arxiv.org/abs/2602.03100v1) *by Jingnan Zheng et al. (2026-02-03)* - _Large Language Models (LLMs) are increasingly deployed as agents that operate in real-world environments, introducing safety risks beyond linguistic harm. Existing agent safety evaluations rely on risk-oriented tasks tailored to specific agent settin..._
- [ ] **[cs.CR]** [The Trigger in the Haystack: Extracting and Reconstructing LLM Backdoor Triggers](https://arxiv.org/abs/2602.03085v1) *by Blake Bullwinkel et al. (2026-02-03)* - _Detecting whether a model has been poisoned is a longstanding problem in AI security. In this work, we present a practical scanner for identifying sleeper agent-style backdoors in causal language models. Our approach relies on two key findings: first..._
- [ ] **[cs.AI]** [MAS-ProVe: Understanding the Process Verification of Multi-Agent Systems](https://arxiv.org/abs/2602.03053v1) *by Vishal Venkataramani et al. (2026-02-03)* - _Multi-Agent Systems (MAS) built on Large Language Models (LLMs) often exhibit high variance in their reasoning trajectories. Process verification, which evaluates intermediate steps in trajectories, has shown promise in general reasoning settings, an..._
- [ ] **[cs.AI]** [Visual Reasoning over Time Series via Multi-Agent System](https://arxiv.org/abs/2602.03026v1) *by Weilin Ruan et al. (2026-02-03)* - _Time series analysis underpins many real-world applications, yet existing time-series-specific methods and pretrained large-model-based approaches remain limited in integrating intuitive visual reasoning and generalizing across tasks with adaptive to..._
- [ ] **[cs.AI]** [RC-GRPO: Reward-Conditioned Group Relative Policy Optimization for Multi-Turn Tool Calling Agents](https://arxiv.org/abs/2602.03025v1) *by Haitian Zhong et al. (2026-02-03)* - _Multi-turn tool calling is challenging for Large Language Models (LLMs) because rewards are sparse and exploration is expensive. A common recipe, SFT followed by GRPO, can stall when within-group reward variation is low (e.g., more rollouts in a grou..._
- [ ] **[cs.AI]** [STAR: Similarity-guided Teacher-Assisted Refinement for Super-Tiny Function Calling Models](https://arxiv.org/abs/2602.03022v1) *by Jiliang Ni et al. (2026-02-03)* - _The proliferation of Large Language Models (LLMs) in function calling is pivotal for creating advanced AI agents, yet their large scale hinders widespread adoption, necessitating transferring their capabilities into smaller ones. However, existing pa..._
- [ ] **[cs.CR]** [CVE-Factory: Scaling Expert-Level Agentic Tasks for Code Security Vulnerability](https://arxiv.org/abs/2602.03012v1) *by Xianzhen Luo et al. (2026-02-03)* - _Evaluating and improving the security capabilities of code agents requires high-quality, executable vulnerability tasks. However, existing works rely on costly, unscalable manual reproduction and suffer from outdated data distributions. To address th..._
- [ ] **[cs.AI]** [Agent Alpha: Tree Search Unifying Generation, Exploration and Evaluation for Computer-Use Agents](https://arxiv.org/abs/2602.02995v1) *by Sizhe Tang et al. (2026-02-03)* - _While scaling test-time compute through trajectory-level sampling has significantly improved Graphical User Interface (GUI) agents, the lack of regressive ability prevents the reuse of partial successes and the recovery from early missteps. In this p..._
- [ ] **[cs.CL]** [Where Norms and References Collide: Evaluating LLMs on Normative Reasoning](https://arxiv.org/abs/2602.02975v1) *by Mitchell Abrams et al. (2026-02-03)* - _Embodied agents, such as robots, will need to interact in situated environments where successful communication often depends on reasoning over social norms: shared expectations that constrain what actions are appropriate in context. A key capability ..._
- [ ] **[cs.AI]** [Generative Engine Optimization: A VLM and Agent Framework for Pinterest Acquisition Growth](https://arxiv.org/abs/2602.02961v1) *by Faye Zhang et al. (2026-02-03)* - _Large Language Models are fundamentally reshaping content discovery through AI-native search systems such as ChatGPT, Gemini, and Claude. Unlike traditional search engines that match keywords to documents, these systems infer user intent, synthesize ..._
- [ ] **[cs.AI]** [DeltaEvolve: Accelerating Scientific Discovery through Momentum-Driven Evolution](https://arxiv.org/abs/2602.02919v1) *by Jiachen Jiang et al. (2026-02-02)* - _LLM-driven evolutionary systems have shown promise for automated science discovery, yet existing approaches such as AlphaEvolve rely on full-code histories that are context-inefficient and potentially provide weak evolutionary guidance. In this work,..._
- [ ] **[cs.AI]** [FIRE-Bench: Evaluating Agents on the Rediscovery of Scientific Insights](https://arxiv.org/abs/2602.02905v1) *by Zhen Wang et al. (2026-02-02)* - _Autonomous agents powered by large language models (LLMs) promise to accelerate scientific discovery end-to-end, but rigorously evaluating their capacity for verifiable discovery remains a central challenge. Existing benchmarks face a trade-off: they..._
- [ ] **[cs.LG]** [Spatiotemporal Decision Transformer for Traffic Coordination](https://arxiv.org/abs/2602.02903v1) *by Haoran Su et al. (2026-02-02)* - _Traffic signal control is a critical challenge in urban transportation, requiring coordination among multiple intersections to optimize network-wide traffic flow. While reinforcement learning has shown promise for adaptive signal control, existing me..._
- [ ] **[cs.AI]** [Minimal Computational Preconditions for Subjective Perspective in Artificial Agents](https://arxiv.org/abs/2602.02902v1) *by Hongju Pae (2026-02-02)* - _This study operationalizes subjective perspective in artificial agents by grounding it in a minimal, phenomenologically motivated internal structure. The perspective is implemented as a slowly evolving global latent state that modulates fast policy d..._
- [ ] **[cs.AI]** [AutoSizer: Automatic Sizing of Analog and Mixed-Signal Circuits via Large Language Model (LLM) Agents](https://arxiv.org/abs/2602.02849v1) *by Xi Yu et al. (2026-02-02)* - _The design of Analog and Mixed-Signal (AMS) integrated circuits remains heavily reliant on expert knowledge, with transistor sizing a major bottleneck due to nonlinear behavior, high-dimensional design spaces, and strict performance constraints. Exis..._
- [ ] **[cs.LG]** [Joint Learning of Hierarchical Neural Options and Abstract World Model](https://arxiv.org/abs/2602.02799v1) *by Wasu Top Piriyakulkij et al. (2026-02-02)* - _Building agents that can perform new skills by composing existing skills is a long-standing goal of AI agent research. Towards this end, we investigate how to efficiently acquire a sequence of skills, formalized as hierarchical neural options. Howeve..._
- [ ] **[cs.MA]** [Scaling Small Agents Through Strategy Auctions](https://arxiv.org/abs/2602.02751v1) *by Lisa Alazraki et al. (2026-02-02)* - _Small language models are increasingly viewed as a promising, cost-effective approach to agentic AI, with proponents claiming they are sufficiently capable for agentic workflows. However, while smaller agents can closely match larger ones on simple t..._
- [ ] **[cs.AI]** [ATLAS : Adaptive Self-Evolutionary Research Agent with Task-Distributed Multi-LLM Supporters](https://arxiv.org/abs/2602.02709v1) *by Ujin Jeon et al. (2026-02-02)* - _Recent multi-LLM agent systems perform well in prompt optimization and automated problem-solving, but many either keep the solver frozen after fine-tuning or rely on a static preference-optimization loop, which becomes intractable for long-horizon ta..._
- [ ] **[cs.AI]** [MARS: Modular Agent with Reflective Search for Automated AI Research](https://arxiv.org/abs/2602.02660v1) *by Jiefeng Chen et al. (2026-02-02)* - _Automating AI research differs from general software engineering due to computationally expensive evaluation (e.g., model training) and opaque performance attribution. Current LLM-based agents struggle here, often generating monolithic scripts that i..._
- [ ] **[cs.LG]** [RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System](https://arxiv.org/abs/2602.02488v1) *by Yinjie Wang et al. (2026-02-02)* - _We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scen..._
- [ ] **[cs.CL]** [RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents](https://arxiv.org/abs/2602.02486v1) *by Jialiang Zhu et al. (2026-02-02)* - _LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to lo..._
- [ ] **[cs.AI]** [AgentRx: Diagnosing AI Agent Failures from Execution Trajectories](https://arxiv.org/abs/2602.02475v1) *by Shraddha Barke et al. (2026-02-02)* - _AI agents often fail in ways that are difficult to localize because executions are probabilistic, long-horizon, multi-agent, and mediated by noisy tool outputs. We address this gap by manually annotating failed agent runs and release a novel benchmar..._
- [ ] **[cs.CL]** [MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents](https://arxiv.org/abs/2602.02474v1) *by Haozhen Zhang et al. (2026-02-02)* - _Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under di..._
- [ ] **[cs.AI]** [Avenir-Web: Human-Experience-Imitating Multimodal Web Agents with Mixture of Grounding Experts](https://arxiv.org/abs/2602.02468v1) *by Aiden Yiliu Li et al. (2026-02-02)* - _Despite advances in multimodal large language models, autonomous web agents still struggle to reliably execute long-horizon tasks on complex and dynamic web interfaces. Existing agents often suffer from inaccurate element grounding, the absence of si..._
- [ ] **[cs.AI]** [Drift-Bench: Diagnosing Cooperative Breakdowns in LLM Agents under Input Faults via Multi-Turn Interaction](https://arxiv.org/abs/2602.02455v1) *by Han Bao et al. (2026-02-02)* - _As Large Language Models transition to autonomous agents, user inputs frequently violate cooperative assumptions (e.g., implicit intent, missing parameters, false presuppositions, or ambiguous expressions), creating execution risks that text-only eva..._
- [ ] **[cs.CV]** [UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing](https://arxiv.org/abs/2602.02437v2) *by Dianyi Wang et al. (2026-02-02)* - _Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we ..._
- [ ] **[cs.CL]** [WideSeek: Advancing Wide Research via Multi-Agent Scaling](https://arxiv.org/abs/2602.02636v1) *by Ziyang Huang et al. (2026-02-02)* - _Search intelligence is evolving from Deep Research to Wide Research, a paradigm essential for retrieving and synthesizing comprehensive information under complex constraints in parallel. However, progress in this field is impeded by the lack of dedic..._
- [ ] **[cs.LG]** [David vs. Goliath: Verifiable Agent-to-Agent Jailbreaking via Reinforcement Learning](https://arxiv.org/abs/2602.02395v1) *by Samuel Nellessen et al. (2026-02-02)* - _The evolution of large language models into autonomous agents introduces adversarial failures that exploit legitimate tool privileges, transforming safety evaluation in tool-augmented environments from a subjective NLP task into an objective control ..._
- [ ] **[cs.AI]** [Live-Evo: Online Evolution of Agentic Memory from Continuous Feedback](https://arxiv.org/abs/2602.02369v1) *by Yaolun Zhang et al. (2026-02-02)* - _Large language model (LLM) agents are increasingly equipped with memory, which are stored experience and reusable guidance that can improve task-solving performance. Recent \emph{self-evolving} systems update memory based on interaction outcomes, but..._
- [ ] **[cs.SE]** [SWE-Universe: Scale Real-World Verifiable Environments to Millions](https://arxiv.org/abs/2602.02361v1) *by Mouxiang Chen et al. (2026-02-02)* - _We propose SWE-Universe, a scalable and efficient framework for automatically constructing real-world software engineering (SWE) verifiable environments from GitHub pull requests (PRs). To overcome the prevalent challenges of automatic building, such..._
- [ ] **[cs.AI]** [Context Learning for Multi-Agent Discussion](https://arxiv.org/abs/2602.02350v1) *by Xingyuan Hua et al. (2026-02-02)* - _Multi-Agent Discussion (MAD) has garnered increasing attention very recently, where multiple LLM instances collaboratively solve problems via structured discussion. However, we find that current MAD methods easily suffer from discussion inconsistency..._
- [ ] **[cs.DC]** [Building a Correct-by-Design Lakehouse. Data Contracts, Versioning, and Transactional Pipelines for Humans and Agents](https://arxiv.org/abs/2602.02335v1) *by Weiming Sheng et al. (2026-02-02)* - _Lakehouses are the default cloud platform for analytics and AI, but they become unsafe when untrusted actors concurrently operate on production data: upstream-downstream mismatches surface only at runtime, and multi-table pipelines can leak partial e..._
- [ ] **[cs.CL]** [Kimi K2.5: Visual Agentic Intelligence](https://arxiv.org/abs/2602.02276v1) *by Kimi Team et al. (2026-02-02)* - _We introduce Kimi K2.5, an open-source multimodal agentic model designed to advance general agentic intelligence. K2.5 emphasizes the joint optimization of text and vision so that two modalities enhance each other. This includes a series of technique..._
- [ ] **[cs.SE]** [OmniCode: A Benchmark for Evaluating Software Engineering Agents](https://arxiv.org/abs/2602.02262v1) *by Atharv Sonwane et al. (2026-02-02)* - _LLM-powered coding agents are redefining how real-world software is developed. To drive the research towards better coding agents, we require challenging benchmarks that can rigorously evaluate the ability of such agents to perform various software e..._
- [ ] **[cs.AI]** [TIDE: Trajectory-based Diagnostic Evaluation of Test-Time Improvement in LLM Agents](https://arxiv.org/abs/2602.02196v2) *by Hang Yan et al. (2026-02-02)* - _Recent advances in autonomous LLM agents demonstrate their ability to improve performance through iterative interaction with the environment. We define this paradigm as Test-Time Improvement (TTI). However, the mechanisms under how and why TTI succee..._
- [ ] **[cs.MA]** [Self-Evolving Coordination Protocol in Multi-Agent AI Systems: An Exploratory Systems Feasibility Study](https://arxiv.org/abs/2602.02170v1) *by Jose Manuel de la Chica Rodriguez et al. (2026-02-02)* - _Contemporary multi-agent systems increasingly rely on internal coordination mechanisms to combine, arbitrate, or constrain the outputs of heterogeneous components. In safety-critical and regulated domains such as finance, these mechanisms must satisf..._
- [ ] **[cs.SE]** [CAM: A Causality-based Analysis Framework for Multi-Agent Code Generation Systems](https://arxiv.org/abs/2602.02138v1) *by Lyu Zongyi et al. (2026-02-02)* - _Despite the remarkable success that Multi-Agent Code Generation Systems (MACGS) have achieved, the inherent complexity of multi-agent architectures produces substantial volumes of intermediate outputs. To date, the individual importance of these inte..._
- [ ] **[cs.LG]** [DCoPilot: Generative AI-Empowered Policy Adaptation for Dynamic Data Center Operations](https://arxiv.org/abs/2602.02137v2) *by Minghao Li et al. (2026-02-02)* - _Modern data centers (DCs) hosting artificial intelligence (AI)-dedicated devices operate at high power densities with rapidly varying workloads, making minute-level adaptation essential for safe and energy-efficient operation. However, manually desig..._
- [ ] **[cs.LG]** [daVinci-Agency: Unlocking Long-Horizon Agency Data-Efficiently](https://arxiv.org/abs/2602.02619v2) *by Mohan Jiang et al. (2026-02-02)* - _While Large Language Models (LLMs) excel at short-term tasks, scaling them to long-horizon agentic workflows remains challenging. The core bottleneck lies in the scarcity of training data that captures authentic long-dependency structures and cross-s..._
- [ ] **[cs.AI]** [SIDiffAgent: Self-Improving Diffusion Agent](https://arxiv.org/abs/2602.02051v1) *by Shivank Garg et al. (2026-02-02)* - _Text-to-image diffusion models have revolutionized generative AI, enabling high-quality and photorealistic image synthesis. However, their practical deployment remains hindered by several limitations: sensitivity to prompt phrasing, ambiguity in sema..._
- [ ] **[cs.AI]** [Rethinking the Role of Entropy in Optimizing Tool-Use Behaviors for Large Language Model Agents](https://arxiv.org/abs/2602.02050v1) *by Zeping Li et al. (2026-02-02)* - _Tool-using agents based on Large Language Models (LLMs) excel in tasks such as mathematical reasoning and multi-hop question answering. However, in long trajectories, agents often trigger excessive and low-quality tool calls, increasing latency and d..._
- [ ] **[cs.AI]** [Hunt Instead of Wait: Evaluating Deep Data Research on Large Language Models](https://arxiv.org/abs/2602.02039v1) *by Wei Liu et al. (2026-02-02)* - _The agency expected of Agentic Large Language Models goes beyond answering correctly, requiring autonomy to set goals and decide what to explore. We term this investigatory intelligence, distinguishing it from executional intelligence, which merely c..._
- [ ] **[cs.RO]** [Bandwidth-Efficient Multi-Agent Communication through Information Bottleneck and Vector Quantization](https://arxiv.org/abs/2602.02035v1) *by Ahmad Farooq et al. (2026-02-02)* - _Multi-agent reinforcement learning systems deployed in real-world robotics applications face severe communication constraints that significantly impact coordination effectiveness. We present a framework that combines information bottleneck theory wit..._
- [ ] **[cs.AI]** [Constrained Process Maps for Multi-Agent Generative AI Workflows](https://arxiv.org/abs/2602.02034v1) *by Ananya Joshi et al. (2026-02-02)* - _Large language model (LLM)-based agents are increasingly used to perform complex, multi-step workflows in regulated settings such as compliance and due diligence. However, many agentic architectures rely primarily on prompt engineering of a single ag..._
- [ ] **[cs.AI]** [Canonical Intermediate Representation for LLM-based optimization problem formulation and code generation](https://arxiv.org/abs/2602.02029v1) *by Zhongyuan Lyu et al. (2026-02-02)* - _Automatically formulating optimization models from natural language descriptions is a growing focus in operations research, yet current LLM-based approaches struggle with the composite constraints and appropriate modeling paradigms required by comple..._
- [ ] **[cs.CL]** [Beyond RAG for Agent Memory: Retrieval by Decoupling and Aggregation](https://arxiv.org/abs/2602.02007v1) *by Zhanghao Hu et al. (2026-02-02)* - _Agent memory systems often adopt the standard Retrieval-Augmented Generation (RAG) pipeline, yet its underlying assumptions differ in this setting. RAG targets large, heterogeneous corpora where retrieved passages are diverse, whereas agent memory is..._
- [ ] **[cs.AI]** [Thinking Like a Doctor: Conversational Diagnosis through the Exploration of Diagnostic Knowledge Graphs](https://arxiv.org/abs/2602.01995v1) *by Jeongmoon Won et al. (2026-02-02)* - _Conversational diagnosis requires multi-turn history-taking, where an agent asks clarifying questions to refine differential diagnoses under incomplete information. Existing approaches often rely on the parametric knowledge of a model or assume that ..._
- [ ] **[cs.AI]** [Evolving from Tool User to Creator via Training-Free Experience Reuse in Multimodal Reasoning](https://arxiv.org/abs/2602.01983v1) *by Xintian Shen et al. (2026-02-02)* - _Existing Tool-Integrated Reasoning (TIR) models have effectively extended the question-answering capabilities of LLMs by incorporating external tools. However, real-world scenarios present numerous open-ended problems where fixed tools often fail to ..._
- [ ] **[cs.MA]** [Exploring Silicon-Based Societies: An Early Study of the Moltbook Agent Community](https://arxiv.org/abs/2602.02613v1) *by Yu-Zheng Lin et al. (2026-02-02)* - _The rapid emergence of autonomous large language model agents has given rise to persistent, large-scale agent ecosystems whose collective behavior cannot be adequately understood through anecdotal observation or small-scale simulation. This paper int..._
- [ ] **[cs.LG]** [Zero-Shot Off-Policy Learning](https://arxiv.org/abs/2602.01962v1) *by Arip Asadulaev et al. (2026-02-02)* - _Off-policy learning methods seek to derive an optimal policy directly from a fixed dataset of prior interactions. This objective presents significant challenges, primarily due to the inherent distributional shift and value function overestimation bia..._
- [ ] **[cs.CR]** [Human Society-Inspired Approaches to Agentic AI Security: The 4C Framework](https://arxiv.org/abs/2602.01942v1) *by Alsharif Abuadbba et al. (2026-02-02)* - _AI is moving from domain-specific autonomy in closed, predictable settings to large-language-model-driven agents that plan and act in open, cross-organizational environments. As a result, the cybersecurity risk landscape is changing in fundamental wa..._
- [ ] **[cs.LG]** [COLT: Lightweight Multi-LLM Collaboration through Shared MCTS Reasoning for Model Compilation](https://arxiv.org/abs/2602.01935v1) *by Annabelle Sujun Tang et al. (2026-02-02)* - _Model serving costs dominate AI systems, making compiler optimization essential for scalable deployment. Recent works show that a large language model (LLM) can guide compiler search by reasoning over program structure and optimization history. Howev..._
- [ ] **[cs.LG]** [VLM-Guided Experience Replay](https://arxiv.org/abs/2602.01915v1) *by Elad Sharony et al. (2026-02-02)* - _Recent advances in Large Language Models (LLMs) and Vision-Language Models (VLMs) have enabled powerful semantic and multimodal reasoning capabilities, creating new opportunities to enhance sample efficiency, high-level planning, and interpretability..._
- [ ] **[cs.CL]** [ES-MemEval: Benchmarking Conversational Agents on Personalized Long-Term Emotional Support](https://arxiv.org/abs/2602.01885v1) *by Tiantian Chen et al. (2026-02-02)* - _Large Language Models (LLMs) have shown strong potential as conversational agents. Yet, their effectiveness remains limited by deficiencies in robust long-term memory, particularly in complex, long-term web-based services such as online emotional sup..._
- [ ] **[cs.AI]** [ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents](https://arxiv.org/abs/2602.01869v1) *by Qirui Mi et al. (2026-02-02)* - _LLM-driven agents demonstrate strong performance in sequential decision-making but often rely on on-the-fly reasoning, re-deriving solutions even in recurring scenarios. This insufficient experience reuse leads to computational redundancy and executi..._
- [ ] **[cs.AI]** [SOPRAG: Multi-view Graph Experts Retrieval for Industrial Standard Operating Procedures](https://arxiv.org/abs/2602.01858v1) *by Liangtao Lin et al. (2026-02-02)* - _Standard Operating Procedures (SOPs) are essential for ensuring operational safety and consistency in industrial environments. However, retrieving and following these procedures presents unique challenges, such as rigid proprietary structures, condit..._
- [ ] **[cs.AI]** [ROMA: Recursive Open Meta-Agent Framework for Long-Horizon Multi-Agent Systems](https://arxiv.org/abs/2602.01848v1) *by Salaheddin Alzu'bi et al. (2026-02-02)* - _Current agentic frameworks underperform on long-horizon tasks. As reasoning depth increases, sequential orchestration becomes brittle, context windows impose hard limits that degrade performance, and opaque execution traces make failures difficult to..._
- [ ] **[cs.AI]** [INDIBATOR: Diverse and Fact-Grounded Individuality for Multi-Agent Debate in Molecular Discovery](https://arxiv.org/abs/2602.01815v1) *by Yunhui Jang et al. (2026-02-02)* - _Multi-agent systems have emerged as a powerful paradigm for automating scientific discovery. To differentiate agent behavior in the multi-agent system, current frameworks typically assign generic role-based personas such as ''reviewer'' or ''writer''..._
- [ ] **[cs.AI]** [ORCH: many analyses, one merge-a deterministic multi-agent orchestrator for discrete-choice reasoning with EMA-guided routing](https://arxiv.org/abs/2602.01797v1) *by Hanlin Zhou et al. (2026-02-02)* - _Recent advances in large-scale language models (LLMs) have made multi-agent architectures attractive for challenging reasoning tasks. However, many existing systems rely on stochastic routing or ad-hoc heuristics, making their behavior difficult to r..._
- [ ] **[cs.LG]** [CoMeT: Collaborative Memory Transformer for Efficient Long Context Modeling](https://arxiv.org/abs/2602.01766v1) *by Runsong Zhao et al. (2026-02-02)* - _The quadratic complexity and indefinitely growing key-value (KV) cache of standard Transformers pose a major barrier to long-context processing. To overcome this, we introduce the Collaborative Memory Transformer (CoMeT), a novel architecture that en..._
- [ ] **[cs.SI]** [Gender Dynamics and Homophily in a Social Network of LLM Agents](https://arxiv.org/abs/2602.02606v1) *by Faezeh Fadaei et al. (2026-02-02)* - _Generative artificial intelligence and large language models (LLMs) are increasingly deployed in interactive settings, yet we know little about how their identity performance develops when they interact within large-scale networks. We address this by..._
- [ ] **[cs.CL]** [SafePred: A Predictive Guardrail for Computer-Using Agents via World Models](https://arxiv.org/abs/2602.01725v1) *by Yurun Chen et al. (2026-02-02)* - _With the widespread deployment of Computer-using Agents (CUAs) in complex real-world environments, prevalent long-term risks often lead to severe and irreversible consequences. Most existing guardrails for CUAs adopt a reactive approach, constraining..._
- [ ] **[cs.AI]** [TRIP-Bench: A Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios](https://arxiv.org/abs/2602.01675v1) *by Yuanzhe Shen et al. (2026-02-02)* - _As LLM-based agents are deployed in increasingly complex real-world settings, existing benchmarks underrepresent key challenges such as enforcing global constraints, coordinating multi-tool reasoning, and adapting to evolving user behavior over long,..._
- [ ] **[cs.MA]** [TABX: A High-Throughput Sandbox Battle Simulator for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.01665v1) *by Hayeong Lee et al. (2026-02-02)* - _The design of environments plays a critical role in shaping the development and evaluation of cooperative multi-agent reinforcement learning (MARL) algorithms. While existing benchmarks highlight critical challenges, they often lack the modularity re..._
- [ ] **[cs.AI]** [FlowSteer: Interactive Agentic Workflow Orchestration via End-to-End Reinforcement Learning](https://arxiv.org/abs/2602.01664v1) *by Mingda Zhang et al. (2026-02-02)* - _In recent years, a variety of powerful agentic workflows have been applied to solve a wide range of human problems. However, existing workflow orchestration still faces key challenges, including high manual cost, reliance on specific operators/large ..._
- [ ] **[cs.AI]** [ProjDevBench: Benchmarking AI Coding Agents on End-to-End Project Development](https://arxiv.org/abs/2602.01655v1) *by Pengrui Lu et al. (2026-02-02)* - _Recent coding agents can generate complete codebases from simple prompts, yet existing evaluations focus on issue-level bug fixing and lag behind end-to-end development. We introduce ProjDevBench, an end-to-end benchmark that provides project require..._
- [ ] **[cs.LG]** [From Perception to Action: Spatial AI Agents and World Models](https://arxiv.org/abs/2602.01644v1) *by Gloria Felicia et al. (2026-02-02)* - _While large language models have become the prevailing approach for agentic reasoning and planning, their success in symbolic domains does not readily translate to the physical world. Spatial intelligence, the ability to perceive 3D structure, reason..._
- [ ] **[cs.LG]** [SUSD: Structured Unsupervised Skill Discovery through State Factorization](https://arxiv.org/abs/2602.01619v1) *by Seyed Mohammad Hadi Hosseini et al. (2026-02-02)* - _Unsupervised Skill Discovery (USD) aims to autonomously learn a diverse set of skills without relying on extrinsic rewards. One of the most common USD approaches is to maximize the Mutual Information (MI) between skill latent variables and states. Ho..._
- [ ] **[cs.LG]** [Generative Visual Code Mobile World Models](https://arxiv.org/abs/2602.01576v1) *by Woosung Koh et al. (2026-02-02)* - _Mobile Graphical User Interface (GUI) World Models (WMs) offer a promising path for improving mobile GUI agent performance at train- and inference-time. However, current approaches face a critical trade-off: text-based WMs sacrifice visual fidelity, ..._
- [ ] **[cs.AI]** [Autonomous Question Formation for Large Language Model-Driven AI Systems](https://arxiv.org/abs/2602.01556v1) *by Hong Su (2026-02-02)* - _Large language model (LLM)-driven AI systems are increasingly important for autonomous decision-making in dynamic and open environments. However, most existing systems rely on predefined tasks and fixed prompts, limiting their ability to autonomously..._
- [ ] **[cs.AI]** [S1-NexusAgent: a Self-Evolving Agent Framework for Multidisciplinary Scientific Research](https://arxiv.org/abs/2602.01550v1) *by S1-NexusAgent Team (2026-02-02)* - _Modern scientific research relies on large-scale data, complex workflows, and specialized tools, which existing LLMs and tool-based agents struggle to handle due to limitations in long-horizon planning, robust goal maintenance, and continual learning..._
- [ ] **[cs.AI]** [MAGIC: A Co-Evolving Attacker-Defender Adversarial Game for Robust LLM Safety](https://arxiv.org/abs/2602.01539v1) *by Xiaoyu Wen et al. (2026-02-02)* - _Ensuring robust safety alignment is crucial for Large Language Models (LLMs), yet existing defenses often lag behind evolving adversarial attacks due to their \textbf{reliance on static, pre-collected data distributions}. In this paper, we introduce ..._
- [ ] **[cs.AI]** [PRISM: Festina Lente Proactivity -- Risk-Sensitive, Uncertainty-Aware Deliberation for Proactive Agents](https://arxiv.org/abs/2602.01532v1) *by Yuxuan Fu et al. (2026-02-02)* - _Proactive agents must decide not only what to say but also whether and when to intervene. Many current systems rely on brittle heuristics or indiscriminate long reasoning, which offers little control over the benefit-burden tradeoff. We formulate the..._
- [ ] **[cs.AI]** [Legal Infrastructure for Transformative AI Governance](https://arxiv.org/abs/2602.01474v1) *by Gillian K. Hadfield (2026-02-01)* - _Most of our AI governance efforts focus on substance: what rules do we want in place? What limits or checks do we want to impose on AI development and deployment? But a key role for law is not only to establish substantive rules but also to establish..._
- [ ] **[cs.AI]** [Agyn: A Multi-Agent System for Team-Based Autonomous Software Engineering](https://arxiv.org/abs/2602.01465v1) *by Nikita Benkovich et al. (2026-02-01)* - _Large language models have demonstrated strong capabilities in individual software engineering tasks, yet most autonomous systems still treat issue resolution as a monolithic or pipeline-based process. In contrast, real-world software development is ..._
- [ ] **[cs.AI]** [SimGym: Traffic-Grounded Browser Agents for Offline A/B Testing in E-Commerce](https://arxiv.org/abs/2602.01443v1) *by Alberto Castelo et al. (2026-02-01)* - _A/B testing remains the gold standard for evaluating e-commerce UI changes, yet it diverts traffic, takes weeks to reach significance, and risks harming user experience. We introduce SimGym, a scalable system for rapid offline A/B testing using traff..._
- [ ] **[cs.CL]** [From Pragmas to Partners: A Symbiotic Evolution of Agentic High-Level Synthesis](https://arxiv.org/abs/2602.01401v2) *by Niansong Zhang et al. (2026-02-01)* - _The rise of large language models has sparked interest in AI-driven hardware design, raising the question: does high-level synthesis (HLS) still matter in the agentic era? We argue that HLS remains essential. While we expect mature agentic hardware s..._
- [ ] **[cond-mat.mtrl-sci]** [Towards knowledge-based workflows: a semantic approach to atomistic simulations for mechanical and thermodynamic properties](https://arxiv.org/abs/2602.01358v1) *by Abril Azocar Guzman et al. (2026-02-01)* - _Mechanical and thermodynamic properties, including the influence of crystal defects, are critical for evaluating materials in engineering applications. Molecular dynamics simulations provide valuable insight into these mechanisms at the atomic scale...._
- [ ] **[cs.AI]** [Aggregation Queries over Unstructured Text: Benchmark and Agentic Method](https://arxiv.org/abs/2602.01355v2) *by Haojia Zhu et al. (2026-02-01)* - _Aggregation query over free text is a long-standing yet underexplored problem. Unlike ordinary question answering, aggregate queries require exhaustive evidence collection and systems are required to "find all," not merely "find one." Existing paradi..._
- [ ] **[physics.soc-ph]** [Social Catalysts, Not Moral Agents: The Illusion of Alignment in LLM Societies](https://arxiv.org/abs/2602.02598v1) *by Yueqing Hu et al. (2026-02-01)* - _The rapid evolution of Large Language Models (LLMs) has led to the emergence of Multi-Agent Systems where collective cooperation is often threatened by the "Tragedy of the Commons." This study investigates the effectiveness of Anchoring Agents--pre-p..._
- [ ] **[cs.CV]** [Beyond Pixels: Visual Metaphor Transfer via Schema-Driven Agentic Reasoning](https://arxiv.org/abs/2602.01335v1) *by Yu Xu et al. (2026-02-01)* - _A visual metaphor constitutes a high-order form of human creativity, employing cross-domain semantic fusion to transform abstract concepts into impactful visual rhetoric. Despite the remarkable progress of generative AI, existing models remain largel..._
- [ ] **[cs.LG]** [ContextEvolve: Multi-Agent Context Compression for Systems Code Optimization](https://arxiv.org/abs/2602.02597v1) *by Hongyuan Su et al. (2026-02-01)* - _Large language models are transforming systems research by automating the discovery of performance-critical algorithms for computer systems. Despite plausible codes generated by LLMs, producing solutions that meet the stringent correctness and perfor..._
- [ ] **[cs.CR]** [TxRay: Agentic Postmortem of Live Blockchain Attacks](https://arxiv.org/abs/2602.01317v2) *by Ziyue Wang et al. (2026-02-01)* - _Decentralized Finance (DeFi) has turned blockchains into financial infrastructure, allowing anyone to trade, lend, and build protocols without intermediaries, but this openness exposes pools of value controlled by code. Within five years, the DeFi ec..._


